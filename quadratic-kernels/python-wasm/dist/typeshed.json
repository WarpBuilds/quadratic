{
  "files": {
    "/typeshed/numpy/__init__.pyi": "\"\"\"Public API of numpy\"\"\"\nimport os\nfrom typing import (\n    Any,\n    Callable,\n    Dict,\n    Generic,\n    Iterator,\n    IO,\n    List,\n    Optional,\n    Sequence,\n    Tuple,\n    Type,\n    TypeVar,\n    Union,\n    overload,\n    Iterable,\n    Generator,\n)\nfrom typing_extensions import Protocol, Literal\nfrom pathlib import Path\nimport builtins\n\nfrom . import testing, random, ma, linalg\n\nfrom pandas import Series\n\n_T = TypeVar(\"_T\")\n\n_Scalar = TypeVar(\"_Scalar\", bound=void)\n\n# void is the base class of all the types that an ndarray can have\nclass void:\n    @property\n    def dtype(self: _DTypeObj) -> _dtype[_DTypeObj]: ...\n    def astype(self, dtype: Type[_DType]) -> _DType: ...\n    def copy(self: _Scalar) -> _Scalar: ...\n\n# a smaller-bit integer can act like a bigger integer in the sense that if you add an int16 and an\n# int64, then numpy will upgrade the int16 to an int64 and add them\n# and this is why we let int32 be a subclass of int64; and similarly for float32 and float64\n# the same logic applies when adding unsigned and signed values (uint + int -> int)\n\n# this would be the correct definition, but it makes `int` conflict with `float`\n# class float64(void, float): ...\nclass float64(void, int):\n    def __float__(self) -> float: ...\n\nclass float32(float64): ...\nclass float16(float32): ...\n\nfloating = float64\nnumber = float64\n\nclass int64(float64): ...\nclass int32(int64, float64): ...\nclass int16(int32, float32): ...\nclass int8(int16, float16): ...\nclass uint64(int64): ...\nclass uint32(uint64, int32): ...\nclass uint16(uint32, int16): ...\nclass uint8(uint16, int8): ...\nclass bool_(int8): ...\nclass str_(void, str): ...\nclass object_(void): ...\n\ninteger = int64\n\n_DType = TypeVar(\n    \"_DType\",\n    bool_,\n    float16,\n    float32,\n    float64,\n    int8,\n    int16,\n    int32,\n    int64,\n    str_,\n    uint8,\n    uint16,\n    uint32,\n    uint64,\n    covariant=True,\n)\n_DType2 = TypeVar(\n    \"_DType2\",\n    bool_,\n    float16,\n    float32,\n    float64,\n    int8,\n    int16,\n    int32,\n    int64,\n    str_,\n    uint8,\n    uint16,\n    uint32,\n    uint64,\n    covariant=True,\n)\n_DTypeObj = TypeVar(\"_DTypeObj\", bound=Union[void, int, float])\n_ShapeType = Union[int, Tuple[int, ...], List[int]]\n_AxesType = Union[int, Tuple[int, ...], List[int]]\n_InterpolationType = Literal[\"linear\", \"lower\", \"higher\", \"midpoint\", \"nearest\"]\n_OrderType = Union[str, Sequence[str]]\n_ScalarLike = Union[_DType, str, int, float]\n_ConditionType = Union[ndarray[bool_], bool_, bool]\nnewaxis: None = ...\n\n_AnyNum = Union[int, float, bool]\n# generic types that are only allowed to take on dtype values\n\n_Float = TypeVar(\"_Float\", float16, float32, float64)\n_FloatLike = TypeVar(\"_FloatLike\", bound=Union[float64, float])\n_Int = TypeVar(\"_Int\", bool_, int8, int16, int32, int64, uint8, uint16, uint32, uint64)\n_IntLike = TypeVar(\"_IntLike\", bound=Union[int64, int])\n_BoolLike = TypeVar(\"_BoolLike\", bound=Union[bool_, bool])\n\n_NestedList = Union[List[_T], List[List[_T]], List[List[List[_T]]], List[List[List[List[_T]]]]]\n\nclass dtype(Generic[_DTypeObj]):\n    @overload\n    def __init__(self: dtype[_DTypeObj], obj: Type[_DTypeObj]) -> None: ...\n    @overload\n    def __init__(self, obj: str) -> None: ...\n    @property\n    def type(self) -> Type[_DTypeObj]: ...\n\n_dtype = dtype\n\nclass ndarray(Generic[_DType]):\n    \"\"\"\n    The main object in the numpy library.\n    \"\"\"\n\n    #\n    # Array-like structures attributes\n    #\n    dtype: _dtype[_DType]\n    size: int\n    ndim: int\n    shape: Tuple[int, ...]\n\n    #\n    # Array-like methods\n    #\n    def __init__(\n        self,\n        shape: Tuple[int, ...],\n        dtype: Optional[Type[_DType]] = ...,\n        buffer: Optional[Any] = ...,\n        offset: Optional[int] = ...,\n        strides: Optional[Tuple[int, ...]] = ...,\n        order: Optional[str] = ...,\n    ) -> None: ...\n    def all(self, axis: Optional[_AxesType] = ..., keepdims: bool = ...) -> ndarray[_DType]: ...\n    def any(self, axis: Optional[_AxesType] = ..., keepdims: bool = ...) -> ndarray[_DType]: ...\n    def argmax(self, axis: Optional[int] = ...) -> ndarray[_DType]: ...\n    def argmin(self, axis: Optional[int] = ...) -> ndarray[_DType]: ...\n    # def argpartition(self, kth: Union[int, Sequence[int]], axis: Optional[int]=-1,\n    #                  kind: str='introselect', order: _OrderType=None) -> ndarray[_DType]: ...\n    def argsort(\n        self, axis: Optional[int] = ..., kind: str = ..., order: Optional[_OrderType] = ...\n    ) -> ndarray[_DType]: ...\n    # _DType has to be split up like this for some reason; I don't fully understand it\n    @overload\n    def astype(self, dtype: Type[_Int], copy: bool = ...) -> ndarray[_Int]: ...\n    @overload\n    def astype(self, dtype: Type[_Float], copy: bool = ...) -> ndarray[_Float]: ...\n    @overload\n    def astype(self, dtype: Type[str_], copy: bool = ...) -> ndarray[str_]: ...\n    # the bool overload has to come before the int overload because bool is a subclass of int\n    @overload\n    def astype(self, dtype: Type[bool], copy: bool = ...) -> ndarray[bool_]: ...\n    @overload\n    def astype(self, dtype: Type[int], copy: bool = ...) -> ndarray[int64]: ...\n    @overload\n    def astype(self, dtype: Type[float], copy: bool = ...) -> ndarray[float64]: ...\n    @overload\n    def astype(self, dtype: Type[str], copy: bool = ...) -> ndarray[str_]: ...\n    def byteswap(self, inplace: bool = ...) -> ndarray[_DType]: ...\n    def choose(self, choices: Sequence[ndarray[_DType]], mode: str = ...) -> ndarray[_DType]: ...\n    def clip(self, a_min: _AnyNum, a_max: _AnyNum) -> ndarray[_DType]: ...\n    def compress(self, condition: Sequence[bool], axis: Optional[int] = ...) -> ndarray[_DType]: ...\n    def conj(self) -> ndarray[_DType]: ...\n    def conjugate(self) -> ndarray[_DType]: ...\n    def copy(self, order: str = ...) -> ndarray[_DType]: ...\n    def cumprod(self, axis: Optional[int] = ..., dtype: Optional[Any] = ...) -> ndarray[_DType]: ...\n    def cumsum(\n        self, axis: Optional[int] = ..., dtype: Optional[Type[_DType]] = ...\n    ) -> ndarray[_DType]: ...\n    def diagonal(\n        self, offset: int = ..., axis1: int = ..., axis2: int = ...\n    ) -> ndarray[_DType]: ...\n    def dot(self, b: ndarray[_DType]) -> ndarray[_DType]: ...\n    def dump(self, file: str) -> None: ...\n    def dumps(self) -> str: ...\n    # def fill(self, value: _S) -> None: ...\n    def flatten(self, order: str = ...) -> ndarray[_DType]: ...\n    def getfield(self, dtype: Type[_DType], offset: int = ...) -> ndarray[_DType]: ...\n    def item(self) -> _DType: ...\n    def itemset(self, arg0: Union[int, Tuple[int, ...]], arg1: Optional[Any] = ...) -> None: ...\n    def max(self) -> _DType: ...\n    @overload\n    def mean(self: ndarray[float32]) -> float32: ...\n    @overload\n    def mean(self: ndarray[float32], axis: _AxesType) -> ndarray[float32]: ...\n    @overload\n    def mean(self) -> float64: ...\n    @overload\n    def mean(self, axis: _AxesType) -> ndarray[float64]: ...\n    def min(self) -> _DType: ...\n    def newbyteorder(self, new_order: str = ...) -> ndarray[_DType]: ...\n    def nonzero(self) -> Tuple[ndarray[int64], ...]: ...\n    def partition(\n        self, kth: _AxesType, axis: int = ..., kind: str = ..., order: Optional[_OrderType] = ...\n    ) -> None: ...\n    def prod(\n        self,\n        axis: Optional[_AxesType] = ...,\n        dtype: Optional[Type[_DType]] = ...,\n        keepdims: bool = ...,\n    ) -> ndarray[_DType]: ...\n    def ptp(self, axis: Optional[int] = ...) -> ndarray[_DType]: ...\n    def put(self, ind: ndarray[_DType], v: ndarray[_DType], mode: str = ...) -> None: ...\n    def ravel(self, order: str = ...) -> ndarray[_DType]: ...\n    def repeat(\n        self, repeats: Union[int, Sequence[int]], axis: Optional[int] = ...\n    ) -> ndarray[_DType]: ...\n    @overload\n    def reshape(self, *newshape: int) -> ndarray[_DType]: ...\n    @overload\n    def reshape(\n        self, newshape: Union[Tuple[int, ...], List[int]], order: str = ...\n    ) -> ndarray[_DType]: ...\n    def resize(self, new_shape: _ShapeType, refcheck: bool = ...) -> None: ...\n    def round(self, decimals: int = ...) -> ndarray[_DType]: ...\n    # def searchsorted(self, v: Union[_S, ndarray[_DType]], side: str='left',\n    #                  sorter: ndarray[_DType]=None) -> ndarray[_DType]: ...\n    def setfield(self, val: Any, dtype: Type[_DType], offset: int = ...) -> None: ...\n    def setflags(\n        self, write: Optional[bool] = ..., align: Optional[bool] = ..., uic: Optional[bool] = ...\n    ) -> None: ...\n    def sort(self, axis: int = ..., kind: str = ..., order: Optional[_OrderType] = ...) -> None: ...\n    def squeeze(self, axis: Optional[_AxesType] = ...) -> ndarray[_DType]: ...\n    @overload\n    def std(self: ndarray[float32]) -> float32: ...\n    @overload\n    def std(self) -> float64: ...\n    @overload\n    def std(\n        self,\n        axis: _AxesType,\n        dtype: Optional[Type[_DType]] = ...,\n        ddof: int = ...,\n        keepdims: bool = ...,\n    ) -> ndarray[_DType]: ...\n    @overload\n    def sum(self) -> _DType: ...\n    @overload\n    def sum(self, axis: Optional[_AxesType], keepdims: bool = ...) -> ndarray[_DType]: ...\n    def swapaxes(self, axis1: int, axis2: int) -> ndarray[_DType]: ...\n    def take(\n        self, indices: Sequence[int], axis: Optional[int] = ..., mode: str = ...\n    ) -> ndarray[_DType]: ...\n    def tobytes(self, order: str = ...) -> bytes: ...\n    def tofile(\n        self,\n        fid: object,\n        sep: str = ...,  # TODO fix fid definition (There's a bug in mypy io's namespace https://github.com/python/mypy/issues/1462)\n        format: str = ...,\n    ) -> None: ...\n    # for some reason, you can not use _Float to narrow down the type of ndarray here:\n    @overload\n    def tolist(\n        self: Union[ndarray[bool_], ndarray[int8], ndarray[int16], ndarray[int32], ndarray[int64]]\n    ) -> Sequence[int]: ...\n    @overload\n    def tolist(self: Union[ndarray[float32], ndarray[float64]]) -> Sequence[float]: ...\n    @overload\n    def tolist(self: ndarray[str_]) -> Sequence[str]: ...\n    def tostring(self, order: str = ...) -> bytes: ...\n    def trace(\n        self,\n        offset: int = ...,\n        axis1: int = ...,\n        axis2: int = ...,\n        dtype: Optional[Type[_DType]] = ...,\n    ) -> ndarray[_DType]: ...\n    def transpose(self, axes: Optional[_AxesType] = ...) -> ndarray[_DType]: ...\n    def var(\n        self,\n        axis: Optional[_AxesType] = ...,\n        dtype: Optional[Type[_DType]] = ...,\n        ddof: int = ...,\n        keepdims: bool = ...,\n    ) -> ndarray[_DType]: ...\n    def view(\n        self,\n        dtype: Optional[Union[Type[_DType], Type[ndarray[_DType]]]] = ...,\n        type: Optional[type] = ...,\n    ) -> ndarray[_DType]: ...\n    #\n    # Magic methods\n    #\n    def __abs__(self) -> ndarray[_DType]: ...\n    @overload\n    def __add__(self, value: ndarray[_DType]) -> ndarray[_DType]: ...\n    @overload\n    def __add__(self, value: _DType) -> ndarray[_DType]: ...\n    @overload\n    def __add__(self, value: float) -> ndarray[float64]: ...\n    def __and__(self, value: object) -> ndarray[_DType]: ...\n    @overload\n    def __array__(self) -> ndarray[_DType]: ...\n    @overload\n    def __array__(self, dtype: Type[_DType2]) -> ndarray[_DType2]: ...\n    def __array_prepare__(self, context: Optional[object] = ...) -> ndarray[_DType]: ...\n    def __array_wrap__(self, context: Optional[object] = ...) -> ndarray[_DType]: ...\n    def __bool__(self) -> bool: ...\n    def __complex__(self) -> complex: ...\n    def __contains__(self, key: object) -> bool: ...\n    def __copy__(self) -> ndarray[_DType]: ...\n    def __deepcopy__(self) -> ndarray[_DType]: ...\n    def __delattr__(self, name: str) -> None: ...\n    def __delitem__(self, key: str) -> None: ...\n    def __dir__(self) -> List[str]: ...\n    def __divmod__(self, value: object) -> Tuple[ndarray[_DType], ndarray[_DType]]: ...\n    def __eq__(self, value: object) -> ndarray[bool_]: ...  # type: ignore\n    def __float__(self) -> float: ...\n    def __floordiv__(self, value: object) -> ndarray[_DType]: ...\n    def __ge__(self, value: object) -> ndarray[bool_]: ...\n    def __getattribute__(self, name: str) -> Any: ...\n    @overload\n    def __getitem__(self, key: Union[int, Tuple[int, ...]]) -> _DType: ...\n    @overload\n    def __getitem__(\n        self,\n        key: Union[\n            None,\n            slice,\n            str,\n            ndarray[_Int],\n            List[int],\n            Tuple[int, Union[slice, ellipsis, None]],\n            Tuple[Union[slice, ellipsis, None], int],\n            Tuple[Union[slice, ellipsis, None], Union[slice, ellipsis, None], int],\n            Tuple[Union[ndarray[_Int], slice, ellipsis, None], ...],\n        ],\n    ) -> ndarray[_DType]: ...\n    def __gt__(self, value: object) -> ndarray[bool_]: ...\n    @overload\n    def __iadd__(self, value: ndarray[_DType]) -> ndarray[_DType]: ...\n    @overload\n    def __iadd__(self, value: _DType) -> ndarray[_DType]: ...\n    @overload\n    def __iadd__(self, value: float) -> ndarray[float64]: ...\n    def __iand__(self, value: object) -> ndarray[bool_]: ...\n    def __ifloordiv__(self, value: object) -> None: ...\n    def __ilshift__(self, value: object) -> None: ...\n    def __imatmul__(self, value: ndarray[_DType]) -> None: ...\n    def __imod__(self, value: object) -> None: ...\n    def __imul__(self, value: object) -> None: ...\n    def __index__(self) -> int: ...\n    def __int__(self) -> int: ...\n    def __invert__(self) -> ndarray[_DType]: ...\n    def __ior__(self, value: object) -> None: ...\n    def __ipow__(self, value: object) -> None: ...\n    def __irshift__(self, value: object) -> None: ...\n    def __isub__(self, value: object) -> None: ...\n    def __iter__(self) -> Iterator[_DType]: ...\n    def __itruediv__(self, value: object) -> ndarray[float64]: ...\n    def __ixor__(self, value: object) -> None: ...\n    def __le__(self, value: object) -> ndarray[_DType]: ...\n    def __len__(self) -> int: ...\n    def __lshift__(self, value: object) -> ndarray[_DType]: ...\n    def __lt__(self, value: object) -> ndarray[_DType]: ...\n    def __matmul__(self, value: ndarray[_DType]) -> ndarray[_DType]: ...\n    def __mod__(self, value: object) -> ndarray[_DType]: ...\n    def __mul__(self, value: object) -> ndarray[_DType]: ...\n    def __ne__(self, value: object) -> ndarray[_DType]: ...  # type: ignore\n    def __neg__(self) -> ndarray[_DType]: ...\n    def __or__(self, value: object) -> ndarray[_DType]: ...\n    def __pos__(self) -> ndarray[_DType]: ...\n    def __pow__(self, value: object) -> ndarray[_DType]: ...\n    @overload\n    def __radd__(self, value: ndarray[_DType]) -> ndarray[_DType]: ...\n    @overload\n    def __radd__(self, value: _DType) -> ndarray[_DType]: ...\n    def __rand__(self, value: object) -> ndarray[_DType]: ...\n    def __rdivmod__(self, value: object) -> Tuple[ndarray[_DType], ndarray[_DType]]: ...\n    def __rfloordiv__(self, value: object) -> ndarray[_DType]: ...\n    def __rlshift__(self, value: object) -> ndarray[_DType]: ...\n    def __rmatmul__(self, value: object) -> ndarray[_DType]: ...\n    def __rmod__(self, value: object) -> ndarray[_DType]: ...\n    def __rmul__(self, value: object) -> ndarray[_DType]: ...\n    def __ror__(self, value: object) -> ndarray[_DType]: ...\n    def __rpow__(self, value: object) -> ndarray[_DType]: ...\n    def __rrshift__(self, value: object) -> ndarray[_DType]: ...\n    def __rshift__(self, value: object) -> ndarray[_DType]: ...\n    def __rsub__(self, value: object) -> ndarray[_DType]: ...\n    @overload\n    def __rtruediv__(\n        self: ndarray[float32], value: Union[ndarray[float32], float32, float]\n    ) -> ndarray[float32]: ...\n    @overload\n    def __rtruediv__(self, value: object) -> ndarray[float64]: ...\n    def __rxor__(self, value: object) -> ndarray[_DType]: ...\n    def __setattr__(self, name: str, value: Any) -> None: ...\n    def __setitem__(self, key: Any, value: Any) -> None: ...\n    def __str__(self) -> str: ...\n    def __sub__(self, value: object) -> ndarray[_DType]: ...\n    @overload\n    def __truediv__(\n        self: ndarray[float32], value: Union[ndarray[float32], float32, float]\n    ) -> ndarray[float32]: ...\n    @overload\n    def __truediv__(self, value: object) -> ndarray[float64]: ...\n    def __xor__(self, value: object) -> ndarray[_DType]: ...\n\nclass Array(Protocol[_DType]):\n    def __array__(self) -> Union[ndarray[_DType], Sequence[Sequence[_DType]]]: ...\n\n_ArrayLike = Union[Array[_DType], Sequence[_DType]]\n_Coercable = Union[_ArrayLike, _DTypeObj]\n\n######\n# numpy's scalar hierarchy (http://docs.scipy.org/doc/numpy/reference/arrays.scalars.html#scalars)\n######\n# class bool_: ...\n# class number: ...\n# class integer(number, int): ...\n# class signedinteger(integer): ...\n# class byte(signedinteger): ...\n# class short(signedinteger): ...\n# class intc(signedinteger): ...\n# class int_(signedinteger): ...\n# class longlong(signedinteger): ...\n# class int8(signedinteger): ...\n# class int16(signedinteger): ...\n# class int32(signedinteger): ...\n# class int64(signedinteger): ...\n# class unsignedinteger(integer): ...\n# class ubyte(unsignedinteger): ...\n# class ushort(unsignedinteger): ...\n# class uintc(unsignedinteger): ...\n# class uint(unsignedinteger): ...\n# class ulonglong(unsignedinteger): ...\n# class uint8(signedinteger): ...\n# class uint16(signedinteger): ...\n# class uint32(signedinteger): ...\n# class uint64(signedinteger): ...\n# class inexact(number[float]): ...\n# class floating(inexact): ...\n# class half(floating): ...\n# class single(floating): ...\n# class float_(floating): ...\n# class longfloat_(floating): ...\n# class float16(floating): ...\n# class float64(floating): ...\n# class float128(floating): ...\n# class complexfloating(inexact): ...\n# class csingle(complexfloating): ...\n# class complex_(complexfloating): ...\n# class clongfloat(complexfloating): ...\n# class complex64(complexfloating): ...\n# class complex128(complexfloating): ...\n# class complex256(complexfloating): ...\n# class flexible(generic[_Scalar], Generic[_Scalar]): ...\n# class character(flexible[str]): ...\n# class str_(character): ...\n# class unicode_(character): ...\n# class void(flexible[None]): ...\n\n#\n# Array creation routines\n#\n# np.array: first check if the dtype has been set explicitly\n@overload\ndef array(\n    object: Union[_NestedList[Any], Iterable[ndarray], ndarray], dtype: Type[_DType]\n) -> ndarray[_DType]: ...\n@overload\ndef array(\n    object: Union[_NestedList[Any], Iterable[ndarray], ndarray], dtype: Type[int]\n) -> ndarray[int64]: ...\n@overload\ndef array(\n    object: Union[_NestedList[Any], Iterable[ndarray], ndarray], dtype: Type[float]\n) -> ndarray[float64]: ...\n\n# np.array: then check if it is a list of some type. check the most specific first\n@overload\ndef array(object: _NestedList[bool]) -> ndarray[bool_]: ...\n@overload\ndef array(object: _NestedList[_Int]) -> ndarray[_Int]: ...\n@overload\ndef array(object: _NestedList[_Float]) -> ndarray[_Float]: ...\n@overload\ndef array(object: _NestedList[int]) -> ndarray[int64]: ...\n@overload\ndef array(object: _NestedList[float]) -> ndarray[float64]: ...\n@overload\ndef array(object: _NestedList[str]) -> ndarray[str_]: ...\n@overload\ndef array(object: str) -> ndarray[str_]: ...\n@overload\ndef array(object: Union[ndarray[_DType], _NestedList[ndarray[_DType]]]) -> ndarray[_DType]: ...\n@overload\ndef array(object: Tuple) -> ndarray[bool_]: ...\n@overload\ndef arange(start: int, stop: int = ..., step: int = ...) -> ndarray[int64]: ...\n@overload\ndef arange(start: float, stop: float = ..., step: float = ...) -> ndarray[float64]: ...\n@overload\ndef arange(range_: int, dtype: Type[_DType]) -> ndarray[_DType]: ...\n@overload\ndef arange(range_: float) -> ndarray[float64]: ...\ndef ascontiguousarray(a: Any, dtype: Optional[Type[_DType]] = ...) -> ndarray: ...\ndef copy(a: Any, order: Optional[str] = ...) -> ndarray: ...\ndef cumprod(\n    a: ndarray[_DType], axis: Optional[int] = ..., dtype: Optional[Type[_DType]] = ...\n) -> ndarray[_DType]: ...\ndef cumsum(\n    a: ndarray[_DType], axis: Optional[int] = ..., dtype: Optional[Type[_DType]] = ...\n) -> ndarray[_DType]: ...\ndef delete(\n    arr: ndarray[_DType], object: Union[int, List[int], slice], axis: Optional[int] = ...\n) -> ndarray[_DType]: ...\n@overload\ndef empty(shape: _ShapeType, dtype: Type[_Int]) -> ndarray[_Int]: ...\n@overload\ndef empty(shape: _ShapeType, dtype: Type[_Float]) -> ndarray[_Float]: ...\n@overload\ndef empty(shape: _ShapeType, dtype: Type[str_]) -> ndarray[str_]: ...\n@overload\ndef empty(shape: _ShapeType, dtype: Type[bool]) -> ndarray[bool_]: ...\n@overload\ndef empty(shape: _ShapeType, dtype: Type[int]) -> ndarray[int64]: ...\n@overload\ndef empty(shape: _ShapeType, dtype: Type[float] = ...) -> ndarray[float64]: ...\n@overload\ndef empty(shape: _ShapeType, dtype: Type[str]) -> ndarray[str_]: ...\ndef empty_like(\n    a: Any, dtype: Optional[Any] = ..., order: str = ..., subok: bool = ...\n) -> ndarray: ...\ndef eye(N: int, M: Optional[int] = ..., k: int = ..., dtype: Type[_DType] = ...) -> ndarray: ...\ndef flatnonzero(a: ndarray[_DType]) -> ndarray[int64]: ...\ndef full(\n    shape: _ShapeType, fill_value: Any, dtype: Optional[Type[_DType]] = ..., order: str = ...\n) -> ndarray: ...\ndef full_like(\n    a: Any,\n    fill_value: Any,\n    dtype: Optional[Type[_DType]] = ...,\n    order: str = ...,\n    subok: bool = ...,\n) -> ndarray: ...\n\n# def fromfunction(\n#     function: Callable[..., _S], shape: _ShapeType, dtype: Type[_DType] = float\n# ) -> ndarray[_S]: ...\ndef fromiter(iterable: Iterator, dtype: Type[_DType], count: int = ...) -> ndarray: ...\ndef fromstring(\n    string: str, dtype: Type[_DType] = ..., count: int = ..., sep: str = ...\n) -> ndarray: ...\ndef frombuffer(\n    buffer: Union[bytes, bytearray, memoryview],\n    dtype: Type[_DType] = ...,\n    count: int = ...,\n    offset: int = ...,\n) -> ndarray: ...\ndef histogramdd(\n    a: ndarray,\n    bins: Optional[Union[ndarray, Series, List, int]],\n    range: Optional[List[Tuple[number, number]]] = ...,\n    density: bool = ...,\n    normed: bool = ...,\n    weights: Optional[Union[ndarray, Series, List[number]]] = ...,\n) -> Tuple[ndarray, List[number]]: ...\ndef identity(n: int, dtype: Optional[Type[_DType]] = ...) -> ndarray: ...\ndef insert(arr: ndarray[_DType], index: int, value: _DType) -> ndarray[_DType]: ...\n@overload\ndef linspace(\n    start: float, stop: float, num: int = ..., endpoint: bool = ...\n) -> ndarray[float64]: ...\n@overload\ndef linspace(\n    start: float, stop: float, *, dtype: Type[_DType], num: int = ..., endpoint: bool = ...\n) -> ndarray[_DType]: ...\ndef load(file: Union[str, os.PathLike, IO], encoding: str = ...) -> Dict[str, ndarray]: ...\ndef loadtxt(\n    fname: Any,\n    dtype: Type[_DType] = ...,\n    comments: Union[str, Sequence[str]] = ...,\n    delimiter: Optional[str] = ...,\n    converters: Optional[Dict[int, Callable[[Any], float]]] = ...,\n    skiprows: int = ...,\n    usecols: Optional[Sequence[int]] = ...,\n    unpack: bool = ...,\n    ndmin: int = ...,\n) -> ndarray: ...\n@overload\ndef ones(shape: _ShapeType, order: str = ...) -> ndarray[float64]: ...\n@overload\ndef ones(shape: _ShapeType, dtype: Type[_DType] = ..., order: str = ...) -> ndarray[_DType]: ...\n@overload\ndef ones_like(a: ndarray[_DType], subok: bool = ...) -> ndarray[_DType]: ...\n@overload\ndef ones_like(a: ndarray, dtype: Type[_DType], subok: bool = ...) -> ndarray[_DType]: ...\n@overload\ndef repeat(a: _DType, repeats: _IntLike) -> ndarray[_DType]: ...\n@overload\ndef repeat(a: int, repeats: _IntLike) -> ndarray[int64]: ...\n@overload\ndef repeat(a: float, repeats: _IntLike) -> ndarray[float64]: ...\n@overload\ndef repeat(a: ndarray[_DType], repeats: _IntLike) -> ndarray[_DType]: ...\n@overload\ndef zeros(shape: _ShapeType, order: str = ...) -> ndarray[float64]: ...\n@overload\ndef zeros(shape: _ShapeType, dtype: Type[_DType] = ..., order: str = ...) -> ndarray[_DType]: ...\n@overload\ndef zeros_like(a: ndarray[_DType], order: str = ..., subok: bool = ...) -> ndarray[_DType]: ...\n@overload\ndef zeros_like(a: ndarray, dtype: Type[_DType], subok: bool = ...) -> ndarray[_DType]: ...\n\n#\n# Array transformation routines\n#\ndef abs(x: ndarray[_DType]) -> ndarray[_DType]: ...\ndef add(x1: ndarray[_DType], x2: ndarray[_DType]) -> ndarray[_DType]: ...\n@overload\ndef all(a: ndarray[_DType]) -> bool_: ...\n@overload\ndef all(a: ndarray[_DType], axis: _AxesType) -> ndarray[bool_]: ...\n@overload\ndef amax(a: ndarray[_DType]) -> _DType: ...\n@overload\ndef amax(a: ndarray[_DType], axis: _AxesType) -> ndarray[_DType]: ...\ndef append(a: _ArrayLike, b: _ArrayLike, axis: _AxesType = ...) -> ndarray: ...\n@overload\ndef argmin(a: Sequence, axis: _AxesType = ...) -> int64: ...\n@overload\ndef argmin(\n    a: ndarray[_DType], axis: _AxesType = ..., out: Optional[ndarray[_DType]] = ...\n) -> ndarray[int64]: ...\n@overload\ndef argmax(a: Sequence, axis: _AxesType = ...) -> int64: ...\n@overload\ndef argmax(\n    a: ndarray[_DType], axis: _AxesType = ..., out: Optional[ndarray[_DType]] = ...\n) -> ndarray[int64]: ...\ndef argsort(a: ndarray[_DType], axis: _AxesType = ...) -> ndarray[_DType]: ...\ndef array_equal(a1: ndarray[_DType], a2: ndarray[_DType]) -> bool: ...\ndef array_split(\n    ary: ndarray[_DType], indices_or_sections: Union[int, List[int]], axis: int = ...\n) -> List[ndarray[_DType]]: ...\ndef asscaler(x: _Int) -> int: ...\n\n# np.asarray\n@overload\ndef asarray(a: ndarray, dtype: Type[_Int]) -> ndarray[_Int]: ...\n@overload\ndef asarray(a: ndarray, dtype: Type[_Float]) -> ndarray[_Float]: ...\n@overload\ndef asarray(a: ndarray, dtype: Type[str_]) -> ndarray[str_]: ...\n\n# the bool overload has to come before the int overload because bool is a subclass of int\n@overload\ndef asarray(a: ndarray, dtype: Type[bool]) -> ndarray[bool_]: ...\n@overload\ndef asarray(a: ndarray, dtype: Type[int]) -> ndarray[int64]: ...\n@overload\ndef asarray(a: ndarray, dtype: Type[float]) -> ndarray[float64]: ...\n@overload\ndef asarray(a: ndarray, dtype: Type[str]) -> ndarray[str_]: ...\n@overload\ndef atleast_2d(ary: _Coercable) -> ndarray: ...\n@overload\ndef atleast_2d(ar: _Coercable, *ary: _Coercable) -> List[ndarray]: ...\n@overload\ndef ceil(a: _FloatLike) -> _FloatLike: ...\n@overload\ndef ceil(a: ndarray[_DType]) -> ndarray[_DType]: ...\ndef clip(a: ndarray[_DType], a_min: _DType, a_max: _DType) -> ndarray[_DType]: ...\ndef concatenate(arrays: Sequence[_ArrayLike[_DType]], axis: _AxesType = ...) -> ndarray[_DType]: ...\ndef corrcoef(\n    x: ndarray[_DType], y: Optional[ndarray[_DType]] = ..., rowvar: Optional[bool] = ...\n) -> ndarray[float64]: ...\ndef cos(\n    x: Union[_DType, ndarray[_DType], int, float, List[int], List[float]],\n    out: Optional[Union[ndarray[_DType], Tuple[ndarray[_DType], None]]] = ...,\n    where: Optional[_ArrayLike] = ...,\n) -> Union[_DType, ndarray[_DType]]: ...\ndef cov(m: ndarray[_DType], rowvar: Optional[bool]) -> ndarray[float64]: ...\ndef deg2rad(\n    x: Union[_DType, ndarray[_DType], int, float, List[int], List[float]],\n    out: Optional[Union[ndarray[_DType], Tuple[ndarray[_DType], None]]] = ...,\n    where: Optional[_ArrayLike] = ...,\n) -> Union[_DType, ndarray[_DType]]: ...\ndef diag(a: ndarray[_DType]) -> ndarray[_DType]: ...\ndef diff(\n    a: ndarray[_DType],\n    n: _IntLike = ...,\n    axis: _AxesType = ...,\n    prepend: ndarray[_DType] = ...,\n    append: ndarray[_DType] = ...,\n) -> ndarray[_DType]: ...\ndef digitize(x: ndarray[_DType], bins: ndarray[_DType], right: bool = ...) -> ndarray[_DType]: ...\n@overload\ndef divide(x1: float32, x2: float32) -> float32: ...\n@overload\ndef divide(x1: _DTypeObj, x2: _DTypeObj) -> float64: ...\n@overload\ndef divide(x1: ndarray[float32], x2: Union[ndarray[float32], float32]) -> ndarray[float32]: ...\n@overload\ndef divide(x1: ndarray, x2: Union[ndarray, _DTypeObj]) -> ndarray[float64]: ...\n@overload\ndef divide(x1: Sequence[_AnyNum], x2: _DTypeObj) -> ndarray[float64]: ...\n@overload\ndef dot(x1: _Int, x2: _Int) -> _Int: ...\n@overload\ndef dot(x1: ndarray, x2: ndarray) -> ndarray: ...\n@overload\ndef exp(a: _DTypeObj) -> _DTypeObj: ...\n@overload\ndef exp(a: ndarray[_DType]) -> ndarray[_DType]: ...\ndef expand_dims(a: ndarray[_DType], axis: _AxesType) -> ndarray[_DType]: ...\ndef fill_diagonal(a: ndarray[_DType], val: _FloatLike, wrap: bool = ...) -> None: ...\n@overload\ndef floor(x: _FloatLike) -> _FloatLike: ...\n@overload\ndef floor(x: ndarray[_Float]) -> ndarray[_Float]: ...\ndef genfromtxt(\n    fname: Union[IO, str, Path, List[str], Generator[str, None, None]],\n    dtype: Type[_DType] = ...,\n    comments: str = ...,\n    delimiter: Optional[str] = ...,\n    skip_header: int = ...,\n    skip_footer: int = ...,\n    converters: Any = ...,\n    missing_values: Any = ...,\n    filling_values: Any = ...,\n    usecols: Sequence[int] = ...,\n    names: Optional[Union[Literal[True], str, Sequence[str]]] = ...,\n    excludelist: Sequence[str] = ...,\n    deletechars: str = ...,\n    replace_space: str = ...,\n    autostrip: bool = ...,\n    case_sensitive: Literal[True, False, \"upper\", \"lower\"] = ...,\n    defaultfmt: str = ...,\n    unpack: bool = ...,\n    usemask: bool = ...,\n    loose: bool = ...,\n    invalid_raise: bool = ...,\n    max_rows: int = ...,\n    encoding: str = ...,\n) -> ndarray[_DType]: ...\ndef hstack(tup: Union[List[ndarray[_DType]], Tuple[ndarray[_DType], ...]]) -> ndarray[_DType]: ...\ndef isclose(\n    a: _ArrayLike, b: _ArrayLike, rtol: float = ..., atol: float = ..., equal_nan: bool = ...\n) -> ndarray: ...\ndef in1d(\n    ar1: ndarray[_DType], ar2: ndarray[_DType], assume_unique: bool = ..., inverse: bool = ...\n) -> ndarray[bool_]: ...\ndef interp(\n    x: _ArrayLike,\n    xp: Sequence[float],\n    fp: Sequence[Union[float, complex]],\n    left: Optional[Union[float, complex]] = ...,\n    right: Optional[Union[float, complex]] = ...,\n    period: Optional[float] = ...,\n) -> ndarray: ...\ndef isin(element: Sequence[_DType], test_element: _DType) -> ndarray[_DType]: ...\n@overload\ndef isnan(x: float64) -> bool: ...\n@overload\ndef isnan(x: ndarray[_DType]) -> ndarray[bool_]: ...\n@overload\ndef ix_(x: ndarray[_DType]) -> ndarray[_DType]: ...\n@overload\ndef ix_(x1: ndarray[_DType], x2: ndarray[_DType]) -> Tuple[ndarray[_DType], ndarray[_DType]]: ...\n@overload\ndef log(a: _FloatLike) -> _FloatLike: ...\n@overload\ndef log(a: ndarray[_DType]) -> ndarray[_DType]: ...\n@overload\ndef log2(a: _FloatLike) -> _FloatLike: ...\n@overload\ndef log2(a: ndarray[_DType]) -> ndarray[_DType]: ...\n@overload\ndef log10(a: _FloatLike) -> _FloatLike: ...\n@overload\ndef log10(a: ndarray[_DType]) -> ndarray[_DType]: ...\ndef logical_and(x1: ndarray[bool_], x2: ndarray[bool_]) -> ndarray[bool_]: ...\ndef matmul(a: ndarray[_DType], b: ndarray[_DType]) -> ndarray[_DType]: ...\n@overload\ndef max(a: ndarray[_DType], axis: None = ...) -> _DType: ...\n@overload\ndef max(a: ndarray[_DType], axis: _AxesType, keepdims: bool = ...) -> ndarray[_DType]: ...\ndef maximum(a: ndarray[_DType], b: ndarray[_DType]) -> ndarray[_DType]: ...\n@overload\ndef mean(a: ndarray[_Float]) -> _Float: ...\n@overload\ndef mean(a: ndarray[_Float], axis: _AxesType, keepdims: bool = ...) -> ndarray[_Float]: ...\ndef median(\n    a: ndarray,\n    axis: _IntLike = ...,\n    out: ndarray = ...,\n    overwrite_input: bool = ...,\n    keepdims: bool = ...,\n) -> ndarray[float64]: ...\n@overload\ndef min(a: ndarray[_DType], axis: None = ...) -> _DType: ...\n@overload\ndef min(a: ndarray[_DType], axis: _AxesType, keepdims: bool = ...) -> ndarray[_DType]: ...\ndef minimum(a: ndarray[_DType], b: ndarray[_DType]) -> ndarray[_DType]: ...\ndef nan_to_num(\n    x: ndarray[_DType],\n    copy: bool = ...,\n    nan: _AnyNum = ...,\n    posinf: _AnyNum = ...,\n    neginf: _AnyNum = ...,\n) -> ndarray[_DType]: ...\ndef nonzero(a: ndarray) -> Tuple[ndarray[int64], ...]: ...\ndef outer(a: ndarray[_DType], b: ndarray[_DType]) -> ndarray[_DType]: ...\n@overload\ndef percentile(\n    a: ndarray[_DType],\n    q: _FloatLike,\n    interpolation: _InterpolationType = ...,\n    axis: _AxesType = ...,\n) -> _DType: ...\n@overload\ndef percentile(\n    a: ndarray[_DType],\n    q: _ArrayLike,\n    interpolation: _InterpolationType = ...,\n    axis: _AxesType = ...,\n) -> ndarray[_DType]: ...\ndef power(x1: ndarray[_DType], x2: Union[_AnyNum, ndarray[_DType]]) -> ndarray[_DType]: ...\n@overload\ndef prod(a: ndarray[_DType], axis: None = ...) -> _DType: ...\n@overload\ndef prod(a: ndarray[_DType], axis: _AxesType, keepdims: bool = ...) -> ndarray[_DType]: ...\ndef ravel(a: ndarray[_DType]) -> ndarray[_DType]: ...\ndef reshape(a: ndarray[_DType], newshape: _ShapeType) -> ndarray[_DType]: ...\ndef round(a: ndarray[_DType], decimals: _IntLike = ...) -> ndarray[_DType]: ...\ndef save(\n    file: Union[str, os.PathLike, IO],\n    arr: ndarray,\n    allow_pickle: bool = ...,\n    fix_imports: bool = ...,\n) -> None: ...\n@overload\ndef searchsorted(a: ndarray[_DType], v: _DType, side: str = ...) -> int64: ...\n@overload\ndef searchsorted(a: ndarray[_DType], v: ndarray[_DType], side: str = ...) -> ndarray[int64]: ...\ndef setdiff1d(\n    ar1: Union[ndarray[_DType], List[_ScalarLike]],\n    ar2: Union[ndarray[_DType], List[_ScalarLike]],\n    assume_unique: bool = ...,\n) -> ndarray[_DType]: ...\ndef sin(\n    x: Union[_DType, ndarray[_DType], int, float, List[int], List[float]],\n    out: Optional[Union[ndarray[_DType], Tuple[ndarray[_DType], None]]] = ...,\n    where: Optional[_ArrayLike] = ...,\n) -> Union[_DType, ndarray[_DType]]: ...\ndef sign(x: ndarray[_DType]) -> ndarray[_DType]: ...\ndef sort(a: ndarray[_DType]) -> ndarray[_DType]: ...\ndef split(\n    ary: ndarray[_DType], indices_or_sections: Union[int, List[int]], axis: int = ...\n) -> List[ndarray[_DType]]: ...\ndef square(x: ndarray[_DType]) -> ndarray[_DType]: ...\ndef squeeze(a: ndarray[_DType], axis: _AxesType = ...) -> ndarray[_DType]: ...\n@overload\ndef sqrt(a: float) -> float: ...\n@overload\ndef sqrt(a: ndarray) -> ndarray[float64]: ...\ndef stack(arrays: List[ndarray[_DType]], axis: _AxesType = ...) -> ndarray[_DType]: ...\n@overload\ndef std(a: ndarray[_Float]) -> _Float: ...\n@overload\ndef std(a: ndarray[_Float], axis: _AxesType, keepdims: bool = ...) -> ndarray[_Float]: ...\ndef subtract(\n    x1: ndarray[_DType], x2: ndarray[_DType], axis: Optional[int] = ...\n) -> ndarray[_DType]: ...\n@overload\ndef sum(a: ndarray[_DType], axis: None = ...) -> _DType: ...\n@overload\ndef sum(a: ndarray[_DType], axis: _AxesType, keepdims: bool = ...) -> ndarray[_DType]: ...\ndef take(a: ndarray[_DType], indices: ndarray[_Int], axis: _AxesType = ...) -> ndarray[_DType]: ...\ndef take_along_axis(\n    arr: ndarray[_DType], indices: ndarray[_Int], axis: _AxesType = ...\n) -> ndarray[_DType]: ...\ndef tan(\n    x: Union[_DType, ndarray[_DType], int, float, List[int], List[float]],\n    out: Optional[Union[ndarray[_DType], Tuple[ndarray[_DType], None]]] = ...,\n    where: Optional[_ArrayLike] = ...,\n) -> Union[_DType, ndarray[_DType]]: ...\ndef tile(a: ndarray[_DType], reps: Union[_NestedList[int], ndarray[_Int]]) -> ndarray[_DType]: ...\ndef trace(a: ndarray[_DType]) -> _DType: ...\ndef transpose(a: ndarray[_DType]) -> ndarray[_DType]: ...\ndef tril(m: ndarray[_DType], k: Optional[int] = ...) -> ndarray[_DType]: ...\ndef tril_indices(n: _IntLike, k: _IntLike = ..., m: _IntLike = ...) -> Tuple[ndarray, ndarray]: ...\ndef triu(m: ndarray[_DType], k: Optional[int] = ...) -> ndarray[_DType]: ...\n@overload\ndef unique(a: ndarray[_DType], axis: Optional[int] = ...) -> ndarray[_DType]: ...\n@overload\ndef unique(\n    a: ndarray[_DType], return_counts: bool = ..., axis: Optional[int] = ...\n) -> Tuple[ndarray[_DType], ndarray[_DType]]: ...\n@overload\ndef unique(\n    a: ndarray[_DType], return_inverse: bool = ..., axis: Optional[int] = ...\n) -> Tuple[ndarray[_DType], ndarray[_DType]]: ...\ndef vstack(tup: Sequence[ndarray[_DType]]) -> ndarray[_DType]: ...\n@overload\ndef where(condition: _ConditionType, x: ndarray[_DType], y: ndarray[_DType]) -> ndarray[_DType]: ...\n@overload\ndef where(condition: _ConditionType, x: _ScalarLike, y: ndarray[_DType]) -> ndarray[_DType]: ...\n@overload\ndef where(condition: _ConditionType, x: ndarray[_DType], y: _ScalarLike) -> ndarray[_DType]: ...\n@overload\ndef where(condition: _ConditionType, x: _DType, y: _DType) -> ndarray[_DType]: ...\n@overload\ndef where(condition: _ConditionType, x: int, y: int) -> ndarray[int64]: ...\n@overload\ndef where(condition: _ConditionType, x: float, y: float) -> ndarray[float64]: ...\n@overload\ndef where(condition: _ConditionType) -> Tuple[ndarray[int64], ...]: ...\n\n#\n# nan series methods\n#\nnancumprod = cumprod\nnancumsum = cumsum\nnanmean = mean\nnanstd = std\nnansum = sum\nnanmin = min\nnanmax = max\n\n#\n# Saving methods\n#\ndef savetxt(\n    fname: str,\n    X: ndarray,\n    *,\n    header: str = ...,\n    delimiter: str = ...,\n    newline: str = ...,\n    comments: str = ...,\n) -> None: ...\ndef savez(file: Path, *args: ndarray, **kwds: ndarray) -> None: ...\ndef savez_compressed(file: Path, *args: ndarray, **kwds: ndarray) -> None: ...\n\n#\n# weird classes\n#\nclass matrix:\n    def __init__(self, data: Union[List, str], dtype: Type[_DType] = ..., copy: bool = ...): ...\n    def reshape(self, shape: _ShapeType) -> matrix: ...\n\nclass finfo(Generic[_Float]):\n    eps: _Float\n    resolution: _Float\n    min: _Float\n    max: _Float\n    dtype: _Float\n    @overload\n    def __init__(self, dtype: _Float): ...\n    @overload\n    def __init__(self, dtype: Type[_Float]): ...\n    @overload\n    def __init__(self: finfo[float64], dtype: Union[float, Type[float]]): ...\n\n#\n# module functions\n#\ndef set_printoptions(\n    precision: Any = ...,\n    threshold: Any = ...,\n    edgeitems: Any = ...,\n    linewidth: Any = ...,\n    suppress: Any = ...,\n    nanstr: Any = ...,\n    infstr: Any = ...,\n    formatter: Any = ...,\n    sign: Any = ...,\n    floatmode: Any = ...,\n    *,\n    legacy: Any = ...,\n) -> None: ...\n\n#\n# Specific values\n#\ne: float\ninf: float\nnan: float\nNaN: float\nNAN: float\npi: float\n\n# Local Variables:\n# blacken-line-length: 100\n# blacken-allow-py36: t\n# blacken-skip-string-normalization: t\n# End:\n",
    "/typeshed/numpy/linalg.pyi": "from typing import Tuple, Union, overload\nfrom typing_extensions import Literal\n\nfrom numpy import ndarray, _Int, float64, _DType\n\ndef slogdet(\n    a: ndarray[_DType],\n) -> Union[Tuple[float64, float64], Tuple[ndarray[float64], ndarray[float64]]]: ...\n@overload\ndef svd(\n    a: ndarray[_DType],\n    full_matrices: bool = ...,\n    compute_uv: Literal[True] = ...,\n    hermitian: bool = ...,\n) -> Tuple[ndarray[_DType], ndarray[_DType], ndarray[_DType]]: ...\n@overload\ndef svd(\n    a: ndarray[_DType],\n    *,\n    compute_uv: Literal[False],\n    full_matrices: bool = ...,\n    hermitian: bool = ...,\n) -> ndarray[_DType]: ...\n",
    "/typeshed/numpy/ma.pyi": "from numpy import ndarray, _DType, bool_\nfrom typing import Generic\n\nclass MaskedArray(ndarray[_DType]): ...\n\ndef array(data: ndarray[_DType], mask: ndarray[bool_] = ...) -> MaskedArray[_DType]: ...\ndef dot(a: MaskedArray[_DType], b: MaskedArray[_DType]) -> MaskedArray[_DType]: ...\ndef masked_array(data: ndarray[_DType], mask: ndarray[_DType]) -> MaskedArray[_DType]: ...\ndef median(data: MaskedArray[_DType]) -> _DType: ...\n",
    "/typeshed/numpy/random.pyi": "from typing import Iterable, List, Optional, Sequence, Tuple, TypeVar, Union, overload\nfrom typing_extensions import Literal\n\nfrom . import (\n    _ArrayLike,\n    _DType,\n    _Float,\n    _FloatLike,\n    _Int,\n    _IntLike,\n    _ShapeType,\n    float64,\n    int64,\n    ndarray,\n)\n\n_T = TypeVar(\"_T\")\n@overload\ndef binomial(n: _IntLike, p: _FloatLike) -> _Int: ...\n@overload\ndef binomial(n: _IntLike, p: _FloatLike, size: _IntLike) -> ndarray[_Int]: ...\n@overload\ndef binomial(n: _IntLike, p: _ArrayLike[_Float], size: ndarray[_Int] = ...) -> ndarray[_Int]: ...\n@overload\ndef binomial(n: _ArrayLike[_Int], p: _FloatLike, size: ndarray[_Int] = ...) -> ndarray[_Int]: ...\n@overload\ndef binomial(\n    n: _ArrayLike[_Int], p: _ArrayLike[_Float], size: ndarray[_Int] = ...\n) -> ndarray[_Int]: ...\n@overload\ndef choice(a: _IntLike) -> _IntLike: ...\n@overload\ndef choice(a: _Int, size: int) -> ndarray[_Int]: ...\n@overload\ndef choice(a: int, size: int) -> ndarray[int64]: ...\n@overload\ndef choice(a: _IntLike, size: _IntLike, replace: bool) -> ndarray[int64]: ...\n@overload\ndef choice(\n    a: List[_T], p: Union[List[_FloatLike], ndarray[_Float]] = ..., replace: bool = ...\n) -> _T: ...\n@overload\ndef choice(\n    a: range, size: _IntLike, replace: bool = ..., p: Union[List[_FloatLike], ndarray[_Float]] = ...\n) -> ndarray[int64]: ...\n@overload\ndef choice(\n    a: range, *, replace: bool = ..., p: Union[List[_FloatLike], ndarray[_Float]] = ...\n) -> int64: ...\n@overload\ndef choice(\n    a: ndarray[_DType],\n    size: _IntLike,\n    replace: bool = ...,\n    p: Union[List[_FloatLike], ndarray[_Float]] = ...,\n) -> ndarray[_DType]: ...\n@overload\ndef choice(\n    a: ndarray[_DType], *, replace: bool = ..., p: Union[List[_FloatLike], ndarray[_Float]] = ...\n) -> _DType: ...\ndef default_rng(seed: Optional[int] = ...) -> Generator: ...\ndef dirichlet(alpha: ndarray[_DType], size: _IntLike = ...) -> ndarray[_DType]: ...\n@overload\ndef exponential(scale: _FloatLike) -> _Float: ...\n@overload\ndef exponential(scale: _FloatLike, size: Sequence[_IntLike]) -> ndarray[float64]: ...\n@overload\ndef exponential(scale: Sequence[_FloatLike], size: Sequence[_IntLike]) -> ndarray[float64]: ...\ndef geometric(p: float, size: _IntLike) -> ndarray[float64]: ...\ndef get_state() -> Tuple[str, ndarray[_Int], _IntLike, _IntLike, _FloatLike]: ...\ndef normal(loc: float, scale: float, size: Union[int, Tuple[int, ...]]) -> ndarray[float64]: ...\n@overload\ndef permutation(size: int) -> ndarray[int64]: ...\n@overload\ndef permutation(size: Iterable[_DType]) -> ndarray[_DType]: ...\ndef rand(*args: int) -> ndarray[_Float]: ...\ndef randn(*args: int) -> ndarray[_Float]: ...\n@overload\ndef randint(low: int, high: int = ...) -> int64: ...\n@overload\ndef randint(low: int, size: Tuple[int, ...], high: int = ...) -> ndarray[int64]: ...\n@overload\ndef randint(low: int, size: int, high: int = ...) -> ndarray[int64]: ...\ndef seed(s: int) -> None: ...\ndef set_state(state: Tuple[str, ndarray[_Int], _IntLike, _IntLike, _FloatLike]) -> None: ...\ndef shuffle(x: ndarray) -> None: ...\n@overload\ndef uniform() -> float64: ...\n@overload\ndef uniform(size: _ShapeType) -> ndarray: ...\n@overload\ndef uniform(low: float, high: float, size: _ShapeType) -> ndarray: ...\n\nclass Generator:\n    def __init__(self, seed: int = ...): ...\n    @overload\n    def choice(self, a: _IntLike) -> _IntLike: ...\n    @overload\n    def choice(self, a: _Int, size: int) -> ndarray[_Int]: ...\n    @overload\n    def choice(self, a: int, size: int) -> ndarray[int64]: ...\n    @overload\n    def choice(self, a: _IntLike, size: _IntLike, replace: bool) -> ndarray[int64]: ...\n    @overload\n    def choice(\n        self, a: List[_T], p: Union[List[_FloatLike], ndarray[_Float]] = ..., replace: bool = ...\n    ) -> _T: ...\n    @overload\n    def choice(\n        self,\n        a: range,\n        size: _IntLike,\n        replace: bool = ...,\n        p: Union[List[_FloatLike], ndarray[_Float]] = ...,\n    ) -> ndarray[int64]: ...\n    @overload\n    def choice(\n        self, a: range, *, replace: bool = ..., p: Union[List[_FloatLike], ndarray[_Float]] = ...\n    ) -> int64: ...\n    @overload\n    def choice(\n        self,\n        a: ndarray[_DType],\n        size: _IntLike,\n        replace: bool = ...,\n        p: Union[List[_FloatLike], ndarray[_Float]] = ...,\n    ) -> ndarray[_DType]: ...\n    @overload\n    def choice(\n        self,\n        a: ndarray[_DType],\n        *,\n        replace: bool = ...,\n        p: Union[List[_FloatLike], ndarray[_Float]] = ...,\n    ) -> _DType: ...\n    def normal(\n        self,\n        loc: Union[float, ndarray[_DType]] = ...,\n        scale: Union[float, ndarray[_DType]] = ...,\n        size: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...\n    def permutation(self, size: int) -> ndarray[int64]: ...\n    def shuffle(self, x: ndarray) -> None: ...\n    def beta(\n        self,\n        a: Union[float, ndarray[_DType]] = ...,\n        b: Union[float, ndarray[_DType]] = ...,\n        size: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...  # Draw samples from a Beta distribution.\n    def binomial(\n        self,\n        n: Union[int, ndarray[_DType]] = ...,\n        p: Union[float, ndarray[_DType]] = ...,\n        size: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...  # Draw samples from a binomial distribution.\n    def chisquare(\n        self, df: Union[float, ndarray[_DType]] = ..., size: Optional[_ShapeType] = ...\n    ) -> ndarray[_DType]: ...  # Draw samples from a chi-square distribution.\n    def dirichlet(\n        self, alpha: Union[float, ndarray[_DType]] = ..., size: Optional[_ShapeType] = ...\n    ) -> ndarray[_DType]: ...  # Draw samples from the Dirichlet distribution.\n    def exponential(\n        self, scale: float, size: Optional[_ShapeType] = ...\n    ) -> ndarray[_DType]: ...  # Draw samples from an exponential distribution.\n    def f(\n        self,\n        dfnum: Union[float, ndarray[_DType]] = ...,\n        dfden: Union[float, ndarray[_DType]] = ...,\n        size: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...  # Draw samples from an F distribution.\n    def gamma(\n        self,\n        shape: Union[float, ndarray[_DType]] = ...,\n        scale: Union[float, ndarray[_DType]] = ...,\n        size: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...  # Draw samples from a Gamma distribution.\n    def geometric(\n        self, p: Union[float, ndarray[_DType]] = ..., size: Optional[_ShapeType] = ...\n    ) -> ndarray[_DType]: ...  # Draw samples from the geometric distribution.\n    def gumbel(\n        self,\n        loc: Union[float, ndarray[_DType]] = ...,\n        scale: Union[float, ndarray[_DType]] = ...,\n        size: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...  # Draw samples from a Gumbel distribution.\n    def hypergeometric(\n        self,\n        ngood: Union[int, ndarray[_DType]] = ...,\n        nbad: Union[int, ndarray[_DType]] = ...,\n        nsample: Union[int, ndarray[_DType]] = ...,\n        size: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...  # Draw samples from a Hypergeometric distribution.\n    def laplace(\n        self,\n        loc: Union[float, ndarray[_DType]] = ...,\n        scale: Union[float, ndarray[_DType]] = ...,\n        size: Optional[_ShapeType] = ...,\n    ) -> ndarray[\n        _DType\n    ]: ...  # Draw samples from the Laplace or double exponential distribution with specified location (or mean) and scale (decay).\n    def logistic(\n        self,\n        loc: Union[float, ndarray[_DType]] = ...,\n        scale: Union[float, ndarray[_DType]] = ...,\n        size: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...  # Draw samples from a logistic distribution.\n    def lognormal(\n        self,\n        mean: Union[float, ndarray[_DType]] = ...,\n        sigma: Union[float, ndarray[_DType]] = ...,\n        size: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...  # Draw samples from a log-normal distribution.\n    def logseries(\n        self, p: Union[float, ndarray[_DType]] = ..., size: Optional[_ShapeType] = ...\n    ) -> ndarray[_DType]: ...  # Draw samples from a logarithmic series distribution.\n    def multimonial(\n        self,\n        n: Union[int, ndarray[_DType]] = ...,\n        pvals: ndarray[_DType] = ...,\n        size: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...  # Draw samples from a multinomial distribution.\n    def multivariate_hypergeometric(\n        self, colors: Sequence[int], nsample: int\n    ) -> ndarray[_DType]: ...  # Generate variates from a multivariate hypergeometric distribution.\n    def multivariate_normal(\n        self,\n        mean: ndarray[_DType] = ...,\n        cov: ndarray[_DType] = ...,\n        size: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...  # Draw samples from a multivariate normal distribution.\n    def negative_binomial(\n        self,\n        n: Union[float, ndarray[_DType]] = ...,\n        p: Union[float, ndarray[_DType]] = ...,\n        size: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...  # Draw samples from a negative binomial distribution.\n    def noncentral_chisquare(\n        self,\n        df: Union[float, ndarray[_DType]] = ...,\n        nonc: Union[float, ndarray[_DType]] = ...,\n        size: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...  # Draw samples from a noncentral chi-square distribution.\n    def noncentral_f(\n        self,\n        dfnum: Union[float, ndarray[_DType]] = ...,\n        dfden: Union[float, ndarray[_DType]] = ...,\n        nonc: Union[float, ndarray[_DType]] = ...,\n        size: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...  # Draw samples from the noncentral F distribution.\n    def pareto(\n        self, a: Union[float, ndarray[_DType]] = ..., size: Optional[_ShapeType] = ...\n    ) -> ndarray[\n        _DType\n    ]: ...  # Draw samples from a Pareto II or Lomax distribution with specified shape.\n    def poisson(\n        self, lam: Union[float, ndarray[_DType]] = ..., size: Optional[_ShapeType] = ...\n    ) -> ndarray[_DType]: ...  # Draw samples from a Poisson distribution.\n    def power(\n        self, a: Union[float, ndarray[_DType]] = ..., size: Optional[_ShapeType] = ...\n    ) -> ndarray[\n        _DType\n    ]: ...  # Draws samples in [0, 1] from a power distribution with positive exponent a - 1.\n    def rayleigh(\n        self, scale: Union[float, ndarray[_DType]] = ..., size: Optional[_ShapeType] = ...\n    ) -> ndarray[_DType]: ...  # Draw samples from a Rayleigh distribution.\n    def standard_cauchy(\n        self, size: Optional[_ShapeType] = ...\n    ) -> ndarray[_DType]: ...  # Draw samples from a standard Cauchy distribution with mode = 0.\n    def standard_exponential(\n        self,\n        size: Union[int, ndarray[_DType]] = ...,\n        dtype: Optional[_DType] = ...,\n        method: Optional[Literal[\"inv\", \"zig\"]] = ...,\n        out: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...  # Draw samples from the standard exponential distribution.\n    def standard_gamma(\n        self,\n        shape: Union[float, ndarray[_DType]] = ...,\n        size: Union[float, ndarray[_DType]] = ...,\n        dtype: Optional[_DType] = ...,\n        out: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...  # Draw samples from a standard Gamma distribution.\n    def standard_normal(\n        self,\n        size: Union[int, ndarray[_DType]] = ...,\n        dtype: Optional[_DType] = ...,\n        out: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...  # Draw samples from a standard Normal distribution (mean=0, stdev=1).\n    def standard_t(\n        self, df: Union[float, ndarray[_DType]] = ..., size: Optional[_ShapeType] = ...\n    ) -> ndarray[\n        _DType\n    ]: ...  # Draw samples from a standard Student\u2019s t distribution with df degrees of freedom.\n    def triangular(\n        self,\n        left: Union[float, ndarray[_DType]] = ...,\n        mode: Union[float, ndarray[_DType]] = ...,\n        right: Union[float, ndarray[_DType]] = ...,\n        size: Optional[_ShapeType] = ...,\n    ) -> ndarray[\n        _DType\n    ]: ...  # Draw samples from the triangular distribution over the interval [left, right].\n    def uniform(\n        self,\n        low: Union[float, ndarray[_DType]] = ...,\n        high: Union[float, ndarray[_DType]] = ...,\n        size: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...  # Draw samples from a uniform distribution.\n    def vonmises(\n        self,\n        mu: Union[float, ndarray[_DType]] = ...,\n        kappa: Union[float, ndarray[_DType]] = ...,\n        size: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...  # Draw samples from a von Mises distribution.\n    def wald(\n        self,\n        mean: Union[float, ndarray[_DType]] = ...,\n        scale: Union[float, ndarray[_DType]] = ...,\n        size: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...  # Draw samples from a Wald, or inverse Gaussian, distribution.\n    def weibull(\n        self, a: Union[float, ndarray[_DType]] = ..., size: Optional[_ShapeType] = ...\n    ) -> ndarray[_DType]: ...  # Draw samples from a Weibull distribution.\n    def zipf(\n        self, a: Union[float, ndarray[_DType]] = ..., size: Optional[_ShapeType] = ...\n    ) -> ndarray[_DType]: ...  # Draw samples from a Zipf distribution.\n\nclass RandomState:\n    def __init__(self, seed: int = ...): ...\n    def multivariate_normal(\n        self,\n        mean: ndarray[_DType] = ...,\n        cov: ndarray[_DType] = ...,\n        size: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...\n    def normal(\n        self,\n        loc: Union[float, ndarray[_DType]] = ...,\n        scale: Union[float, ndarray[_DType]] = ...,\n        size: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...\n    def permutation(self, size: int) -> ndarray[int64]: ...\n    def shuffle(self, x: ndarray) -> None: ...\n    def uniform(self, size: _ShapeType) -> ndarray: ...\n    @overload\n    def choice(self, a: _IntLike) -> _IntLike: ...\n    @overload\n    def choice(self, a: _Int, size: int) -> ndarray[_Int]: ...\n    @overload\n    def choice(self, a: int, size: int) -> ndarray[int64]: ...\n    @overload\n    def choice(self, a: _IntLike, size: _IntLike, replace: bool) -> ndarray[int64]: ...\n    @overload\n    def choice(\n        self, a: List[_T], p: Union[List[_FloatLike], ndarray[_Float]] = ..., replace: bool = ...\n    ) -> _T: ...\n    @overload\n    def choice(\n        self,\n        a: range,\n        size: _IntLike,\n        replace: bool = ...,\n        p: Union[List[_FloatLike], ndarray[_Float]] = ...,\n    ) -> ndarray[int64]: ...\n    @overload\n    def choice(\n        self, a: range, *, replace: bool = ..., p: Union[List[_FloatLike], ndarray[_Float]] = ...\n    ) -> int64: ...\n    @overload\n    def choice(\n        self,\n        a: ndarray[_DType],\n        size: _IntLike,\n        replace: bool = ...,\n        p: Union[List[_FloatLike], ndarray[_Float]] = ...,\n    ) -> ndarray[_DType]: ...\n    @overload\n    def choice(\n        self,\n        a: ndarray[_DType],\n        *,\n        replace: bool = ...,\n        p: Union[List[_FloatLike], ndarray[_Float]] = ...,\n    ) -> _DType: ...\n",
    "/typeshed/numpy/testing.pyi": "from typing import overload\n\nfrom . import ndarray\n\ndef assert_allclose(\n    actual: ndarray, desired: ndarray, rtol: float = ..., atol: float = ...\n) -> None: ...\ndef assert_array_equal(actual: ndarray, desired: ndarray) -> None: ...\n@overload\ndef assert_almost_equal(actual: ndarray, desired: ndarray, decimal: float) -> None: ...\n@overload\ndef assert_almost_equal(actual: float, desired: float, decimal: float) -> None: ...\n",
    "/typeshed/matplotlib/__init__.pyi": "from . import collections, color, cm, pyplot, style, artist, legend\n\ndef use(backend: str) -> None: ...\n",
    "/typeshed/matplotlib/artist.pyi": "class Artist:\n    def set_label(self, s: str) -> None: ...\n    def remove(self) -> None: ...\n\nclass Line2D(Artist): ...\nclass Collection(Artist): ...\nclass LineCollection(Collection): ...\nclass Patch(Artist): ...\nclass Rectangle(Patch): ...\n",
    "/typeshed/matplotlib/axes.pyi": "from typing import Union, Sequence, Tuple, List, Optional, TypeVar\nfrom typing_extensions import Literal\n\nimport numpy as _np\n\nfrom .artist import Artist, Line2D, LineCollection, Rectangle\nfrom .collections import PolyCollection, PathCollection\nfrom .color import Normalize\nfrom .pyplot import Figure\nfrom .legend import Legend\nfrom .pyplot import Data, NumericArray\nfrom .image import AxesImage\nfrom .text import Text\n\n_Float = TypeVar(\"_Float\", _np.float32, _np.float64)\n\n_LegendLocation = Literal[\n    \"best\",\n    \"upper right\",\n    \"upper left\",\n    \"lower left\",\n    \"lower right\",\n    \"center left\",\n    \"center right\",\n    \"lower center\",\n    \"upper center\",\n    \"center\",\n]\n\nclass Axes:\n    title: Text\n    def axvline(\n        self,\n        x: float = ...,\n        ymin: float = ...,\n        ymax: float = ...,\n        color: str = ...,\n        linestyle: Literal[\"-\", \"--\", \"-.\", \":\", \"\"] = ...,\n    ) -> Line2D: ...\n    def set_xlabel(self, xlabel: str) -> None: ...\n    def set_ylabel(self, ylabel: str) -> None: ...\n    def set_title(self, label: str, loc: Literal[\"left\", \"center\", \"right\"] = ...) -> None: ...\n    def set_xticks(self, ticks: Union[_np.ndarray[_Float], Sequence[float]]) -> None: ...\n    def set_yticks(self, ticks: Union[_np.ndarray[_Float], Sequence[float]]) -> None: ...\n    def set_xticklabels(self, labels: List[str]) -> Text: ...\n    def set_yticklabels(self, labels: List[str]) -> Text: ...\n    def grid(\n        self,\n        b: Optional[bool] = ...,\n        which: Literal[\"major\", \"minor\", \"both\"] = ...,\n        axis: Literal[\"both\", \"x\", \"y\"] = ...,\n    ) -> None: ...\n    def get_legend_handles_labels(\n        self,\n    ) -> Tuple[List[Union[Artist, Tuple[Artist, ...]]], List[str]]: ...\n    def get_figure(self) -> Figure: ...\n    def legend(\n        self,\n        handles: Sequence[Union[Artist, Tuple[Artist, ...]]] = ...,\n        labels: Sequence[str] = ...,\n        loc: _LegendLocation = ...,\n        bbox_to_anchor: Tuple[float, float] = ...,\n    ) -> Legend: ...\n    def errorbar(\n        self,\n        x: Data,\n        y: Data,\n        *,\n        barsabove: bool = ...,\n        capsize: float = ...,\n        capthick: float = ...,\n        color: Optional[str] = ...,\n        ecolor: str = ...,\n        elinewidth: float = ...,\n        errorevery: int = ...,\n        label: str = ...,\n        linestyle: Literal[\"-\", \"--\", \"-.\", \":\", \"\"] = ...,\n        lolims: bool = ...,\n        marker: str = ...,\n        markersize: float = ...,\n        uplims: bool = ...,\n        xerr: Optional[Data] = ...,\n        xlolims: bool = ...,\n        xuplims: bool = ...,\n        yerr: Optional[Data] = ...,\n        zorder: float = ...,\n    ) -> Tuple[Line2D, Line2D, LineCollection]: ...\n    def bar(\n        self,\n        x: Data,\n        height: Data,\n        width: Data = ...,\n        bottom: Data = ...,\n        *,\n        align: Literal[\"center\", \"edge\"] = ...,\n        color: Optional[str] = ...,\n        edgecolor: str = ...,\n        hatch: str = ...,\n        label: str = ...,\n        linewidth: float = ...,\n        zorder: float = ...,\n    ) -> Tuple[Rectangle, ...]: ...\n    def imshow(\n        self, X: Data, cmap: str = ..., vmin: float = ..., vmax: float = ...\n    ) -> AxesImage: ...\n    def hist(\n        self, x: Data, bins: Union[int, Sequence[float], _np.ndarray[_Float]]\n    ) -> Tuple[List[_np.ndarray], _np.ndarray, List]: ...\n    def plot(\n        self,\n        x: Data,\n        y: Data,\n        *,\n        color: Optional[str] = ...,\n        label: str = ...,\n        linestyle: Literal[\"-\", \"--\", \"-.\", \":\", \"\"] = ...,\n        marker: str = ...,\n        markerfacecolor: str = ...,\n        markersize: float = ...,\n        scalex: bool = ...,\n        scaley: bool = ...,\n        zorder: float = ...,\n    ) -> None: ...\n    def scatter(\n        self,\n        x: Data,\n        y: Data,\n        s: Optional[Union[float, Optional[NumericArray]]] = ...,\n        c: Optional[str] = ...,\n        cmap: Optional[str] = ...,\n        norm: Optional[Normalize] = ...,\n        vmin: Optional[float] = ...,\n        vmax: Optional[float] = ...,\n        marker: Optional[str] = ...,\n        alpha: Optional[float] = ...,\n        linewidths: Optional[float] = ...,\n        verts: Optional[List[Tuple]] = ...,\n        edgecolors: Optional[Union[Literal[\"face\", \"none\"], str, Sequence[str]]] = ...,\n        *,\n        plotnonfinite: bool = ...,\n        data: Optional[Data] = ...,\n        label: str = ...,\n    ) -> PathCollection: ...\n    def set_xlim(\n        self, xmin: float = ..., xmax: float = ..., auto: Optional[bool] = ...\n    ) -> None: ...\n    def set_ylim(\n        self, ymin: float = ..., ymax: float = ..., auto: Optional[bool] = ...\n    ) -> None: ...\n    def vlines(\n        self,\n        x: Union[_Float, NumericArray],\n        ymin: Union[_Float, NumericArray],\n        ymax: Union[_Float, NumericArray],\n        colors: Union[str, Union[List[str], Tuple[str]]] = ...,\n        linestyles: Literal[\"-\", \"--\", \"-.\", \":\", \"\"] = ...,\n    ) -> LineCollection: ...\n\nclass SubplotBase(Axes):\n    def is_first_col(self) -> bool: ...\n    def is_first_row(self) -> bool: ...\n    def is_last_row(self) -> bool: ...\n    def is_last_col(self) -> bool: ...\n",
    "/typeshed/matplotlib/backend_bases.pyi": "from typing import Optional\n\nclass Event: ...\nclass LocationEvent(Event): ...\nclass MouseEvent(LocationEvent): ...\n\nclass KeyEvent(Event):\n    key: Optional[str]\n",
    "/typeshed/matplotlib/cm.pyi": "class ScalarMappable: ...\n",
    "/typeshed/matplotlib/collections.pyi": "from .artist import Artist\nfrom .cm import ScalarMappable\n\nclass Collection(Artist, ScalarMappable): ...\nclass _CollectionWithSizes(Collection): ...\nclass PolyCollection(_CollectionWithSizes): ...\nclass PathCollection(_CollectionWithSizes): ...\n",
    "/typeshed/matplotlib/color.pyi": "class Normalize: ...\n",
    "/typeshed/matplotlib/font_manager.pyi": "class FontProperties: ...\n",
    "/typeshed/matplotlib/image.pyi": "class AxesImage: ...\n",
    "/typeshed/matplotlib/legend.pyi": "from .artist import Artist\n\nclass Legend(Artist):\n    def set_title(self, title: str) -> None: ...\n",
    "/typeshed/matplotlib/patheffects.pyi": "class AbstractPathEffect: ...\n",
    "/typeshed/matplotlib/style.pyi": "def use(style: str) -> None: ...\n",
    "/typeshed/matplotlib/text.pyi": "from typing import Optional\n\nfrom .artist import Artist\n\nclass Text(Artist):\n    def get_text(self) -> str: ...\n    def set_color(self, color: str) -> None: ...\n    def set_text(self, s: Optional[str]) -> None: ...\n",
    "/typeshed/matplotlib/transforms.pyi": "class TransformNode: ...\nclass Transform(TransformNode): ...\nclass BboxBase(TransformNode): ...\nclass Bbox(BboxBase): ...\n",
    "/typeshed/six/__init__.pyi": "import builtins\nimport operator\nimport types\nimport unittest\nfrom _typeshed import IdentityFunction, Unused, _KT_contra, _VT_co\nfrom builtins import next as next\nfrom collections.abc import Callable, ItemsView, Iterable, Iterator as _Iterator, KeysView, Mapping, ValuesView\nfrom functools import wraps as wraps\nfrom importlib.util import spec_from_loader as spec_from_loader\nfrom io import BytesIO as BytesIO, StringIO as StringIO\nfrom re import Pattern\nfrom typing import Any, AnyStr, Literal, NoReturn, Protocol, TypeVar, overload\n\nfrom six import moves as moves\n\n# TODO: We should switch to the _typeshed version of SupportsGetItem\n# once mypy updates its vendored copy of typeshed and makes a new release\nclass _SupportsGetItem(Protocol[_KT_contra, _VT_co]):\n    def __contains__(self, __x: Any) -> bool: ...\n    def __getitem__(self, __key: _KT_contra) -> _VT_co: ...\n\n_T = TypeVar(\"_T\")\n_K = TypeVar(\"_K\")\n_V = TypeVar(\"_V\")\n\n__author__: str\n__version__: str\n\nPY2: Literal[False]\nPY3: Literal[True]\nPY34: Literal[True]\n\nstring_types: tuple[type[str]]\ninteger_types: tuple[type[int]]\nclass_types: tuple[type[type]]\ntext_type = str\nbinary_type = bytes\n\nMAXSIZE: int\n\ncallable = builtins.callable\n\ndef get_unbound_function(unbound: types.FunctionType) -> types.FunctionType: ...\n\ncreate_bound_method = types.MethodType\n\ndef create_unbound_method(func: types.FunctionType, cls: type) -> types.FunctionType: ...\n\nIterator = object\n\ndef get_method_function(meth: types.MethodType) -> types.FunctionType: ...\ndef get_method_self(meth: types.MethodType) -> object: ...\ndef get_function_closure(fun: types.FunctionType) -> tuple[types._Cell, ...] | None: ...\ndef get_function_code(fun: types.FunctionType) -> types.CodeType: ...\ndef get_function_defaults(fun: types.FunctionType) -> tuple[Any, ...] | None: ...\ndef get_function_globals(fun: types.FunctionType) -> dict[str, Any]: ...\ndef iterkeys(d: Mapping[_K, Any]) -> _Iterator[_K]: ...\ndef itervalues(d: Mapping[Any, _V]) -> _Iterator[_V]: ...\ndef iteritems(d: Mapping[_K, _V]) -> _Iterator[tuple[_K, _V]]: ...\ndef viewkeys(d: Mapping[_K, Any]) -> KeysView[_K]: ...\ndef viewvalues(d: Mapping[Any, _V]) -> ValuesView[_V]: ...\ndef viewitems(d: Mapping[_K, _V]) -> ItemsView[_K, _V]: ...\ndef b(s: str) -> bytes: ...\ndef u(s: str) -> str: ...\n\nunichr = chr\n\ndef int2byte(i: int) -> bytes: ...\n\n# Should be `byte2int: operator.itemgetter[int]`. But a bug in mypy prevents using TypeVar in itemgetter.__call__\ndef byte2int(obj: _SupportsGetItem[int, _T]) -> _T: ...\n\nindexbytes = operator.getitem\niterbytes = iter\n\ndef assertCountEqual(self: unittest.TestCase, first: Iterable[_T], second: Iterable[_T], msg: str | None = ...) -> None: ...\n@overload\ndef assertRaisesRegex(self: unittest.TestCase, msg: str | None = ...) -> Any: ...\n@overload\ndef assertRaisesRegex(self: unittest.TestCase, callable_obj: Callable[..., object], *args: Any, **kwargs: Any) -> Any: ...\ndef assertRegex(self: unittest.TestCase, text: AnyStr, expected_regex: AnyStr | Pattern[AnyStr], msg: Any = ...) -> None: ...\ndef assertNotRegex(self: unittest.TestCase, text: AnyStr, expected_regex: AnyStr | Pattern[AnyStr], msg: Any = ...) -> None: ...\n\nexec_ = exec\n\ndef reraise(tp: type[BaseException] | None, value: BaseException | None, tb: types.TracebackType | None = None) -> NoReturn: ...\ndef raise_from(value: BaseException | type[BaseException], from_value: BaseException | None) -> NoReturn: ...\n\nprint_ = print\n\ndef with_metaclass(meta: type, *bases: type) -> type: ...\ndef add_metaclass(metaclass: type) -> IdentityFunction: ...\ndef ensure_binary(s: bytes | str, encoding: str = \"utf-8\", errors: str = \"strict\") -> bytes: ...\ndef ensure_str(s: bytes | str, encoding: str = \"utf-8\", errors: str = \"strict\") -> str: ...\ndef ensure_text(s: bytes | str, encoding: str = \"utf-8\", errors: str = \"strict\") -> str: ...\ndef python_2_unicode_compatible(klass: _T) -> _T: ...\n\nclass _LazyDescr:\n    name: str\n    def __init__(self, name: str) -> None: ...\n    def __get__(self, obj: object, tp: Unused) -> Any: ...\n\nclass MovedModule(_LazyDescr):\n    mod: str\n    def __init__(self, name: str, old: str, new: str | None = None) -> None: ...\n    def __getattr__(self, attr: str) -> Any: ...\n\nclass MovedAttribute(_LazyDescr):\n    mod: str\n    attr: str\n    def __init__(\n        self, name: str, old_mod: str, new_mod: str, old_attr: str | None = None, new_attr: str | None = None\n    ) -> None: ...\n\ndef add_move(move: MovedModule | MovedAttribute) -> None: ...\ndef remove_move(name: str) -> None: ...\n",
    "/typeshed/six/moves/BaseHTTPServer.pyi": "from http.server import *\n",
    "/typeshed/six/moves/CGIHTTPServer.pyi": "from http.server import *\n",
    "/typeshed/six/moves/SimpleHTTPServer.pyi": "from http.server import *\n",
    "/typeshed/six/moves/__init__.pyi": "# Stubs for six.moves\n#\n# Note: Commented out items means they weren't implemented at the time.\n# Uncomment them when the modules have been added to the typeshed.\nimport importlib\nimport shlex\nfrom builtins import filter as filter, input as input, map as map, range as range, zip as zip\nfrom collections import UserDict as UserDict, UserList as UserList, UserString as UserString\nfrom functools import reduce as reduce\nfrom io import StringIO as StringIO\nfrom itertools import filterfalse as filterfalse, zip_longest as zip_longest\nfrom os import getcwd as getcwd, getcwdb as getcwdb\nfrom sys import intern as intern\n\n# import tkinter.font as tkinter_font\n# import tkinter.messagebox as tkinter_messagebox\n# import tkinter.simpledialog as tkinter_tksimpledialog\n# import tkinter.dnd as tkinter_dnd\n# import tkinter.colorchooser as tkinter_colorchooser\n# import tkinter.scrolledtext as tkinter_scrolledtext\n# import tkinter.simpledialog as tkinter_simpledialog\n# import tkinter.tix as tkinter_tix\n# import dbm.gnu as dbm_gnu\nfrom . import (\n    BaseHTTPServer as BaseHTTPServer,\n    CGIHTTPServer as CGIHTTPServer,\n    SimpleHTTPServer as SimpleHTTPServer,\n    _dummy_thread as _dummy_thread,\n    _thread as _thread,\n    builtins as builtins,\n    configparser as configparser,\n    copyreg as copyreg,\n    cPickle as cPickle,\n    email_mime_base as email_mime_base,\n    email_mime_multipart as email_mime_multipart,\n    email_mime_nonmultipart as email_mime_nonmultipart,\n    email_mime_text as email_mime_text,\n    html_entities as html_entities,\n    html_parser as html_parser,\n    http_client as http_client,\n    http_cookiejar as http_cookiejar,\n    http_cookies as http_cookies,\n    queue as queue,\n    reprlib as reprlib,\n    socketserver as socketserver,\n    tkinter as tkinter,\n    tkinter_commondialog as tkinter_commondialog,\n    tkinter_constants as tkinter_constants,\n    tkinter_dialog as tkinter_dialog,\n    tkinter_filedialog as tkinter_filedialog,\n    tkinter_tkfiledialog as tkinter_tkfiledialog,\n    tkinter_ttk as tkinter_ttk,\n    urllib as urllib,\n    urllib_error as urllib_error,\n    urllib_parse as urllib_parse,\n    urllib_robotparser as urllib_robotparser,\n)\n\n# import xmlrpc.client as xmlrpc_client\n# import xmlrpc.server as xmlrpc_server\n\nxrange = range\nreload_module = importlib.reload\ncStringIO = StringIO\nshlex_quote = shlex.quote\n",
    "/typeshed/six/moves/_dummy_thread.pyi": "import sys\n\nif sys.version_info >= (3, 9):\n    from _thread import *\nelse:\n    from _dummy_thread import *\n",
    "/typeshed/six/moves/_thread.pyi": "from _thread import *\n",
    "/typeshed/six/moves/builtins.pyi": "from builtins import *\n",
    "/typeshed/six/moves/cPickle.pyi": "from pickle import *\n",
    "/typeshed/six/moves/collections_abc.pyi": "from collections.abc import *\n",
    "/typeshed/six/moves/configparser.pyi": "# Error is not included in __all__ so export it explicitly\nfrom configparser import *\nfrom configparser import Error as Error\n",
    "/typeshed/six/moves/copyreg.pyi": "from copyreg import *\n",
    "/typeshed/six/moves/email_mime_base.pyi": "from email.mime.base import *\n",
    "/typeshed/six/moves/email_mime_multipart.pyi": "from email.mime.multipart import *\n",
    "/typeshed/six/moves/email_mime_nonmultipart.pyi": "from email.mime.nonmultipart import *\n",
    "/typeshed/six/moves/email_mime_text.pyi": "from email.mime.text import *\n",
    "/typeshed/six/moves/html_entities.pyi": "from html.entities import *\n",
    "/typeshed/six/moves/html_parser.pyi": "from html.parser import *\n",
    "/typeshed/six/moves/http_client.pyi": "# Many definitions are not included in http.client.__all__\nfrom http.client import *\nfrom http.client import (\n    ACCEPTED as ACCEPTED,\n    BAD_GATEWAY as BAD_GATEWAY,\n    BAD_REQUEST as BAD_REQUEST,\n    CONFLICT as CONFLICT,\n    CONTINUE as CONTINUE,\n    CREATED as CREATED,\n    EXPECTATION_FAILED as EXPECTATION_FAILED,\n    FAILED_DEPENDENCY as FAILED_DEPENDENCY,\n    FORBIDDEN as FORBIDDEN,\n    FOUND as FOUND,\n    GATEWAY_TIMEOUT as GATEWAY_TIMEOUT,\n    GONE as GONE,\n    HTTP_PORT as HTTP_PORT,\n    HTTP_VERSION_NOT_SUPPORTED as HTTP_VERSION_NOT_SUPPORTED,\n    HTTPS_PORT as HTTPS_PORT,\n    IM_USED as IM_USED,\n    INSUFFICIENT_STORAGE as INSUFFICIENT_STORAGE,\n    INTERNAL_SERVER_ERROR as INTERNAL_SERVER_ERROR,\n    LENGTH_REQUIRED as LENGTH_REQUIRED,\n    LOCKED as LOCKED,\n    METHOD_NOT_ALLOWED as METHOD_NOT_ALLOWED,\n    MOVED_PERMANENTLY as MOVED_PERMANENTLY,\n    MULTI_STATUS as MULTI_STATUS,\n    MULTIPLE_CHOICES as MULTIPLE_CHOICES,\n    NETWORK_AUTHENTICATION_REQUIRED as NETWORK_AUTHENTICATION_REQUIRED,\n    NO_CONTENT as NO_CONTENT,\n    NON_AUTHORITATIVE_INFORMATION as NON_AUTHORITATIVE_INFORMATION,\n    NOT_ACCEPTABLE as NOT_ACCEPTABLE,\n    NOT_EXTENDED as NOT_EXTENDED,\n    NOT_FOUND as NOT_FOUND,\n    NOT_IMPLEMENTED as NOT_IMPLEMENTED,\n    NOT_MODIFIED as NOT_MODIFIED,\n    OK as OK,\n    PARTIAL_CONTENT as PARTIAL_CONTENT,\n    PAYMENT_REQUIRED as PAYMENT_REQUIRED,\n    PRECONDITION_FAILED as PRECONDITION_FAILED,\n    PRECONDITION_REQUIRED as PRECONDITION_REQUIRED,\n    PROCESSING as PROCESSING,\n    PROXY_AUTHENTICATION_REQUIRED as PROXY_AUTHENTICATION_REQUIRED,\n    REQUEST_ENTITY_TOO_LARGE as REQUEST_ENTITY_TOO_LARGE,\n    REQUEST_HEADER_FIELDS_TOO_LARGE as REQUEST_HEADER_FIELDS_TOO_LARGE,\n    REQUEST_TIMEOUT as REQUEST_TIMEOUT,\n    REQUEST_URI_TOO_LONG as REQUEST_URI_TOO_LONG,\n    REQUESTED_RANGE_NOT_SATISFIABLE as REQUESTED_RANGE_NOT_SATISFIABLE,\n    RESET_CONTENT as RESET_CONTENT,\n    SEE_OTHER as SEE_OTHER,\n    SERVICE_UNAVAILABLE as SERVICE_UNAVAILABLE,\n    SWITCHING_PROTOCOLS as SWITCHING_PROTOCOLS,\n    TEMPORARY_REDIRECT as TEMPORARY_REDIRECT,\n    TOO_MANY_REQUESTS as TOO_MANY_REQUESTS,\n    UNAUTHORIZED as UNAUTHORIZED,\n    UNPROCESSABLE_ENTITY as UNPROCESSABLE_ENTITY,\n    UNSUPPORTED_MEDIA_TYPE as UNSUPPORTED_MEDIA_TYPE,\n    UPGRADE_REQUIRED as UPGRADE_REQUIRED,\n    USE_PROXY as USE_PROXY,\n    HTTPMessage as HTTPMessage,\n    parse_headers as parse_headers,\n)\n",
    "/typeshed/six/moves/http_cookiejar.pyi": "from http.cookiejar import *\n",
    "/typeshed/six/moves/http_cookies.pyi": "# Morsel is not included in __all__ so export it explicitly\nfrom http.cookies import *\nfrom http.cookies import Morsel as Morsel\n",
    "/typeshed/six/moves/queue.pyi": "from queue import *\n",
    "/typeshed/six/moves/reprlib.pyi": "from reprlib import *\n",
    "/typeshed/six/moves/socketserver.pyi": "from socketserver import *\n",
    "/typeshed/six/moves/tkinter.pyi": "from tkinter import *\n",
    "/typeshed/six/moves/tkinter_commondialog.pyi": "from tkinter.commondialog import *\n",
    "/typeshed/six/moves/tkinter_constants.pyi": "from tkinter.constants import *\n",
    "/typeshed/six/moves/tkinter_dialog.pyi": "from tkinter.dialog import *\n",
    "/typeshed/six/moves/tkinter_filedialog.pyi": "from tkinter.filedialog import *\n",
    "/typeshed/six/moves/tkinter_tkfiledialog.pyi": "from tkinter.filedialog import *\n",
    "/typeshed/six/moves/tkinter_ttk.pyi": "from tkinter.ttk import *\n",
    "/typeshed/six/moves/urllib_error.pyi": "from urllib.error import *\n",
    "/typeshed/six/moves/urllib_parse.pyi": "from urllib.parse import *\n",
    "/typeshed/six/moves/urllib_request.pyi": "from .urllib.request import *\n",
    "/typeshed/six/moves/urllib_response.pyi": "from .urllib.response import *\n",
    "/typeshed/six/moves/urllib_robotparser.pyi": "from urllib.robotparser import *\n",
    "/typeshed/six/moves/urllib/__init__.pyi": "from six.moves.urllib import error as error, parse as parse, request as request, response as response, robotparser as robotparser\n",
    "/typeshed/six/moves/urllib/error.pyi": "from urllib.error import ContentTooShortError as ContentTooShortError, HTTPError as HTTPError, URLError as URLError\n",
    "/typeshed/six/moves/urllib/parse.pyi": "# Stubs for six.moves.urllib.parse\n#\n# Note: Commented out items means they weren't implemented at the time.\n# Uncomment them when the modules have been added to the typeshed.\n# from urllib.parse import splitquery as splitquery\n# from urllib.parse import splittag as splittag\n# from urllib.parse import splituser as splituser\nfrom urllib.parse import (\n    ParseResult as ParseResult,\n    SplitResult as SplitResult,\n    parse_qs as parse_qs,\n    parse_qsl as parse_qsl,\n    quote as quote,\n    quote_plus as quote_plus,\n    unquote as unquote,\n    unquote_plus as unquote_plus,\n    unquote_to_bytes as unquote_to_bytes,\n    urldefrag as urldefrag,\n    urlencode as urlencode,\n    urljoin as urljoin,\n    urlparse as urlparse,\n    urlsplit as urlsplit,\n    urlunparse as urlunparse,\n    urlunsplit as urlunsplit,\n    uses_fragment as uses_fragment,\n    uses_netloc as uses_netloc,\n    uses_params as uses_params,\n    uses_query as uses_query,\n    uses_relative as uses_relative,\n)\n",
    "/typeshed/six/moves/urllib/request.pyi": "# Stubs for six.moves.urllib.request\n#\n# Note: Commented out items means they weren't implemented at the time.\n# Uncomment them when the modules have been added to the typeshed.\n# from urllib.request import proxy_bypass as proxy_bypass\nfrom urllib.request import (\n    AbstractBasicAuthHandler as AbstractBasicAuthHandler,\n    AbstractDigestAuthHandler as AbstractDigestAuthHandler,\n    BaseHandler as BaseHandler,\n    CacheFTPHandler as CacheFTPHandler,\n    FancyURLopener as FancyURLopener,\n    FileHandler as FileHandler,\n    FTPHandler as FTPHandler,\n    HTTPBasicAuthHandler as HTTPBasicAuthHandler,\n    HTTPCookieProcessor as HTTPCookieProcessor,\n    HTTPDefaultErrorHandler as HTTPDefaultErrorHandler,\n    HTTPDigestAuthHandler as HTTPDigestAuthHandler,\n    HTTPErrorProcessor as HTTPErrorProcessor,\n    HTTPHandler as HTTPHandler,\n    HTTPPasswordMgr as HTTPPasswordMgr,\n    HTTPPasswordMgrWithDefaultRealm as HTTPPasswordMgrWithDefaultRealm,\n    HTTPRedirectHandler as HTTPRedirectHandler,\n    HTTPSHandler as HTTPSHandler,\n    OpenerDirector as OpenerDirector,\n    ProxyBasicAuthHandler as ProxyBasicAuthHandler,\n    ProxyDigestAuthHandler as ProxyDigestAuthHandler,\n    ProxyHandler as ProxyHandler,\n    Request as Request,\n    UnknownHandler as UnknownHandler,\n    URLopener as URLopener,\n    build_opener as build_opener,\n    getproxies as getproxies,\n    install_opener as install_opener,\n    parse_http_list as parse_http_list,\n    parse_keqv_list as parse_keqv_list,\n    pathname2url as pathname2url,\n    url2pathname as url2pathname,\n    urlcleanup as urlcleanup,\n    urlopen as urlopen,\n    urlretrieve as urlretrieve,\n)\n",
    "/typeshed/six/moves/urllib/response.pyi": "# Stubs for six.moves.urllib.response\n#\n# Note: Commented out items means they weren't implemented at the time.\n# Uncomment them when the modules have been added to the typeshed.\n# from urllib.response import addbase as addbase\n# from urllib.response import addclosehook as addclosehook\n# from urllib.response import addinfo as addinfo\nfrom urllib.response import addinfourl as addinfourl\n",
    "/typeshed/six/moves/urllib/robotparser.pyi": "from urllib.robotparser import RobotFileParser as RobotFileParser\n",
    "/typeshed/pandas/__init__.pyi": "\"\"\"Pandas public API\"\"\"\nfrom pathlib import Path\nfrom typing import (\n    IO,\n    Any,\n    Callable,\n    Dict,\n    List,\n    Mapping,\n    Optional,\n    Sequence,\n    Tuple,\n    Type,\n    TypeVar,\n    Union,\n    overload,\n)\n\nimport numpy as _np\nfrom typing_extensions import Literal\n\nfrom . import testing\nfrom .core.arrays.integer import Int8Dtype as Int8Dtype\nfrom .core.arrays.integer import Int16Dtype as Int16Dtype\nfrom .core.arrays.integer import Int32Dtype as Int32Dtype\nfrom .core.arrays.integer import Int64Dtype as Int64Dtype\nfrom .core.arrays.integer import UInt8Dtype as UInt8Dtype\nfrom .core.arrays.integer import UInt16Dtype as UInt16Dtype\nfrom .core.arrays.integer import UInt32Dtype as UInt32Dtype\nfrom .core.arrays.integer import UInt64Dtype as UInt64Dtype\nfrom .core.frame import DataFrame as DataFrame\nfrom .core.frame import _AxisType, _ListLike\nfrom .core.indexes import Index as Index\nfrom .core.indexes import MultiIndex as MultiIndex\nfrom .core.series import Series as Series\n\ndef concat(\n    dataframes: Union[Sequence[DataFrame], Mapping[str, DataFrame]],\n    axis: _AxisType = ...,\n    sort: Optional[bool] = ...,\n    ignore_index: bool = ...,\n) -> DataFrame: ...\ndef cut(arr: _np.ndarray, bins: int) -> Tuple[Union[Series, _np.ndarray], _np.ndarray]: ...\ndef get_dummies(df: Union[DataFrame, Series], columns: Optional[_ListLike] = ...) -> DataFrame: ...\n@overload\ndef isna(obj: Union[float, str]) -> bool: ...\n@overload\ndef isna(obj: DataFrame) -> DataFrame: ...\n@overload\ndef isna(obj: Series) -> Series[bool]: ...\n@overload\ndef isna(obj: Union[Index, _np.ndarray]) -> _np.ndarray[_np.bool_]: ...\n@overload\ndef isnull(obj: Union[None, float, str]) -> bool: ...\n@overload\ndef isnull(obj: DataFrame) -> DataFrame: ...\n@overload\ndef isnull(obj: Series) -> Series[bool]: ...\n@overload\ndef isnull(obj: Union[Index, _np.ndarray]) -> _np.ndarray[_np.bool_]: ...\n@overload\ndef merge(left: DataFrame, right: DataFrame, on: str = ...) -> DataFrame: ...\n@overload\ndef merge(\n    left: DataFrame, right: DataFrame, left_on: str, right_on: str, how: str\n) -> DataFrame: ...\n@overload\ndef merge(\n    left: DataFrame, right: DataFrame, left_on: List[str], right_on: List[str], how: str\n) -> DataFrame: ...\n@overload\ndef merge(\n    left: DataFrame,\n    right: DataFrame,\n    left_index: bool = ...,\n    right_index: bool = ...,\n    how: str = ...,\n) -> DataFrame: ...\ndef read_parquet(\n    path: Union[str, Path, IO],\n    engine: Literal[\"auto\", \"pyarrow\", \"fastparquet\"] = ...,\n    columns: Optional[List[str]] = ...,\n    **kwargs: Any,\n) -> DataFrame: ...\ndef read_pickle(\n    path: Union[str, Path, IO],\n    compression: Optional[Literal[\"infer\", \"gzip\", \"bz2\", \"zip\", \"xz\"]] = ...,\n) -> DataFrame: ...\ndef read_csv(\n    filepath_or_buffer: Union[str, Path, IO],\n    sep: str = ...,\n    delimiter: Optional[str] = ...,  # only an alias to sep\n    header: Optional[Union[int, List[int], Literal[\"infer\"]]] = ...,\n    names: Optional[List[str]] = ...,\n    index_col: Optional[Union[str, int, List[str], Tuple[str, ...], Sequence[int], bool]] = ...,\n    usecols: Optional[Union[List[str], List[int], Callable]] = ...,\n    squeeze: bool = ...,\n    prefix: Optional[str] = ...,\n    mangle_dupe_cols: bool = ...,\n    dtype: Optional[Union[Type, str, Mapping[str, Union[str, Type]]]] = ...,\n    engine: Optional[Union[Literal[\"c\"], Literal[\"python\"]]] = ...,\n    converters: Dict[Union[str, int], Callable] = ...,\n    true_values: Optional[List] = ...,\n    false_values: Optional[List] = ...,\n    skipinitialspace: bool = ...,\n    skiprows: Optional[Union[int, _ListLike, Callable]] = ...,\n    skipfooter: int = ...,\n    nrows: Optional[int] = ...,\n    na_values: Optional[Union[str, List[str]]] = ...,\n    keep_default_na: bool = ...,\n    na_filter: bool = ...,\n    verbose: bool = ...,\n    skip_blank_line: bool = ...,\n    parse_dates: Union[bool, List[int], List[str], List[List[int]], Dict[str, List[int]]] = ...,\n    infer_datetime_format: bool = ...,\n    keep_date_col: bool = ...,\n    date_parser: Optional[Callable] = ...,\n    dayfirst: bool = ...,\n    cache_dates: bool = ...,\n    iterator: bool = ...,\n    chunksize: Optional[int] = ...,\n    compression: Optional[Literal[\"infer\", \"gzip\", \"bz3\", \"zip\", \"xz\"]] = ...,\n    thousands: Optional[str] = ...,\n    decimal: Optional[str] = ...,\n    lineterminator: Optional[str] = ...,\n    quotechar: Optional[str] = ...,\n    quoting: Optional[Literal[0, 1, 2, 3]] = ...,\n    doublequote: bool = ...,\n    escapechar: Optional[str] = ...,\n    comment: Optional[str] = ...,\n    encoding: Optional[str] = ...,\n    dialect: Any = ...,  # TODO str or csv.Dialect Optional\n    error_bad_lines: bool = ...,\n    warn_bad_lines: bool = ...,\n    delim_whitespace: bool = ...,\n    low_memory: bool = ...,\n    memory_map: bool = ...,\n    float_precision: Optional[str] = ...,\n) -> DataFrame: ...\ndef read_sql(\n    sql: Union[str, Any],\n    con: Union[str, Any] = ...,\n    index_col: Optional[Union[str, List[str]]] = ...,\n    coerce_float: bool = ...,\n    params: Optional[Union[List[str], Tuple[str, ...], Dict[str, str]]] = ...,\n    parse_dates: Optional[Union[List[str], Dict[str, str], Dict[str, Dict[str, Any]]]] = ...,\n    columns: List[str] = ...,\n    chunksize: int = ...,\n) -> DataFrame: ...\ndef read_feather(p: Union[Path, IO]) -> DataFrame: ...\ndef read_json(\n    path_or_buf: str = ...,\n    orient: Optional[Literal[\"split\", \"records\", \"index\", \"columns\", \"values\", \"table\"]] = ...,\n    typ: Literal[\"frame\", \"series\"] = ...,\n    dtype: Optional[Union[bool, Dict[str, str]]] = ...,\n    convert_axes: Optional[bool] = ...,\n    convert_dates: Optional[Union[bool, List[str]]] = ...,\n    keep_default_dates: Optional[bool] = ...,\n    numpy: Optional[bool] = ...,\n    precise_float: Optional[bool] = ...,\n    date_unit: Optional[str] = ...,\n    encoding: str = ...,\n    lines: bool = ...,\n    chunksize: Optional[int] = ...,\n    compression: Optional[Literal[\"infer\", \"gzip\", \"bz3\", \"zip\", \"xz\"]] = ...,\n    nrows: Optional[int] = ...,\n) -> Union[DataFrame, Series]: ...\ndef to_numeric(\n    arg: Union[int, float, List, Tuple, _np.ndarray, Series],\n    errors: Literal[\"ignore\", \"raise\", \"coerce\"] = ...,\n    downcast: Literal[\"integer\", \"signed\", \"unsigned\", \"float\"] = ...,\n) -> Union[Series, _np.ndarray]: ...\ndef unique(values: Series) -> _np.ndarray: ...\n",
    "/typeshed/pandas/testing.pyi": "from typing import Optional\n\nfrom .core.frame import DataFrame\nfrom .core.series import Series\nfrom .core.indexes import Index\n\ndef assert_frame_equal(\n    left: DataFrame,\n    right: DataFrame,\n    check_like: Optional[bool] = ...,\n    check_exact: Optional[bool] = ...,\n    check_dtype: bool = ...,\n) -> None: ...\ndef assert_index_equal(left: Index, right: Index) -> None: ...\ndef assert_series_equal(\n    left: Series, right: Series, check_names: bool = ..., check_dtype: bool = ...\n) -> None: ...\n",
    "/typeshed/pandas/core/__init__.pyi": "",
    "/typeshed/pandas/core/api.pyi": "from .arrays.integer import (\n    Int8Dtype,\n    Int16Dtype,\n    Int32Dtype,\n    Int64Dtype,\n    UInt8Dtype,\n    UInt16Dtype,\n    UInt32Dtype,\n    UInt64Dtype,\n)\n",
    "/typeshed/pandas/core/frame.pyi": "import sre_compile\nimport sys\nfrom pathlib import Path\nfrom typing import (\n    Any,\n    Callable,\n    Dict,\n    Hashable,\n    Iterable,\n    Iterator,\n    List,\n    Mapping,\n    NamedTuple,\n    Optional,\n    Pattern,\n    Sequence,\n    Tuple,\n    Type,\n    Union,\n    overload,\n)\n\nimport matplotlib\nimport numpy as _np\nfrom typing_extensions import Literal\n\nfrom .groupby.generic import DataFrameGroupBy\nfrom .indexes import Index\nfrom .indexing import _AtIndexerFrame, _iLocIndexerFrame, _LocIndexerFrame\nfrom .series import Series, _DTypeNp\n\n_str = str  # needed because Series has a property called \"str\"...\n\n_AxisType = Literal[\"columns\", \"index\", 0, 1]\n\n_ErrorType = Literal[\"raise\", \"ignore\"]\n\n_ListLike = Union[Series, Index, _np.ndarray, Sequence]\n\n_ColSubsetType = Union[Series, DataFrame, List[_str], _str, _np.ndarray[_np.str_]]\n\n_FunctionLike = Union[_str, Callable]\n\n_TypeLike = Union[_str, _np.dtype, Type[_np.void], Type[float], Type[_str]]\n\n_Label = Optional[Hashable]\n\n_Renamer = Union[Mapping[_Label, Any], Callable[[_Label], _Label]]\n\nclass DataFrame:\n    def __init__(\n        self,\n        data: Optional[Union[_ListLike, DataFrame, Dict[_str, _ListLike]]] = ...,\n        columns: Optional[_ListLike] = ...,\n        index: Optional[_ListLike] = ...,\n        dtype: Optional[_TypeLike] = ...,\n    ): ...\n    #\n    # magic methods\n    def __add__(self, other: float) -> DataFrame: ...\n    def __and__(self, other: DataFrame) -> DataFrame: ...\n    def __eq__(self, other: Union[float, Series, DataFrame]) -> DataFrame: ...  # type: ignore\n    def __floordiv__(self, other: float) -> DataFrame: ...\n    def __ge__(self, other: float) -> DataFrame: ...\n    def __getattr__(self, name: _str) -> Series: ...\n    @overload\n    def __getitem__(self, idx: _str) -> Series: ...\n    @overload\n    def __getitem__(\n        self, idx: Union[Series, DataFrame, List[_str], Index[_str], _np.ndarray[_np.str_]]\n    ) -> DataFrame: ...\n    def __gt__(self, other: float) -> DataFrame: ...\n    def __iter__(self) -> Iterator: ...\n    def __le__(self, other: float) -> DataFrame: ...\n    def __len__(self) -> int: ...\n    def __lt__(self, other: float) -> DataFrame: ...\n    def __mul__(self, other: float) -> DataFrame: ...\n    def __ne__(self, other: Union[float, Series, DataFrame]) -> DataFrame: ...  # type: ignore\n    def __or__(self, other: DataFrame) -> DataFrame: ...\n    def __radd__(self, other: float) -> DataFrame: ...\n    def __rsub__(self, other: float) -> DataFrame: ...\n    def __setitem__(self, key: Any, value: Any) -> None: ...\n    def __sub__(self, other: float) -> DataFrame: ...\n    #\n    # properties\n    @property\n    def columns(self) -> Index[_str]: ...\n    @columns.setter  # setter needs to be right next to getter; otherwise mypy complains\n    def columns(self, cols: Union[List[_str], Index[_str]]) -> None: ...\n    @property\n    def dtypes(self) -> Series: ...\n    @property\n    def iloc(self) -> _iLocIndexerFrame: ...\n    @property\n    def index(self) -> Index[int]: ...\n    @index.setter\n    def index(self, idx: Index) -> None: ...\n    @property\n    def loc(self) -> _LocIndexerFrame: ...\n    @property\n    def shape(self) -> Tuple[int, ...]: ...\n    @property\n    def size(self) -> int: ...\n    @property\n    def T(self) -> DataFrame: ...\n    # this function is deprecated:\n    @property\n    def values(self) -> _np.ndarray: ...\n    @property\n    def empty(self) -> bool: ...\n    #\n    # methods\n    @overload\n    def any(\n        self, axis: Optional[_AxisType] = ..., bool_only: Optional[bool] = ..., skipna: bool = ...\n    ) -> Series: ...\n    @overload\n    def any(\n        self,\n        level: int,\n        axis: Optional[_AxisType] = ...,\n        bool_only: Optional[bool] = ...,\n        skipna: bool = ...,\n    ) -> DataFrame: ...\n    def append(\n        self, s: Union[DataFrame, Dict[_str, Any]], ignore_index: bool = ..., sort: bool = ...\n    ) -> DataFrame: ...\n    def apply(\n        self, f: Callable[[Series], Any], axis: _AxisType = ...\n    ) -> Union[Series, DataFrame]: ...\n    def assign(self, **kwargs: Any) -> DataFrame: ...\n    def astype(\n        self,\n        dtype: Union[_TypeLike, Dict[Hashable, _TypeLike]],\n        copy: bool = ...,\n        errors: _ErrorType = ...,\n    ) -> DataFrame: ...\n    def copy(self, deep: bool = ...) -> DataFrame: ...\n    def corr(self, method: Optional[_str] = ..., min_periods: Optional[int] = ...) -> DataFrame: ...\n    def count(self) -> Series: ...\n    @overload\n    def drop(\n        self, labels: Union[_str, List[_str], Index], axis: _AxisType = ..., inplace: bool = ...\n    ) -> DataFrame: ...\n    @overload\n    def drop(self, *, index: Union[List[_str], Index]) -> DataFrame: ...\n    @overload\n    def drop(self, *, columns: Union[_str, List[_str], Index]) -> DataFrame: ...\n    def drop_duplicates(self, keep: Union[_str, bool] = ...) -> DataFrame: ...\n    def transpose(self, *args: int, copy: bool = ...) -> DataFrame: ...\n    @overload\n    def dropna(\n        self,\n        inplace: Literal[False] = ...,\n        axis: Optional[_AxisType] = ...,\n        how: _str = ...,\n        subset: _ColSubsetType = ...,\n    ) -> DataFrame: ...\n    @overload\n    def dropna(\n        self,\n        inplace: Literal[True],\n        axis: Optional[_AxisType] = ...,\n        how: _str = ...,\n        subset: _ColSubsetType = ...,\n    ) -> None: ...\n    @overload\n    def fillna(\n        self,\n        value: Union[float, Dict, Series, DataFrame, _str] = ...,\n        method: _str = ...,\n        axis: Optional[_AxisType] = ...,\n        inplace: Literal[False] = ...,\n        limit: int = ...,\n        downcast: Dict = ...,\n    ) -> DataFrame: ...\n    @overload\n    def fillna(\n        self,\n        inplace: Literal[True],\n        value: Union[float, Dict, Series, DataFrame, _str] = ...,\n        method: _str = ...,\n        axis: Optional[_AxisType] = ...,\n        limit: int = ...,\n        downcast: Dict = ...,\n    ) -> None: ...\n    @overload\n    def filter(\n        self,\n        items: List[_str],\n        axis: _AxisType = ...,\n    ) -> DataFrame: ...\n    @overload\n    def filter(self, *, like: _str, axis: _AxisType = ...) -> DataFrame: ...\n    @overload\n    def filter(self, *, regex: _str, axis: _AxisType = ...) -> DataFrame: ...\n    @overload\n    def groupby(\n        self,\n        by: Union[\n            _str,\n            Tuple[_str, ...],\n            List[_str],\n            List[Tuple[_str, _str]],\n            List[Tuple[_str, _str, _str]],\n        ],\n        level: Union[int, _str] = ...,\n        as_index: bool = ...,\n        sort: bool = ...,\n        group_keys: bool = ...,\n        squeeze: bool = ...,\n        observed: bool = ...,\n    ) -> DataFrameGroupBy: ...\n    @overload\n    def groupby(\n        self,\n        by: Union[Series[_str], Dict[_str, _str], Callable],\n        axis: _AxisType = ...,\n        level: Union[int, _str] = ...,\n        sort: bool = ...,\n        group_keys: bool = ...,\n        squeeze: bool = ...,\n        observed: bool = ...,\n    ) -> DataFrameGroupBy: ...\n    def head(self, n: int = ...) -> DataFrame: ...\n    def idxmax(self, axis: _AxisType = ...) -> Series: ...\n    def idxmin(self, axis: _AxisType = ...) -> Series: ...\n    def insert(\n        self, loc: int, column: _str, value: _ListLike, allow_duplicates: bool = ...\n    ) -> None: ...\n    def isin(self, values: Union[Iterable, Series, DataFrame, Dict]) -> DataFrame: ...\n    def isna(self) -> DataFrame: ...\n    def isnull(self) -> DataFrame: ...\n    def iterrows(self) -> Iterator[Tuple[_Label, Series]]: ...\n    @overload\n    def itertuples(self, name: Literal[None], index: bool = ...) -> Iterator[Tuple[Any, ...]]: ...\n    @overload\n    def itertuples(self, name: _str, index: bool = ...) -> Iterator[NamedTuple]: ...\n    @overload\n    def itertuples(self, index: bool = ...) -> Iterator[NamedTuple]: ...\n    def max(self) -> Series: ...\n    def mean(self) -> Series: ...\n    @overload\n    def merge(\n        self,\n        right: DataFrame,\n        on: Union[_str, List[_str]],\n        how: Literal[\"left\", \"right\", \"inner\", \"outer\"] = ...,\n        suffixes: Iterable[_str] = ...,\n    ) -> DataFrame: ...\n    @overload\n    def merge(\n        self,\n        right: DataFrame,\n        left_on: Union[_str, List[_str]],\n        right_on: Union[_str, List[_str]],\n        how: Literal[\"left\", \"right\", \"inner\", \"outer\"] = ...,\n        suffixes: Iterable[_str] = ...,\n    ) -> DataFrame: ...\n    def min(self) -> Series: ...\n    def mode(self, axis: _AxisType = ...) -> DataFrame: ...\n    def median(\n        self, axis: int = ..., skipna: bool = ..., level: Union[int, _str] = ...\n    ) -> Union[DataFrame, Series]: ...\n    def notna(self) -> DataFrame: ...\n    def notnull(self) -> DataFrame: ...\n    def nunique(self) -> Series: ...\n    def plot(self, kind: _str, yerr: DataFrame) -> matplotlib.axes.Axes: ...\n    def query(self, expr: _str) -> DataFrame: ...\n    def rank(\n        self,\n        axis: _AxisType = ...,\n        method: _str = ...,\n        numeric_only: Optional[bool] = ...,\n        na_option: _str = ...,\n        ascending: bool = ...,\n        pct: bool = ...,\n    ) -> DataFrame: ...\n    @overload\n    def reindex(self, index: Index) -> DataFrame: ...\n    @overload\n    def reindex(self, columns: List[_str]) -> DataFrame: ...\n    # rename specifying mapper= and axis=\n    @overload\n    def rename(\n        self, mapper: _Renamer, *, inplace: Literal[True], axis: _AxisType = ...\n    ) -> None: ...\n    @overload\n    def rename(\n        self, mapper: _Renamer, axis: _AxisType = ..., inplace: Literal[False] = ...\n    ) -> DataFrame: ...\n    @overload\n    # rename specifying columns=\n    def rename(self, *, columns: _Renamer, inplace: Literal[True]) -> None: ...\n    @overload\n    def rename(self, *, columns: _Renamer, inplace: Literal[False] = ...) -> DataFrame: ...\n    # rename specifying index=\n    @overload\n    def rename(self, *, index: _Renamer, inplace: Literal[True]) -> None: ...\n    @overload\n    def rename(self, *, index: _Renamer, inplace: Literal[False] = ...) -> DataFrame: ...\n    def replace(\n        self,\n        a: Union[_np.dtype, _str, Pattern[_str]],\n        b: Union[_np.dtype, float, _str],\n        regex: bool = ...,\n        inplace: bool = ...,\n    ) -> DataFrame: ...\n    @overload\n    def reset_index(self, drop: bool = ...) -> DataFrame: ...\n    @overload\n    def reset_index(self, inplace: Literal[True], drop: bool = ...) -> None: ...\n    @overload\n    def sample(self, frac: float, random_state: int = ..., replace: bool = ...) -> DataFrame: ...\n    @overload\n    def sample(self, n: int, random_state: int = ..., replace: bool = ...) -> DataFrame: ...\n    @overload\n    def sample(self, n: int, random_state: int = ..., axis: _AxisType = ...) -> DataFrame: ...\n    @overload\n    def sample(self, axis: _str, frac: float) -> DataFrame: ...\n    def set_index(self, index: Union[_str, List[_str]]) -> DataFrame: ...\n    def sort_index(\n        self,\n        axis: _AxisType = ...,\n        level: Optional[Union[int, _str, List[int], List[_str]]] = ...,\n        ascending: bool = ...,\n        inplace: bool = ...,\n        kind: _str = ...,\n        na_position: _str = ...,\n        sort_remaining: bool = ...,\n        ignore_index: bool = ...,\n    ) -> Optional[DataFrame]: ...\n    @overload\n    def sort_values(\n        self,\n        by: Union[_str, List[_str]],\n        inplace: Literal[True],\n        axis: _AxisType = ...,\n        ascending: Union[bool, List[bool]] = ...,\n    ) -> None: ...\n    @overload\n    def sort_values(\n        self,\n        by: Union[_str, List[_str]],\n        inplace: Optional[Literal[False]] = ...,\n        axis: _AxisType = ...,\n        ascending: Union[bool, List[bool]] = ...,\n    ) -> DataFrame: ...\n    def std(self) -> Series: ...\n    def sum(self, axis: _AxisType = ...) -> Series: ...\n    def tail(self, n: int = ...) -> DataFrame: ...\n    def to_csv(\n        self,\n        path_or_buf: Optional[Union[Path, _str]] = ...,\n        sep: _str = ...,\n        na_rep: _str = ...,\n        float_format: Optional[_str] = ...,\n        columns: Optional[Sequence[Optional[Hashable]]] = ...,\n        header: Union[bool, List[_str]] = ...,\n        index: bool = ...,\n        index_label: Optional[Union[bool, _str, Sequence[Optional[Hashable]]]] = ...,\n        mode: _str = ...,\n        encoding: Optional[_str] = ...,\n        compression: Optional[\n            Union[Literal[\"infer\", \"gzip\", \"bz3\", \"zip\", \"xz\"], Mapping[_str, _str]]\n        ] = ...,\n        quoting: Optional[int] = ...,\n        quotechar: _str = ...,\n        line_terminator: Optional[_str] = ...,\n        chunksize: Optional[int] = ...,\n        date_format: Optional[_str] = ...,\n        doublequote: bool = ...,\n        escape_char: Optional[_str] = ...,\n        decimal: _str = ...,\n    ) -> Optional[_str]: ...\n    @overload\n    def to_dict(self) -> Dict[_str, Any]: ...\n    @overload\n    def to_dict(self, orient: _str) -> List[Dict[_str, Any]]: ...\n    def to_feather(self, filename: Path) -> None: ...\n    def to_html(\n        self,\n        columns: Optional[Sequence[_str]] = ...,\n        col_space: Optional[int] = ...,\n        header: bool = ...,\n        index: bool = ...,\n        na_rep: _str = ...,\n        formatters: Optional[\n            Union[List[Callable[[_str], _str]], Dict[_str, Callable[[_str], _str]]]\n        ] = ...,\n        float_format: Optional[Callable[[_str], _str]] = ...,\n        sparsify: Optional[bool] = ...,\n        index_names: bool = ...,\n        justify: Optional[\n            Literal[\n                \"left\",\n                \"right\",\n                \"center\",\n                \"justify\",\n                \"justify-all\",\n                \"start\",\n                \"end\",\n                \"inherit\",\n                \"match-parent\",\n                \"initial\",\n                \"unset\",\n            ]\n        ] = ...,\n        bold_rows: bool = ...,\n        classes: Optional[Union[_str, List[_str], Tuple[_str, ...]]] = ...,\n        escape: bool = ...,\n        max_rows: Optional[int] = ...,\n        max_cols: Optional[int] = ...,\n        show_dimensions: bool = ...,\n        notebook: bool = ...,\n        decimal: _str = ...,\n        border: Optional[int] = ...,\n        table_id: Optional[_str] = ...,\n    ) -> _str: ...\n    @overload\n    def to_numpy(self) -> _np.ndarray: ...\n    @overload\n    def to_numpy(self, dtype: Type[_DTypeNp]) -> _np.ndarray[_DTypeNp]: ...\n    def to_parquet(\n        self,\n        path: Union[Path, _str],\n        engine: Literal[\"auto\", \"pyarrow\", \"fastparquet\"] = ...,\n        compression: Union[Literal[\"snappy\", \"gzip\", \"brotli\"], None] = ...,\n        index: Optional[bool] = ...,\n        partition_colslist: Optional[List[_str]] = ...,\n        **kwargs: Any,\n    ) -> None: ...\n    def to_pickle(\n        self,\n        path: Union[Path, _str],\n        compression: Optional[Literal[\"infer\", \"gzip\", \"bz2\", \"zip\", \"xz\"]] = ...,\n        protocol: int = ...,\n    ) -> None: ...\n    def unique(self) -> DataFrame: ...\n    def update(self, other: Union[DataFrame, Series]) -> None: ...\n    def where(self, cond: Union[Series, DataFrame, _np.ndarray]) -> DataFrame: ...\n    @property\n    def at(self) -> _AtIndexerFrame: ...\n\n# Local Variables:\n# blacken-line-length: 100\n# blacken-allow-py36: t\n# blacken-skip-string-normalization: t\n# End:\n",
    "/typeshed/pandas/core/indexing.pyi": "from typing import Union, overload, Tuple, List, Generic, Hashable\nimport numpy as _np\n\nfrom .series import Series, _DType\nfrom .frame import DataFrame\nfrom .indexes import Index\n\n_IndexType = Union[slice, _np.ndarray[_np.int64], Index[int], List[int], Series[int]]\n_MaskType = Union[Series[bool], _np.ndarray[_np.bool_], List[bool]]\n_StrLike = Union[str, _np.str_]\n\nclass _iLocIndexerFrame:\n    # get item\n    @overload\n    def __getitem__(self, idx: int) -> Series: ...\n    @overload\n    def __getitem__(self, idx: Tuple[int, int]) -> float: ...\n    @overload\n    def __getitem__(self, idx: _IndexType) -> DataFrame: ...\n    @overload\n    def __getitem__(self, idx: Tuple[_IndexType, _IndexType]) -> DataFrame: ...\n    @overload\n    def __getitem__(self, idx: Tuple[_IndexType, int]) -> Series: ...\n    @overload\n    def __getitem__(self, idx: Tuple[int, _IndexType]) -> Series: ...\n    # set item\n    @overload\n    def __setitem__(self, idx: int, value: Union[float, Series]) -> None: ...\n    @overload\n    def __setitem__(self, idx: Tuple[int, int], value: float) -> None: ...\n    @overload\n    def __setitem__(self, idx: _IndexType, value: Union[float, Series, DataFrame]) -> None: ...\n    @overload\n    def __setitem__(\n        self, idx: Tuple[_IndexType, _IndexType], value: Union[float, Series, DataFrame]\n    ) -> None: ...\n    @overload\n    def __setitem__(self, idx: Tuple[_IndexType, int], value: Union[float, Series]) -> None: ...\n    @overload\n    def __setitem__(self, idx: Tuple[int, _IndexType], value: Union[float, Series]) -> None: ...\n\nclass _iLocIndexerSeries(Generic[_DType]):\n    # get item\n    @overload\n    def __getitem__(self, idx: int) -> _DType: ...\n    @overload\n    def __getitem__(self, idx: _IndexType) -> Series[_DType]: ...\n    # set item\n    @overload\n    def __setitem__(self, idx: int, value: _DType) -> None: ...\n    @overload\n    def __setitem__(self, idx: _IndexType, value: Union[_DType, Series[_DType]]) -> None: ...\n\nclass _LocIndexerFrame:\n    # get item\n    @overload\n    def __getitem__(self, idx: Union[_MaskType, _IndexType]) -> DataFrame: ...\n    @overload\n    def __getitem__(self, idx: _StrLike) -> Series: ...\n    @overload\n    def __getitem__(self, idx: List[_StrLike]) -> DataFrame: ...\n    @overload\n    def __getitem__(\n        self,\n        idx: Tuple[\n            Union[slice, _MaskType, _IndexType, List[str]], Union[_MaskType, List[str], str]\n        ],\n    ) -> DataFrame: ...\n    @overload\n    def __getitem__(self, idx: Tuple[_StrLike, _StrLike]) -> float: ...\n    # set item\n    @overload\n    def __setitem__(\n        self, idx: Union[_MaskType, _IndexType], value: Union[float, _np.ndarray, DataFrame]\n    ) -> None: ...\n    @overload\n    def __setitem__(self, idx: _StrLike, value: Union[float, Series, _np.ndarray]) -> None: ...\n    @overload\n    def __setitem__(\n        self, idx: List[_StrLike], value: Union[float, _np.ndarray, DataFrame]\n    ) -> None: ...\n    @overload\n    def __setitem__(self, idx: Tuple[_IndexType, str], value: Union[_IndexType, float]) -> None: ...\n    @overload\n    def __setitem__(\n        self,\n        idx: Tuple[Union[_MaskType, _IndexType, List[str]], Union[_MaskType, List[str]]],\n        value: Union[DataFrame, Series, float],\n    ) -> None: ...\n\nclass _AtIndexerFrame:\n    # get item\n    def __getitem__(self, idx: Tuple[int, Hashable]) -> Union[int, float, str]: ...\n    # set item\n    def __setitem__(self, idx: Tuple[int, Hashable], value: Union[int, float, str]) -> None: ...\n\nclass _AtIndexerSeries(Generic[_DType]):\n    # get item\n    def __getitem__(self, idx: _StrLike) -> _DType: ...\n    # set item\n    def __setitem__(self, idx: _StrLike, value: _DType) -> None: ...\n\nclass _LocIndexerSeries(Generic[_DType]):\n    # get item\n    @overload\n    def __getitem__(self, idx: _MaskType) -> Series[_DType]: ...\n    @overload\n    def __getitem__(self, idx: str) -> _DType: ...\n    @overload\n    def __getitem__(self, idx: List[str]) -> Series[_DType]: ...\n    @overload\n    # set item\n    def __setitem__(\n        self, idx: _MaskType, value: Union[_DType, _np.ndarray, Series[_DType]]\n    ) -> None: ...\n    @overload\n    def __setitem__(self, idx: str, value: _DType) -> None: ...\n    @overload\n    def __setitem__(\n        self, idx: List[str], value: Union[_DType, _np.ndarray, Series[_DType]]\n    ) -> None: ...\n\n# Local Variables:\n# blacken-line-length: 100\n# blacken-allow-py36: t\n# blacken-skip-string-normalization: t\n# End:\n",
    "/typeshed/pandas/core/series.pyi": "from pathlib import Path\nfrom typing import (\n    List,\n    Set,\n    Tuple,\n    Type,\n    Union,\n    overload,\n    Optional,\n    Dict,\n    Mapping,\n    TypeVar,\n    Iterator,\n    Generic,\n    Sequence,\n    Callable,\n    Any,\n)\nfrom typing_extensions import Literal\nimport numpy as _np\n\nfrom .indexing import _LocIndexerSeries, _iLocIndexerSeries, _AtIndexerSeries\nfrom .frame import DataFrame, _AxisType\nfrom .indexes import Index\nfrom .strings import StringMethods\n\n_str = str  # needed because Series has a property called \"str\"...\n\n_DType = TypeVar(\"_DType\", str, bool, int, float, object, _np.ndarray, List, covariant=True)\n_DType2 = TypeVar(\"_DType2\", str, bool, int, float, object, _np.ndarray, List, covariant=True)\n_Number = TypeVar(\"_Number\", int, float, covariant=True)\n_ListLike = Union[_np.ndarray, List[_DType], Dict[_str, _np.ndarray]]\n# dtypes for numpy\n_DTypeNp = TypeVar(\n    \"_DTypeNp\",\n    _np.bool_,\n    _np.int8,\n    _np.int16,\n    _np.int32,\n    _np.int64,\n    _np.float32,\n    _np.float64,\n    _np.str_,\n)\n_SortKind = Literal[\"quicksort\", \"mergesort\", \"heapsort\"]\n_LevelType = Optional[Union[int, _str, List[int], List[_str]]]\n\nclass Series(Generic[_DType]):\n    def __init__(\n        self,\n        data: Optional[\n            Union[_ListLike[_DType], Series[_DType], Dict[int, _DType], Dict[_str, _DType], int]\n        ],\n        index: Union[_str, int, Series, Index, range] = ...,\n    ): ...\n    # magic methods\n    def __add__(self, other: Union[_Number, Series[_Number]]) -> Series[_Number]: ...\n    def __and__(self, other: Union[bool, Series[bool]]) -> Series[bool]: ...\n    def __eq__(self, other: object) -> Series: ...  # type: ignore\n    def __floordiv__(self, other: Union[int, Series[int]]) -> Series[int]: ...\n    def __ge__(self, other: Union[float, Series[float]]) -> Series[bool]: ...\n    @overload\n    def __getitem__(self, idx: Union[List[_str], Index[int], Series, slice]) -> Series: ...\n    @overload\n    def __getitem__(self, idx: Union[_str, int]) -> _DType: ...\n    def __gt__(self, other: Union[float, Series[float]]) -> Series[bool]: ...\n    def __invert__(self: Series[bool]) -> Series[bool]: ...\n    def __iter__(self) -> Iterator[_DType]: ...\n    def __le__(self, other: Union[float, Series[float]]) -> Series[bool]: ...\n    def __len__(self) -> int: ...\n    def __lt__(self, other: Union[float, Series[float]]) -> Series[bool]: ...\n    def __mod__(self, other: Union[int, Series[int]]) -> Series[int]: ...\n    def __mul__(self, other: Union[_Number, Series[_Number]]) -> Series[_Number]: ...\n    def __ne__(self, other: object) -> Series: ...  # type: ignore\n    def __or__(self, other: Union[bool, Series[bool]]) -> Series[bool]: ...\n    def __radd__(self, other: Union[_Number, Series[_Number]]) -> Series[_Number]: ...\n    def __rmul__(self, other: Union[_Number, Series[_Number]]) -> Series[_Number]: ...\n    def __rsub__(self, other: Union[_Number, Series[_Number]]) -> Series[_Number]: ...\n    def __sub__(self, other: Union[_Number, Series[_Number]]) -> Series[_Number]: ...\n    def __truediv__(self, other: Union[_Number, Series[_Number]]) -> Series[_Number]: ...\n    #\n    # properties\n    @property\n    def iloc(self) -> _iLocIndexerSeries[_DType]: ...\n    @property\n    def index(self) -> Index: ...\n    @property\n    def item(self) -> _DType: ...\n    @property\n    def loc(self) -> _LocIndexerSeries[_DType]: ...\n    @property\n    def shape(self) -> Tuple[int, ...]: ...\n    @property\n    def size(self) -> int: ...\n    @property\n    def str(self) -> StringMethods: ...\n    @property\n    def values(self) -> _np.ndarray: ...\n    #\n    # methods\n    def all(self, axis: Optional[_AxisType] = ..., bool_only: bool = ...) -> bool: ...\n    def any(self, axis: Optional[_AxisType] = ..., bool_only: bool = ...) -> bool: ...\n    def append(\n        self,\n        to_append: Union[Series, Sequence[Series]],\n        ignore_index: bool = ...,\n        verify_integrity: bool = ...,\n    ) -> Series: ...\n    def apply(\n        self, func: Callable, convert_dtype: bool = ..., args: Tuple = ..., **kwargs: Any\n    ) -> Series: ...\n    @overload\n    def astype(self, dtype: Type[int]) -> Series[int]: ...\n    @overload\n    def astype(self, dtype: Type[float]) -> Series[float]: ...\n    @overload\n    def astype(self, dtype: Type[_str]) -> Series[object]: ...\n    @overload\n    def astype(self, dtype: Type[object]) -> Series[object]: ...\n    @overload\n    def copy(self) -> Series[_DType]: ...\n    @overload\n    def copy(self, deep: bool = ...) -> Series[_DType]: ...\n    def corr(\n        self, other: Series, method: Literal[\"pearson\", \"kendall\", \"spearman\"] = ...\n    ) -> float: ...\n    def count(self) -> int: ...\n    @overload\n    def drop(\n        self, labels: Union[_str, List[_str], Index], axis: _AxisType = ..., inplace: bool = ...\n    ) -> Series[_DType]: ...\n    @overload\n    def drop(self, *, index: Union[List[_str], Index]) -> Series[_DType]: ...\n    @overload\n    def drop(self, *, columns: Union[_str, List[_str], Index]) -> Series[_DType]: ...\n    def drop_duplicates(self, keep: Union[_str, bool] = ...) -> Series[_DType]: ...\n    def duplicated(self, keep: Literal[\"first\", \"last\", False] = ...) -> Series[_DType]: ...\n    @overload\n    def fillna(\n        self,\n        value: Union[_DType, Dict, Series, DataFrame],\n        method: _str = ...,\n        axis: Optional[_AxisType] = ...,\n        inplace: Literal[True] = ...,\n        limit: int = ...,\n        downcast: Dict = ...,\n    ) -> None: ...\n    @overload\n    def fillna(\n        self,\n        value: Union[_DType, Dict, Series, DataFrame],\n        method: _str = ...,\n        axis: Optional[_AxisType] = ...,\n        inplace: Literal[False] = ...,\n        limit: int = ...,\n        downcast: Dict = ...,\n    ) -> Optional[Series]: ...\n    def head(self, n: int = ...) -> Series: ...\n    def isna(self) -> Series[bool]: ...\n    def isnull(self) -> Series[bool]: ...\n    def isin(self, values: Union[Set, List, Tuple, Series]) -> Series[bool]: ...\n    def ge(self, value: float) -> Series[bool]: ...\n    def map(\n        self, arg: Union[Callable, Mapping, Series], na_action: Optional[_str] = ...\n    ) -> Series: ...\n    def max(self) -> _DType: ...\n    def mean(self) -> float: ...\n    def median(self) -> float: ...\n    def min(self) -> _DType: ...\n    def mode(self) -> Series[_DType]: ...\n    def notnull(self) -> Series[bool]: ...\n    def nunique(self) -> int: ...\n    def rank(\n        self,\n        axis: _AxisType = ...,\n        method: Literal[\"average\", \"min\", \"max\", \"first\", \"dense\"] = ...,\n        numeric_only: Optional[bool] = ...,\n        na_option: Literal[\"keep\", \"top\", \"bottom\"] = ...,\n        ascending: bool = ...,\n        pct: bool = ...,\n    ) -> Series[float]: ...\n    @overload\n    def replace(\n        self, to_replace: Sequence[_DType2], value: Sequence[_DType2], inplace: Literal[False] = ...\n    ) -> Series[_DType]: ...\n    @overload\n    def replace(\n        self, to_replace: Sequence[_DType2], value: Sequence[_DType2], inplace: Literal[True]\n    ) -> None: ...\n    @overload\n    def replace(\n        self, to_replace: _DType2, value: _DType2, inplace: Literal[False] = ...\n    ) -> Series[_DType]: ...\n    @overload\n    def replace(self, to_replace: _DType2, value: _DType2, inplace: Literal[True]) -> None: ...\n    def reset_index(self, drop: bool = ...) -> Series: ...\n    @overload\n    def sort_index(\n        self,\n        axis: Optional[_AxisType] = ...,\n        level: _LevelType = ...,\n        ascending: bool = ...,\n        inplace: Literal[False] = ...,\n        kind: _SortKind = ...,\n        na_position: Literal[\"first\", \"last\"] = ...,\n        sort_remaining: bool = ...,\n        ignore_index: bool = ...,\n        key: Optional[Callable] = ...,\n    ) -> Series[_DType]: ...\n    @overload\n    def sort_index(\n        self,\n        axis: Optional[_AxisType],\n        level: _LevelType,\n        ascending: bool,\n        inplace: Literal[True],\n        kind: _SortKind = ...,\n        na_position: Literal[\"first\", \"last\"] = ...,\n        sort_remaining: bool = ...,\n        ignore_index: bool = ...,\n        key: Optional[Callable] = ...,\n    ) -> None: ...\n    @overload\n    def sort_index(\n        self,\n        *,\n        inplace: Literal[True],\n        axis: Optional[_AxisType] = ...,\n        level: _LevelType = ...,\n        ascending: bool = ...,\n        kind: _SortKind = ...,\n        na_position: Literal[\"first\", \"last\"] = ...,\n        sort_remaining: bool = ...,\n        ignore_index: bool = ...,\n        key: Optional[Callable] = ...,\n    ) -> None: ...\n    @overload\n    def sort_values(\n        self,\n        axis: Optional[_AxisType] = ...,\n        ascending: bool = ...,\n        inplace: Literal[False] = ...,\n        kind: _SortKind = ...,\n        na_position: Literal[\"first\", \"last\"] = ...,\n        ignore_index: bool = ...,\n        key: Optional[Callable] = ...,\n    ) -> Series[_DType]: ...\n    @overload\n    def sort_values(\n        self,\n        axis: Optional[_AxisType],\n        ascending: bool,\n        inplace: Literal[True],\n        kind: _SortKind = ...,\n        na_position: Literal[\"first\", \"last\"] = ...,\n        ignore_index: bool = ...,\n        key: Optional[Callable] = ...,\n    ) -> None: ...\n    @overload\n    def sort_values(\n        self,\n        *,\n        inplace: Literal[True],\n        axis: Optional[_AxisType] = ...,\n        ascending: bool = ...,\n        kind: _SortKind = ...,\n        na_position: Literal[\"first\", \"last\"] = ...,\n        ignore_index: bool = ...,\n        key: Optional[Callable] = ...,\n    ) -> None: ...\n    def shift(\n        self,\n        periods: int = ...,\n        freq: Optional[_str] = ...,\n        axis: Optional[_AxisType] = ...,\n        fill_value: Optional[object] = ...,\n    ) -> Series[_DType]: ...\n    def std(self) -> float: ...\n    def sum(self) -> float: ...\n    def to_csv(self, filename: Union[Path, _str], index: bool = ...) -> None: ...\n    def to_dict(self) -> Dict[Union[int, _str], _DType]: ...\n    def to_frame(self, name: Optional[_str] = ...) -> DataFrame: ...\n    @overload\n    def to_numpy(self: Series[bool]) -> _np.ndarray[_np.bool_]: ...\n    @overload\n    def to_numpy(self: Series[int]) -> _np.ndarray[_np.int64]: ...\n    @overload\n    def to_numpy(self: Series[float]) -> _np.ndarray[_np.float64]: ...\n    @overload\n    def to_numpy(self: Series[object]) -> _np.ndarray: ...\n    @overload\n    def to_numpy(self, dtype: Type[_DTypeNp]) -> _np.ndarray[_DTypeNp]: ...\n    def to_pickle(\n        self,\n        path: Union[Path, _str],\n        compression: Optional[Literal[\"infer\", \"gzip\", \"bz2\", \"zip\", \"xz\"]] = ...,\n        protocol: int = ...,\n    ) -> None: ...\n    def tolist(self) -> List[_DType]: ...\n    def unique(self) -> _np.ndarray: ...\n    def update(self, other: Series) -> None: ...\n    def where(self, cond: Union[Series, DataFrame, _np.ndarray]) -> Series[_DType]: ...\n    def value_counts(self, normalize: bool = ...) -> Series[_DType]: ...\n    @property\n    def at(self) -> _AtIndexerSeries[_DType]: ...\n\n# Local Variables:\n# blacken-line-length: 100\n# blacken-allow-py36: t\n# blacken-skip-string-normalization: t\n# End:\n",
    "/typeshed/pandas/core/strings.pyi": "from typing import List, Optional, Union\nfrom .frame import DataFrame\nfrom .series import Series\n\nclass StringMethods:\n    def contains(\n        self, pat: str, case: bool = ..., flags: int = ..., na: float = ..., regex: bool = ...\n    ) -> Series[bool]: ...\n    def count(self, pat: str, flags: int = ...) -> Series[int]: ...\n    def endswith(self, pat: str, na: float = ...) -> Series[bool]: ...\n    def find(self, sub: str, start: int, end: int) -> Series[int]: ...\n    def findall(self, sub: str, flags: int = ...) -> Series[list]: ...\n    def get(self, i: int) -> Series: ...\n    def index(self, sub: str, start: int, end: int) -> Series: ...\n    def join(self, sep: str) -> Series: ...\n    def len(self) -> Series[int]: ...\n    def ljust(self, width: int, fillchar: str) -> Series: ...\n    def lower(self) -> Series[str]: ...\n    def lstrip(self, to_strip: str = ...) -> Series: ...\n    def match(self, pat: str, case: bool = ..., flag: int = ..., na: float = ...) -> Series: ...\n    def pad(self, width: int, side: str = ..., fillchar: str = ...) -> Series: ...\n    def repeat(self, repeats: Union[int, List[int]]) -> Series: ...\n    def rfind(self, sub: str, start: int, end: int) -> Series[int]: ...\n    def rindex(self, sub: str, start: int, end: int) -> Series: ...\n    def rjust(self, width: int, fillchar: str) -> Series: ...\n    def rstrip(self, to_strip: Optional[str] = ...) -> Series: ...\n    def slice(self, start: Optional[int], stop: Optional[int], step: Optional[int]) -> Series: ...\n    def slice_replace(\n        self, start: Optional[int], stop: Optional[int], repl: Optional[str]\n    ) -> Series: ...\n    def split(self, pat: Optional[str], n: int = ..., expand: bool = ...) -> Series: ...\n    def rsplit(self, pat: Optional[str], n: int = ..., expand: bool = ...) -> Series: ...\n    def startswith(self, pat: str, na: float = ...) -> Series: ...\n    def strip(self, to_strip: Optional[str] = ...) -> Series: ...\n    def translate(self, table: dict) -> Series: ...\n    def wrap(\n        self,\n        width: int,\n        expand_tabs: Optional[bool],\n        replace_whitespace: Optional[bool],\n        drop_whitespace: Optional[bool],\n        break_long_words: Optional[bool],\n        break_on_hyphens: Optional[bool],\n    ) -> Series: ...\n    def zfill(self, width: int) -> Series: ...\n    def get_dummies(self, sep: str = ...) -> DataFrame: ...\n",
    "/typeshed/pandas/core/dtypes/__init__.pyi": "",
    "/typeshed/pandas/core/dtypes/base.pyi": "from typing import (\n    Any,\n    Callable,\n    Generator,\n    List,\n    Optional,\n    Sequence,\n    Tuple,\n    Type,\n    TypeVar,\n    Union,\n)\nfrom typing_extensions import Literal\n\nimport numpy as np\nfrom numpy import _ScalarLike\n\n_ArrayLike = TypeVar(\"_ArrayLike\", _ExtensionArray, np.ndarray)\n_DtypeObj = Union[np.dtype, ExtensionDtype]\n\nclass ExtensionDtype:\n    def __str__(self) -> str: ...\n    def __eq__(self, other: Any) -> bool: ...\n    def __hash__(self) -> int: ...\n    def __ne__(self, other: Any) -> bool: ...\n    @property\n    def na_value(self) -> object: ...\n    @property\n    def type(self) -> Type: ...\n    @property\n    def kind(self) -> str: ...\n    @property\n    def name(self) -> str: ...\n    @property\n    def names(self) -> Optional[List[str]]: ...\n    @classmethod\n    def construct_array_type(cls) -> Type[_ExtensionArray]: ...\n    @classmethod\n    def construct_from_string(cls, string: str) -> ExtensionDtype: ...\n    @classmethod\n    def is_dtype(cls, dtype: object) -> bool: ...\n    @property\n    def _is_numeric(self) -> bool: ...\n    @property\n    def _is_boolean(self) -> bool: ...\n    def _get_common_dtype(self, dtypes: List[_DtypeObj]) -> Optional[_DtypeObj]: ...\n\nclass _ExtensionArray:\n    @classmethod\n    def _from_sequence(\n        cls, scalars: Sequence[_ScalarLike], dtype: Optional[_DtypeObj] = ..., copy: bool = ...\n    ) -> _ExtensionArray: ...\n    @classmethod\n    def _from_sequence_of_strings(\n        cls, strings: Sequence[str], dtype: Optional[_DtypeObj] = ..., copy: bool = ...\n    ) -> _ExtensionArray: ...\n    @classmethod\n    def _from_factorized(cls, values: np.ndarray, original: _ExtensionArray) -> _ExtensionArray: ...\n    def __getitem__(self, item: Union[int, slice, np.ndarray]) -> Any: ...\n    def __setitem__(self, key: Union[int, slice, np.ndarray], value: Any) -> None: ...\n    def __len__(self) -> int: ...\n    def __iter__(self) -> Generator[Any, None, None]: ...\n    # The next two functions are complaining that we're changing the return type of the base class\n    # Which Pandas does. Instead of bool, it returns an array of bools\n    # So squelch those warnings\n    def __eq__(self, other: Any) -> _ArrayLike: ...  # type: ignore\n    def __ne__(self, other: Any) -> _ArrayLike: ...  # type: ignore\n    def to_numpy(\n        self,\n        dtype: Optional[_DtypeObj] = ...,\n        copy: bool = ...,\n        na_value: Optional[Any] = ...,\n    ) -> np.ndarray: ...\n    @property\n    def dtype(self) -> _DtypeObj: ...\n    @property\n    def shape(self) -> Tuple[int, ...]: ...\n    @property\n    def size(self) -> int: ...\n    @property\n    def ndim(self) -> int: ...\n    @property\n    def nbytes(self) -> int: ...\n    def astype(self, dtype: Union[str, _DtypeObj], copy: bool = ...) -> np.ndarray: ...\n    def isna(self) -> _ArrayLike: ...\n    def _values_for_argsort(self) -> np.ndarray: ...\n    def argsort(\n        self, ascending: bool = ..., kind: str = ..., *args: Any, **kwargs: Any\n    ) -> np.ndarray: ...\n    def argmin(self) -> int: ...\n    def argmax(self) -> int: ...\n    def fillna(\n        self,\n        value: Union[_ScalarLike, _ArrayLike] = ...,\n        method: Optional[Literal[\"backfill\", \"bfill\", \"pad\", \"ffill\"]] = ...,\n        limit: Optional[int] = ...,\n    ) -> _ExtensionArray: ...\n    def dropna(self) -> _ExtensionArray: ...\n    def shift(self, periods: int = ..., fill_value: object = ...) -> _ExtensionArray: ...\n    def unique(self) -> _ExtensionArray: ...\n    def searchsorted(\n        self,\n        value: _ArrayLike,\n        side: Optional[Literal[\"left\", \"right\"]] = ...,\n        sorter: Optional[_ArrayLike] = ...,\n    ) -> np.ndarray: ...\n    def equals(self, other: _ExtensionArray) -> bool: ...\n    def _values_for_factorize(self) -> Tuple[np.ndarray, Any]: ...\n    def factorize(self, na_sentinel: int = ...) -> Tuple[np.ndarray, _ExtensionArray]: ...\n    def repeat(\n        self, repeats: Union[int, np.ndarray], axis: Optional[int] = ...\n    ) -> _ExtensionArray: ...\n    def take(\n        self, indices: Sequence[int], allow_fill: bool = ..., fill_value: Any = ...\n    ) -> _ExtensionArray: ...\n    def copy(self) -> _ExtensionArray: ...\n    def view(self, dtype: _DtypeObj = ...) -> _ArrayLike: ...\n    def __repr__(self) -> str: ...\n    def _formatter(self, boxed: bool = ...) -> Callable[[Any], Optional[str]]: ...\n    def ravel(self, order: Optional[Literal[\"C\", \"F\", \"A\", \"K\"]] = ...) -> _ExtensionArray: ...\n    @classmethod\n    def _concat_same_type(cls, to_concat: Sequence[_ExtensionArray]) -> _ExtensionArray: ...\n    def _reduce(self, name: str, skipna: bool = ..., **kwargs: Any) -> _ScalarLike: ...\n    def __hash__(self) -> int: ...\n",
    "/typeshed/pandas/core/groupby/__init__.pyi": "",
    "/typeshed/pandas/core/groupby/generic.pyi": "from typing import overload, Union, List, Dict, Iterator\nfrom typing_extensions import Literal\nimport numpy as _np\n\nfrom pandas.core.frame import DataFrame\nfrom pandas.core.series import Series\nfrom ..frame import _FunctionLike\n\n_str = str  # needed because Series has a property called \"str\"...\n\nclass GroupBy: ...\n\nclass SeriesGroupBy(GroupBy):\n    def __getitem__(self, item: _str) -> Series: ...\n    def count(self) -> Series: ...\n    def head(self, n: int = ...) -> Series: ...\n    def max(self) -> Series: ...\n    def mean(self) -> Series: ...\n    def median(self) -> Series: ...\n    def min(self) -> Series: ...\n    def nunique(self, dropna: bool = ...) -> Series: ...\n    def quantile(self, q: float = ..., interpolation: str = ...) -> Series: ...\n    def rank(\n        self,\n        method: Literal[\"average\", \"min\", \"max\", \"first\", \"dense\"] = ...,\n        ascending: bool = ...,\n        na_option: Literal[\"keep\", \"top\", \"bottom\"] = ...,\n        pct: bool = ...,\n    ) -> Series: ...\n    def std(self, ddof: int = ...) -> Series: ...\n    def sum(self) -> Series: ...\n    def tail(self, n: int = ...) -> Series: ...\n    def unique(self) -> Series[_np.ndarray]: ...\n    def var(self, ddof: int = ...) -> Series: ...\n\nclass DataFrameGroupBy(GroupBy):\n    @overload\n    def __getitem__(self, item: _str) -> SeriesGroupBy: ...\n    @overload\n    def __getitem__(self, item: List[_str]) -> DataFrameGroupBy: ...\n    def __getattr__(self, name: _str) -> SeriesGroupBy: ...\n    def __iter__(self) -> Iterator: ...\n    def aggregate(\n        self, func: Union[_FunctionLike, List[_FunctionLike], Dict[_str, _FunctionLike]]\n    ) -> DataFrame: ...\n    agg = aggregate\n    def count(self) -> DataFrame: ...\n    def head(self, n: int = ...) -> DataFrame: ...\n    def max(self) -> DataFrame: ...\n    def mean(self) -> DataFrame: ...\n    def median(self) -> DataFrame: ...\n    def min(self) -> DataFrame: ...\n    def nunique(self, dropna: bool = ...) -> DataFrame: ...\n    def quantile(self, q: float = ..., interpolation: str = ...) -> DataFrame: ...\n    def rank(\n        self, method: str, ascending: bool, na_option: str, pct: bool, axis: int\n    ) -> DataFrame: ...\n    def std(self, ddof: int = ...) -> DataFrame: ...\n    def sum(self) -> DataFrame: ...\n    def tail(self, n: int = ...) -> DataFrame: ...\n    def var(self, ddof: int = ...) -> DataFrame: ...\n",
    "/typeshed/pandas/core/arrays/__init__.pyi": "from .base import ExtensionArray, ExtensionOpsMixin\n",
    "/typeshed/pandas/core/arrays/base.pyi": "from typing import Any, Callable, TypeVar\n\nimport numpy as np\n\n# This is normally where ExtensionArray would be defined,\n# but we can't do conditional TYPE_CHECKING imports like pandas does.\n# So this will work for now.\nfrom ..dtypes.base import _ArrayLike\nfrom ..dtypes.base import _ExtensionArray as ExtensionArray\n\nclass ExtensionOpsMixin:\n    @classmethod\n    def _create_arithmetic_method(\n        cls, op: Callable[..., Any]\n    ) -> Callable[[Any, Any], ExtensionArray]: ...\n    @classmethod\n    def _add_arithmetic_ops(cls) -> None: ...\n    @classmethod\n    def _create_comparison_method(cls, op: Callable[..., Any]) -> Callable[..., bool]: ...\n    @classmethod\n    def _add_comparison_ops(cls) -> None: ...\n    @classmethod\n    def _create_logical_method(cls, op: Callable[..., Any]) -> Callable[..., bool]: ...\n    @classmethod\n    def _add_logical_ops(cls) -> None: ...\n",
    "/typeshed/pandas/core/arrays/integer.pyi": "from typing import Any, Callable, List, Optional, Sequence, Type, Union, Tuple\nfrom typing_extensions import Literal\nimport numpy as np\nfrom numpy import _ScalarLike\n\nfrom ..dtypes.base import _ArrayLike, _DtypeObj\nfrom .masked import BaseMaskedArray, BaseMaskedDtype\n\nclass _IntegerDtype(BaseMaskedDtype):\n    def __repr__(self) -> str: ...\n    def is_signed_integer(self) -> bool: ...\n    def is_unsigned_integer(self) -> bool: ...\n    @property\n    def _is_numeric(self) -> bool: ...\n    def numpy_dtype(self) -> np.dtype: ...\n    def kind(self) -> str: ...\n    def itemsize(self) -> int: ...\n    @classmethod\n    def construct_array_type(cls) -> Type[IntegerArray]: ...\n    def _get_common_dtype(self, dtypes: List[_DtypeObj]) -> Optional[_DtypeObj]: ...\n    def __from_arrow__(\n        self,\n        array: Any,  # Union[pyarrow.Array, pyarrow.ChunkedArray]\n    ) -> IntegerArray: ...\n\nclass IntegerArray(BaseMaskedArray):\n    def dtype(self) -> _IntegerDtype: ...\n    def __init__(self, values: np.ndarray, mask: np.ndarray, copy: bool = ...) -> None: ...\n    @classmethod\n    def _from_sequence(\n        cls, scalars: Sequence[_ScalarLike], dtype: Optional[_DtypeObj] = ..., copy: bool = ...\n    ) -> IntegerArray: ...\n    @classmethod\n    def _from_sequence_of_strings(\n        cls, strings: Sequence[str], dtype: Optional[_DtypeObj] = ..., copy: bool = ...\n    ) -> IntegerArray: ...\n    def __array_ufunc__(\n        self,\n        ufunc: Callable[..., Any],\n        method: Literal[\"reduce\", \"accumulate\", \"reduceat\", \"outer\", \"at\", \"__call__\"],\n        *inputs: Any,\n        **kwargs: Any,\n    ) -> Any: ...\n    def _coerce_to_array(self, value: Any) -> Tuple[np.ndarray, np.ndarray]: ...\n    def astype(self, dtype: Union[str, _DtypeObj], copy: bool = ...) -> _ArrayLike: ...\n    def _values_for_argsort(self) -> np.ndarray: ...\n    @classmethod\n    def _create_comparison_method(cls, op: Callable[..., Any]) -> Callable[..., bool]: ...\n    def sum(self, skipna: bool = ..., min_count: int = ..., **kwargs: Any) -> _IntegerDtype: ...\n    def _maybe_mask_result(\n        self,\n        result: _ArrayLike,\n        mask: _ArrayLike,\n        other: Union[_ScalarLike, _ArrayLike],\n        op_name: str,\n    ) -> Callable[[Any, Any], IntegerArray]: ...\n    @classmethod\n    def _create_arithmetic_method(\n        cls, op: Callable[..., Any]\n    ) -> Callable[[Any, Any], IntegerArray]: ...\n\nclass Int8Dtype(_IntegerDtype): ...\nclass Int16Dtype(_IntegerDtype): ...\nclass Int32Dtype(_IntegerDtype): ...\nclass Int64Dtype(_IntegerDtype): ...\nclass UInt8Dtype(_IntegerDtype): ...\nclass UInt16Dtype(_IntegerDtype): ...\nclass UInt32Dtype(_IntegerDtype): ...\nclass UInt64Dtype(_IntegerDtype): ...\n",
    "/typeshed/pandas/core/arrays/masked.pyi": "from typing import Any, Generator, Iterable, Optional, Sequence, Tuple, Type, TypeVar, Union\n\nimport numpy as np\nfrom numpy import _ScalarLike\n\nfrom ..arrays.base import ExtensionArray, ExtensionOpsMixin\nfrom ..dtypes.base import ExtensionDtype, _ArrayLike, _DtypeObj\nfrom ..series import Series\n\n_BaseMaskedArrayT = TypeVar(\"_BaseMaskedArrayT\", bound=BaseMaskedArray)\n\nclass BaseMaskedDtype(ExtensionDtype):\n    @property\n    def numpy_dtype(self) -> np.dtype: ...\n    @classmethod\n    def construct_array_type(cls) -> Type[BaseMaskedArray]: ...\n\nclass BaseMaskedArray(ExtensionArray, ExtensionOpsMixin):\n    def __init__(self, values: np.ndarray, mask: np.ndarray, copy: bool = ...) -> None: ...\n    @property\n    def dtype(self) -> BaseMaskedDtype: ...\n    def _coerce_to_array(self, values: Any) -> Tuple[np.ndarray, np.ndarray]: ...\n    def __setitem__(self, key: Union[int, slice, np.ndarray], value: Any) -> None: ...\n    def __iter__(self) -> Generator[Any, None, None]: ...\n    def __len__(self) -> int: ...\n    def __invert__(self: _BaseMaskedArrayT) -> _BaseMaskedArrayT: ...\n    def to_numpy(\n        self, dtype: Optional[_DtypeObj] = ..., copy: bool = ..., na_value: _ScalarLike = ...\n    ) -> np.ndarray: ...\n    def __array__(self, dtype: _DtypeObj = ...) -> np.ndarray: ...\n    def __arrow_array__(self, type: Optional[Any] = ...) -> Any: ...  # pyarrow.array: ...\n    @property\n    def _hasna(self) -> bool: ...\n    def isna(self) -> _ArrayLike: ...\n    @property\n    def _na_value(self) -> Any: ...\n    @property\n    def nbytes(self) -> int: ...\n    @classmethod\n    def _concat_same_type(\n        cls: Type[_BaseMaskedArrayT], to_concat: Iterable\n    ) -> _BaseMaskedArrayT: ...\n    def take(\n        self: _BaseMaskedArrayT,\n        indexer: Sequence,\n        allow_fill: bool = ...,\n        fill_value: Optional[_ScalarLike] = ...,\n    ) -> _BaseMaskedArrayT: ...\n    def copy(self: _BaseMaskedArrayT) -> _BaseMaskedArrayT: ...\n    def factorize(self, na_sentinel: int = ...) -> Tuple[np.ndarray, ExtensionArray]: ...\n    def value_counts(self, dropna: bool = ...) -> Series: ...\n    def _reduce(self, name: str, skipna: bool = ..., **kwargs: Any) -> _ScalarLike: ...\n",
    "/typeshed/pandas/core/indexes/__init__.pyi": "from .base import Index as Index\nfrom .frozen import FrozenList as FrozenList\nfrom .multi import MultiIndex as MultiIndex\n",
    "/typeshed/pandas/core/indexes/base.pyi": "from typing import (\n    Callable,\n    Generic,\n    Iterator,\n    List,\n    Optional,\n    Set,\n    Tuple,\n    Type,\n    TypeVar,\n    Union,\n    overload,\n)\n\nimport numpy as _np\n\nfrom ..frame import DataFrame\nfrom ..series import Series\nfrom ..strings import StringMethods\nfrom .frozen import FrozenList\n\n_str = str  # needed because Index has a property called \"str\"...\n\n_T = TypeVar(\"_T\", _str, int)\n_U = TypeVar(\"_U\", _str, int)\n\n_ArrayLike = Union[List[_T], Series[_T], _np.ndarray, range]\n\nclass Index(Generic[_T]):\n    # magic methods\n    def __init__(\n        self,\n        data: _ArrayLike[_T],\n        dtype: Optional[_np.dtype] = ...,\n        copy: Optional[bool] = ...,\n        name: Optional[_str] = ...,\n        tupleize_cols: Optional[bool] = ...,\n    ): ...\n    def __eq__(self, other: object) -> Series: ...  # type: ignore\n    @overload\n    def __getitem__(self, idx: int) -> _T: ...\n    @overload\n    def __getitem__(self, idx: Index[_T]) -> Index[_T]: ...\n    @overload\n    def __getitem__(self, idx: Series[bool]) -> _T: ...\n    @overload\n    def __getitem__(self, idx: Tuple[_np.ndarray[_np.int64], ...]) -> _T: ...\n    @overload\n    def __getitem__(self, idx: _np.ndarray[_np.int64]) -> _T: ...\n    def __iter__(self) -> Iterator: ...\n    def __len__(self) -> int: ...\n    def __ne__(self, other: _str) -> Index[_T]: ...  # type: ignore\n    #\n    # properties\n    @property\n    def names(self) -> FrozenList[_str]: ...\n    @property\n    def shape(self) -> Tuple[int, ...]: ...\n    @property\n    def str(self) -> StringMethods: ...\n    @overload\n    def values(self: Index[_str]) -> _np.ndarray[_np.str_]: ...\n    @overload\n    def values(self: Index[int]) -> _np.ndarray[_np.int64]: ...\n    #\n    # methods\n    def astype(self, dtype: Type[_U]) -> Index[_U]: ...\n    def difference(self, other: Union[List[_T], Index[_T]]) -> Index[_T]: ...\n    def get_level_values(self, level: _str) -> Index: ...\n    def isin(\n        self, values: Union[Set, _ArrayLike], level: Union[_str, int] = ...\n    ) -> _np.ndarray[_np.bool_]: ...\n    def map(self, fn: Callable) -> Index: ...\n    def min(self) -> _T: ...\n    def max(self) -> _T: ...\n    def to_frame(self) -> DataFrame: ...\n    def tolist(self) -> List[_T]: ...\n    @overload\n    def to_numpy(self: Index[_str]) -> _np.ndarray[_np.str_]: ...\n    @overload\n    def to_numpy(self: Index[int]) -> _np.ndarray[_np.int64]: ...\n    def unique(self) -> List[_T]: ...\n    def duplicated(self) -> _np.ndarray[_np.bool_]: ...\n    def isna(self) -> _np.ndarray[_np.bool_]: ...\n    def isnull(self) -> _np.ndarray[_np.bool_]: ...\n",
    "/typeshed/pandas/core/indexes/frozen.pyi": "from typing import Generic, Iterator, List, overload, TypeVar, Tuple, Union\n\n_T = TypeVar(\"_T\")\n\nclass FrozenList(Generic[_T]):\n    @overload\n    def __getitem__(self, idx: int) -> _T: ...\n    @overload\n    def __getitem__(self, idx: slice) -> FrozenList[_T]: ...\n    def __iter__(self) -> Iterator[_T]: ...\n    def __len__(self) -> int: ...\n    def __contains__(self, key: object) -> bool: ...\n    def __reversed__(self) -> FrozenList[_T]: ...\n    def __radd__(\n        self, other: Union[FrozenList[_T], List[_T], Tuple[_T, ...]]\n    ) -> FrozenList[_T]: ...\n",
    "/typeshed/pandas/core/indexes/multi.pyi": "from typing import Iterable, List, Optional, Sequence, Tuple, TypeVar, Union\n\nimport numpy as _np\n\nfrom ..frame import DataFrame\nfrom ..series import Series\nfrom .base import Index\nfrom .frozen import FrozenList\n\n_str = str\n_T = TypeVar(\"_T\", _str, int)\n_ArrayLike = Union[List[_T], Series[_T], _np.ndarray]\n\nclass MultiIndex(Index):\n    @property\n    def names(self) -> FrozenList[str]: ...\n    @property\n    def levels(self) -> FrozenList[Index[_T]]: ...\n    @property\n    def codes(self) -> FrozenList[_np.ndarray[_np.int8]]: ...\n    @property\n    def nlevels(self) -> int: ...\n    @property\n    def levshape(self) -> Tuple[int, ...]: ...\n    @classmethod\n    def from_arrays(\n        cls,\n        arrays: Sequence[_ArrayLike],\n        sort_order: Optional[bool] = ...,\n        names: Optional[Union[List[str], Tuple[str, ...]]] = ...,\n    ) -> MultiIndex: ...\n    @classmethod\n    def from_product(\n        cls,\n        iterables: Sequence[Iterable[_T]],\n        sort_order: Optional[bool] = ...,\n        names: Optional[Union[List[str], Tuple[str, ...]]] = ...,\n    ) -> MultiIndex: ...\n    @classmethod\n    def from_tuples(\n        cls,\n        tuples: Sequence[Tuple[_T, ...]],\n        sort_order: Optional[bool] = ...,\n        names: Optional[Union[List[str], Tuple[str, ...]]] = ...,\n    ) -> MultiIndex: ...\n    @classmethod\n    def from_frame(\n        cls,\n        df: DataFrame,\n        sort_order: Optional[bool] = ...,\n        names: Optional[Union[List[str], Tuple[str, ...]]] = ...,\n    ) -> MultiIndex: ...\n"
  }
}