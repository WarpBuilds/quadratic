{
  "files": {
    "/typeshed/python-dateutil/dateutil/__init__.pyi": "",
    "/typeshed/python-dateutil/dateutil/_common.pyi": "from typing_extensions import Self\n\nclass weekday:\n    def __init__(self, weekday: int, n: int | None = None) -> None: ...\n    def __call__(self, n: int) -> Self: ...\n    def __eq__(self, other: object) -> bool: ...\n    def __hash__(self) -> int: ...\n    weekday: int\n    n: int\n",
    "/typeshed/python-dateutil/dateutil/easter.pyi": "from datetime import date\nfrom typing import Literal\n\nEASTER_JULIAN: Literal[1]\nEASTER_ORTHODOX: Literal[2]\nEASTER_WESTERN: Literal[3]\n\ndef easter(year: int, method: Literal[1, 2, 3] = 3) -> date: ...\n",
    "/typeshed/python-dateutil/dateutil/relativedelta.pyi": "from datetime import date, datetime, timedelta\nfrom typing import SupportsFloat, TypeVar, overload\nfrom typing_extensions import Self, TypeAlias\n\n# See #9817 for why we reexport this here\nfrom ._common import weekday as weekday\n\n_DateT = TypeVar(\"_DateT\", date, datetime)\n# Work around attribute and type having the same name.\n_Weekday: TypeAlias = weekday\n\nMO: weekday\nTU: weekday\nWE: weekday\nTH: weekday\nFR: weekday\nSA: weekday\nSU: weekday\n\nclass relativedelta:\n    years: int\n    months: int\n    days: int\n    leapdays: int\n    hours: int\n    minutes: int\n    seconds: int\n    microseconds: int\n    year: int | None\n    month: int | None\n    weekday: _Weekday | None\n    day: int | None\n    hour: int | None\n    minute: int | None\n    second: int | None\n    microsecond: int | None\n    def __init__(\n        self,\n        dt1: date | None = None,\n        dt2: date | None = None,\n        years: int | None = 0,\n        months: int | None = 0,\n        days: int | None = 0,\n        leapdays: int | None = 0,\n        weeks: int | None = 0,\n        hours: int | None = 0,\n        minutes: int | None = 0,\n        seconds: int | None = 0,\n        microseconds: int | None = 0,\n        year: int | None = None,\n        month: int | None = None,\n        day: int | None = None,\n        weekday: int | _Weekday | None = None,\n        yearday: int | None = None,\n        nlyearday: int | None = None,\n        hour: int | None = None,\n        minute: int | None = None,\n        second: int | None = None,\n        microsecond: int | None = None,\n    ) -> None: ...\n    @property\n    def weeks(self) -> int: ...\n    @weeks.setter\n    def weeks(self, value: int) -> None: ...\n    def normalized(self) -> Self: ...\n    # TODO: use Union when mypy will handle it properly in overloaded operator\n    # methods (#2129, #1442, #1264 in mypy)\n    @overload\n    def __add__(self, other: relativedelta) -> Self: ...\n    @overload\n    def __add__(self, other: timedelta) -> Self: ...\n    @overload\n    def __add__(self, other: _DateT) -> _DateT: ...\n    @overload\n    def __radd__(self, other: relativedelta) -> Self: ...\n    @overload\n    def __radd__(self, other: timedelta) -> Self: ...\n    @overload\n    def __radd__(self, other: _DateT) -> _DateT: ...\n    @overload\n    def __rsub__(self, other: relativedelta) -> Self: ...\n    @overload\n    def __rsub__(self, other: timedelta) -> Self: ...\n    @overload\n    def __rsub__(self, other: _DateT) -> _DateT: ...\n    def __sub__(self, other: relativedelta) -> Self: ...\n    def __neg__(self) -> Self: ...\n    def __bool__(self) -> bool: ...\n    def __nonzero__(self) -> bool: ...\n    def __mul__(self, other: SupportsFloat) -> Self: ...\n    def __rmul__(self, other: SupportsFloat) -> Self: ...\n    def __eq__(self, other: object) -> bool: ...\n    def __ne__(self, other: object) -> bool: ...\n    def __div__(self, other: SupportsFloat) -> Self: ...\n    def __truediv__(self, other: SupportsFloat) -> Self: ...\n    def __abs__(self) -> Self: ...\n    def __hash__(self) -> int: ...\n",
    "/typeshed/python-dateutil/dateutil/rrule.pyi": "import datetime\nfrom _typeshed import Incomplete\nfrom collections.abc import Iterable, Iterator, Sequence\nfrom typing_extensions import TypeAlias\n\nfrom ._common import weekday as weekdaybase\n\nYEARLY: int\nMONTHLY: int\nWEEKLY: int\nDAILY: int\nHOURLY: int\nMINUTELY: int\nSECONDLY: int\n\nclass weekday(weekdaybase): ...\n\nweekdays: tuple[weekday, weekday, weekday, weekday, weekday, weekday, weekday]\nMO: weekday\nTU: weekday\nWE: weekday\nTH: weekday\nFR: weekday\nSA: weekday\nSU: weekday\n\nclass rrulebase:\n    def __init__(self, cache: bool = False) -> None: ...\n    def __iter__(self) -> Iterator[datetime.datetime]: ...\n    def __getitem__(self, item): ...\n    def __contains__(self, item): ...\n    def count(self): ...\n    def before(self, dt, inc: bool = False): ...\n    def after(self, dt, inc: bool = False): ...\n    def xafter(self, dt, count: Incomplete | None = None, inc: bool = False): ...\n    def between(self, after, before, inc: bool = False, count: int = 1): ...\n\nclass rrule(rrulebase):\n    def __init__(\n        self,\n        freq,\n        dtstart: datetime.date | None = None,\n        interval: int = 1,\n        wkst: weekday | int | None = None,\n        count: int | None = None,\n        until: datetime.date | int | None = None,\n        bysetpos: int | Iterable[int] | None = None,\n        bymonth: int | Iterable[int] | None = None,\n        bymonthday: int | Iterable[int] | None = None,\n        byyearday: int | Iterable[int] | None = None,\n        byeaster: int | Iterable[int] | None = None,\n        byweekno: int | Iterable[int] | None = None,\n        byweekday: int | weekday | Iterable[int] | Iterable[weekday] | None = None,\n        byhour: int | Iterable[int] | None = None,\n        byminute: int | Iterable[int] | None = None,\n        bysecond: int | Iterable[int] | None = None,\n        cache: bool = False,\n    ) -> None: ...\n    def replace(self, **kwargs): ...\n\n_RRule: TypeAlias = rrule\n\nclass _iterinfo:\n    rrule: _RRule\n    def __init__(self, rrule: _RRule) -> None: ...\n    yearlen: int | None\n    nextyearlen: int | None\n    yearordinal: int | None\n    yearweekday: int | None\n    mmask: Sequence[int] | None\n    mdaymask: Sequence[int] | None\n    nmdaymask: Sequence[int] | None\n    wdaymask: Sequence[int] | None\n    mrange: Sequence[int] | None\n    wnomask: Sequence[int] | None\n    nwdaymask: Sequence[int] | None\n    eastermask: Sequence[int] | None\n    lastyear: int | None\n    lastmonth: int | None\n    def rebuild(self, year, month): ...\n    def ydayset(self, year, month, day): ...\n    def mdayset(self, year, month, day): ...\n    def wdayset(self, year, month, day): ...\n    def ddayset(self, year, month, day): ...\n    def htimeset(self, hour, minute, second): ...\n    def mtimeset(self, hour, minute, second): ...\n    def stimeset(self, hour, minute, second): ...\n\nclass rruleset(rrulebase):\n    class _genitem:\n        dt: Incomplete\n        genlist: list[Incomplete]\n        gen: Incomplete\n        def __init__(self, genlist, gen) -> None: ...\n        def __next__(self) -> None: ...\n        next = __next__\n        def __lt__(self, other) -> bool: ...\n        def __gt__(self, other) -> bool: ...\n        def __eq__(self, other) -> bool: ...\n        def __ne__(self, other) -> bool: ...\n\n    def __init__(self, cache: bool = False) -> None: ...\n    def rrule(self, rrule: _RRule): ...\n    def rdate(self, rdate): ...\n    def exrule(self, exrule): ...\n    def exdate(self, exdate): ...\n\nclass _rrulestr:\n    def __call__(self, s, **kwargs) -> rrule | rruleset: ...\n\nrrulestr: _rrulestr\n",
    "/typeshed/python-dateutil/dateutil/utils.pyi": "from datetime import datetime, timedelta, tzinfo\n\ndef default_tzinfo(dt: datetime, tzinfo: tzinfo) -> datetime: ...\ndef today(tzinfo: tzinfo | None = None) -> datetime: ...\ndef within_delta(dt1: datetime, dt2: datetime, delta: timedelta) -> bool: ...\n",
    "/typeshed/python-dateutil/dateutil/zoneinfo/__init__.pyi": "from _typeshed import Incomplete\nfrom typing import IO\nfrom typing_extensions import TypeAlias\n\n__all__ = [\"get_zonefile_instance\", \"gettz\", \"gettz_db_metadata\"]\n\n_MetadataType: TypeAlias = dict[str, Incomplete]\n\nclass ZoneInfoFile:\n    zones: dict[Incomplete, Incomplete]\n    metadata: _MetadataType | None\n    def __init__(self, zonefile_stream: IO[bytes] | None = None) -> None: ...\n    def get(self, name, default: Incomplete | None = None): ...\n\ndef get_zonefile_instance(new_instance: bool = False) -> ZoneInfoFile: ...\ndef gettz(name): ...\ndef gettz_db_metadata() -> _MetadataType: ...\n",
    "/typeshed/python-dateutil/dateutil/zoneinfo/rebuild.pyi": "from _typeshed import Incomplete, StrOrBytesPath\nfrom collections.abc import Sequence\nfrom tarfile import TarInfo\n\ndef rebuild(\n    filename: StrOrBytesPath,\n    tag: Incomplete | None = None,\n    format: str = \"gz\",\n    zonegroups: Sequence[str | TarInfo] = [],\n    metadata: Incomplete | None = None,\n) -> None: ...\n",
    "/typeshed/python-dateutil/dateutil/parser/__init__.pyi": "from collections.abc import Callable, Mapping\nfrom datetime import datetime, tzinfo\nfrom typing import IO, Any\nfrom typing_extensions import TypeAlias\n\nfrom .isoparser import isoparse as isoparse, isoparser as isoparser\n\n_FileOrStr: TypeAlias = bytes | str | IO[str] | IO[Any]\n_TzData: TypeAlias = tzinfo | int | str | None\n_TzInfo: TypeAlias = Mapping[str, _TzData] | Callable[[str, int], _TzData]\n\nclass parserinfo:\n    JUMP: list[str]\n    WEEKDAYS: list[tuple[str, ...]]\n    MONTHS: list[tuple[str, ...]]\n    HMS: list[tuple[str, str, str]]\n    AMPM: list[tuple[str, str]]\n    UTCZONE: list[str]\n    PERTAIN: list[str]\n    TZOFFSET: dict[str, int]\n    def __init__(self, dayfirst: bool = False, yearfirst: bool = False) -> None: ...\n    def jump(self, name: str) -> bool: ...\n    def weekday(self, name: str) -> int | None: ...\n    def month(self, name: str) -> int | None: ...\n    def hms(self, name: str) -> int | None: ...\n    def ampm(self, name: str) -> int | None: ...\n    def pertain(self, name: str) -> bool: ...\n    def utczone(self, name: str) -> bool: ...\n    def tzoffset(self, name: str) -> int | None: ...\n    def convertyear(self, year: int) -> int: ...\n    def validate(self, res: datetime) -> bool: ...\n\nclass parser:\n    def __init__(self, info: parserinfo | None = None) -> None: ...\n    def parse(\n        self,\n        timestr: _FileOrStr,\n        default: datetime | None = None,\n        ignoretz: bool = False,\n        tzinfos: _TzInfo | None = None,\n        *,\n        dayfirst: bool | None = ...,\n        yearfirst: bool | None = ...,\n        fuzzy: bool = ...,\n        fuzzy_with_tokens: bool = ...,\n    ) -> datetime: ...\n\nDEFAULTPARSER: parser\n\ndef parse(\n    timestr: _FileOrStr,\n    parserinfo: parserinfo | None = None,\n    *,\n    dayfirst: bool | None = ...,\n    yearfirst: bool | None = ...,\n    ignoretz: bool = ...,\n    fuzzy: bool = ...,\n    fuzzy_with_tokens: bool = ...,\n    default: datetime | None = ...,\n    tzinfos: _TzInfo | None = ...,\n) -> datetime: ...\n\nclass _tzparser: ...\n\nDEFAULTTZPARSER: _tzparser\n\nclass ParserError(ValueError): ...\n",
    "/typeshed/python-dateutil/dateutil/parser/isoparser.pyi": "from _typeshed import SupportsRead\nfrom datetime import date, datetime, time, tzinfo\nfrom typing_extensions import TypeAlias\n\n_Readable: TypeAlias = SupportsRead[str | bytes]\n_TakesAscii: TypeAlias = str | bytes | _Readable\n\nclass isoparser:\n    def __init__(self, sep: str | bytes | None = None): ...\n    def isoparse(self, dt_str: _TakesAscii) -> datetime: ...\n    def parse_isodate(self, datestr: _TakesAscii) -> date: ...\n    def parse_isotime(self, timestr: _TakesAscii) -> time: ...\n    def parse_tzstr(self, tzstr: _TakesAscii, zero_as_utc: bool = True) -> tzinfo: ...\n\ndef isoparse(dt_str: _TakesAscii) -> datetime: ...\n",
    "/typeshed/python-dateutil/dateutil/tz/__init__.pyi": "from .tz import (\n    datetime_ambiguous as datetime_ambiguous,\n    datetime_exists as datetime_exists,\n    gettz as gettz,\n    resolve_imaginary as resolve_imaginary,\n    tzfile as tzfile,\n    tzical as tzical,\n    tzlocal as tzlocal,\n    tzoffset as tzoffset,\n    tzrange as tzrange,\n    tzstr as tzstr,\n    tzutc as tzutc,\n)\n\nUTC: tzutc\n",
    "/typeshed/python-dateutil/dateutil/tz/_common.pyi": "import abc\nfrom datetime import datetime, timedelta, tzinfo\nfrom typing import ClassVar\n\ndef tzname_in_python2(namefunc): ...\ndef enfold(dt: datetime, fold: int = 1): ...\n\nclass _DatetimeWithFold(datetime):\n    @property\n    def fold(self): ...\n\n# Doesn't actually have ABCMeta as the metaclass at runtime,\n# but mypy complains if we don't have it in the stub.\n# See discussion in #8908\nclass _tzinfo(tzinfo, metaclass=abc.ABCMeta):\n    def is_ambiguous(self, dt: datetime) -> bool: ...\n    def fromutc(self, dt: datetime) -> datetime: ...\n\nclass tzrangebase(_tzinfo):\n    def __init__(self) -> None: ...\n    def utcoffset(self, dt: datetime | None) -> timedelta | None: ...\n    def dst(self, dt: datetime | None) -> timedelta | None: ...\n    def tzname(self, dt: datetime | None) -> str: ...\n    def fromutc(self, dt: datetime) -> datetime: ...\n    def is_ambiguous(self, dt: datetime) -> bool: ...\n    __hash__: ClassVar[None]  # type: ignore[assignment]\n    def __ne__(self, other): ...\n    __reduce__ = object.__reduce__\n",
    "/typeshed/python-dateutil/dateutil/tz/tz.pyi": "import datetime\nfrom _typeshed import Incomplete\nfrom typing import ClassVar, Literal, Protocol, TypeVar\n\nfrom ..relativedelta import relativedelta\nfrom ._common import _tzinfo as _tzinfo, enfold as enfold, tzname_in_python2 as tzname_in_python2, tzrangebase as tzrangebase\n\n_DT = TypeVar(\"_DT\", bound=datetime.datetime)\n\nZERO: datetime.timedelta\nEPOCH: datetime.datetime\nEPOCHORDINAL: int\n\nclass tzutc(datetime.tzinfo):\n    def utcoffset(self, dt: datetime.datetime | None) -> datetime.timedelta | None: ...\n    def dst(self, dt: datetime.datetime | None) -> datetime.timedelta | None: ...\n    def tzname(self, dt: datetime.datetime | None) -> str: ...\n    def is_ambiguous(self, dt: datetime.datetime | None) -> bool: ...\n    def fromutc(self, dt: _DT) -> _DT: ...\n    def __eq__(self, other): ...\n    __hash__: ClassVar[None]  # type: ignore[assignment]\n    def __ne__(self, other): ...\n    __reduce__ = object.__reduce__\n\nclass tzoffset(datetime.tzinfo):\n    def __init__(self, name, offset) -> None: ...\n    def utcoffset(self, dt: datetime.datetime | None) -> datetime.timedelta | None: ...\n    def dst(self, dt: datetime.datetime | None) -> datetime.timedelta | None: ...\n    def is_ambiguous(self, dt: datetime.datetime | None) -> bool: ...\n    def tzname(self, dt: datetime.datetime | None) -> str: ...\n    def fromutc(self, dt: _DT) -> _DT: ...\n    def __eq__(self, other): ...\n    __hash__: ClassVar[None]  # type: ignore[assignment]\n    def __ne__(self, other): ...\n    __reduce__ = object.__reduce__\n    @classmethod\n    def instance(cls, name, offset) -> tzoffset: ...\n\nclass tzlocal(_tzinfo):\n    def __init__(self) -> None: ...\n    def utcoffset(self, dt: datetime.datetime | None) -> datetime.timedelta | None: ...\n    def dst(self, dt: datetime.datetime | None) -> datetime.timedelta | None: ...\n    def tzname(self, dt: datetime.datetime | None) -> str: ...\n    def is_ambiguous(self, dt: datetime.datetime | None) -> bool: ...\n    def __eq__(self, other): ...\n    __hash__: ClassVar[None]  # type: ignore[assignment]\n    def __ne__(self, other): ...\n    __reduce__ = object.__reduce__\n\nclass _ttinfo:\n    def __init__(self) -> None: ...\n    def __eq__(self, other): ...\n    __hash__: ClassVar[None]  # type: ignore[assignment]\n    def __ne__(self, other): ...\n\nclass _TZFileReader(Protocol):\n    # optional attribute:\n    # name: str\n    def read(self, __size: int) -> bytes: ...\n    def seek(self, __target: int, __whence: Literal[1]) -> object: ...\n\nclass tzfile(_tzinfo):\n    def __init__(self, fileobj: str | _TZFileReader, filename: str | None = None) -> None: ...\n    def is_ambiguous(self, dt: datetime.datetime | None, idx: int | None = None) -> bool: ...\n    def utcoffset(self, dt: datetime.datetime | None) -> datetime.timedelta | None: ...\n    def dst(self, dt: datetime.datetime | None) -> datetime.timedelta | None: ...\n    def tzname(self, dt: datetime.datetime | None) -> str: ...\n    def __eq__(self, other): ...\n    __hash__: ClassVar[None]  # type: ignore[assignment]\n    def __ne__(self, other): ...\n    def __reduce__(self): ...\n    def __reduce_ex__(self, protocol): ...\n\nclass tzrange(tzrangebase):\n    hasdst: bool\n    def __init__(\n        self,\n        stdabbr: str,\n        stdoffset: int | datetime.timedelta | None = None,\n        dstabbr: str | None = None,\n        dstoffset: int | datetime.timedelta | None = None,\n        start: relativedelta | None = None,\n        end: relativedelta | None = None,\n    ) -> None: ...\n    def transitions(self, year: int) -> tuple[datetime.datetime, datetime.datetime]: ...\n    def __eq__(self, other): ...\n\nclass tzstr(tzrange):\n    hasdst: bool\n    def __init__(self, s: str, posix_offset: bool = False) -> None: ...\n    @classmethod\n    def instance(cls, name, offset) -> tzoffset: ...\n\nclass _ICalReader(Protocol):\n    # optional attribute:\n    # name: str\n    def read(self) -> str: ...\n\nclass tzical:\n    def __init__(self, fileobj: str | _ICalReader) -> None: ...\n    def keys(self): ...\n    def get(self, tzid: Incomplete | None = None): ...\n\nTZFILES: list[str]\nTZPATHS: list[str]\n\ndef datetime_exists(dt: datetime.datetime, tz: datetime.tzinfo | None = None) -> bool: ...\ndef datetime_ambiguous(dt: datetime.datetime, tz: datetime.tzinfo | None = None) -> bool: ...\ndef resolve_imaginary(dt: datetime.datetime) -> datetime.datetime: ...\n\nclass _GetTZ:\n    def __call__(self, name: str | None = ...) -> datetime.tzinfo | None: ...\n    def nocache(self, name: str | None) -> datetime.tzinfo | None: ...\n\ngettz: _GetTZ\n",
    "/typeshed/pytz/pytz/__init__.pyi": "import datetime\nfrom _typeshed import Unused\nfrom collections.abc import Mapping\nfrom typing import ClassVar\n\nfrom .exceptions import (\n    AmbiguousTimeError as AmbiguousTimeError,\n    InvalidTimeError as InvalidTimeError,\n    NonExistentTimeError as NonExistentTimeError,\n    UnknownTimeZoneError as UnknownTimeZoneError,\n)\nfrom .tzinfo import BaseTzInfo as BaseTzInfo, DstTzInfo, StaticTzInfo\n\n# Actually named UTC and then masked with a singleton with the same name\nclass _UTCclass(BaseTzInfo):\n    def localize(self, dt: datetime.datetime, is_dst: bool | None = ...) -> datetime.datetime: ...\n    def normalize(self, dt: datetime.datetime) -> datetime.datetime: ...\n    def tzname(self, dt: datetime.datetime | None) -> str: ...\n    def utcoffset(self, dt: datetime.datetime | None) -> datetime.timedelta: ...\n    def dst(self, dt: datetime.datetime | None) -> datetime.timedelta: ...\n\nutc: _UTCclass\nUTC: _UTCclass\n\ndef timezone(zone: str) -> _UTCclass | StaticTzInfo | DstTzInfo: ...\n\nclass _FixedOffset(datetime.tzinfo):\n    zone: ClassVar[None]\n    def __init__(self, minutes: int) -> None: ...\n    def utcoffset(self, dt: Unused) -> datetime.timedelta | None: ...\n    def dst(self, dt: Unused) -> datetime.timedelta: ...\n    def tzname(self, dt: Unused) -> None: ...\n    def localize(self, dt: datetime.datetime, is_dst: bool = False) -> datetime.datetime: ...\n    def normalize(self, dt: datetime.datetime, is_dst: bool = False) -> datetime.datetime: ...\n\ndef FixedOffset(offset: int, _tzinfos: dict[int, _FixedOffset] = {}) -> _UTCclass | _FixedOffset: ...\n\nall_timezones: list[str]\nall_timezones_set: set[str]\ncommon_timezones: list[str]\ncommon_timezones_set: set[str]\ncountry_timezones: Mapping[str, list[str]]\ncountry_names: Mapping[str, str]\nZERO: datetime.timedelta\nHOUR: datetime.timedelta\nVERSION: str\n",
    "/typeshed/pytz/pytz/exceptions.pyi": "__all__ = [\"UnknownTimeZoneError\", \"InvalidTimeError\", \"AmbiguousTimeError\", \"NonExistentTimeError\"]\n\nclass Error(Exception): ...\nclass UnknownTimeZoneError(KeyError, Error): ...\nclass InvalidTimeError(Error): ...\nclass AmbiguousTimeError(InvalidTimeError): ...\nclass NonExistentTimeError(InvalidTimeError): ...\n",
    "/typeshed/pytz/pytz/lazy.pyi": "from _typeshed import Incomplete\nfrom collections.abc import Iterator, Mapping as DictMixin\n\nclass LazyDict(DictMixin[str, Incomplete]):\n    data: dict[str, Incomplete] | None\n    def __getitem__(self, key: str) -> Incomplete: ...\n    def __contains__(self, key: object) -> bool: ...\n    def __iter__(self) -> Iterator[str]: ...\n    def __len__(self) -> int: ...\n\nclass LazyList(list[Incomplete]):\n    # does not return `Self` type:\n    def __new__(cls, fill_iter: Incomplete | None = None) -> LazyList: ...  # noqa: Y034\n\nclass LazySet(set[Incomplete]):\n    # does not return `Self` type:\n    def __new__(cls, fill_iter: Incomplete | None = None) -> LazySet: ...  # noqa: Y034\n",
    "/typeshed/pytz/pytz/reference.pyi": "import datetime\n\nfrom pytz import UTC as UTC\n\nclass FixedOffset(datetime.tzinfo):\n    def __init__(self, offset: float, name: str) -> None: ...\n    def utcoffset(self, dt: datetime.datetime | None) -> datetime.timedelta: ...\n    def tzname(self, dt: datetime.datetime | None) -> str: ...\n    def dst(self, dt: datetime.datetime | None) -> datetime.timedelta: ...\n\nSTDOFFSET: datetime.timedelta\nDSTOFFSET: datetime.timedelta\n\nclass LocalTimezone(datetime.tzinfo):\n    def utcoffset(self, dt: datetime.datetime) -> datetime.timedelta: ...  # type: ignore[override]\n    def dst(self, dt: datetime.datetime) -> datetime.timedelta: ...  # type: ignore[override]\n    def tzname(self, dt: datetime.datetime) -> str: ...  # type: ignore[override]\n\nLocal: LocalTimezone\nDSTSTART: datetime.datetime\nDSTEND: datetime.datetime\n\ndef first_sunday_on_or_after(dt: datetime.datetime) -> datetime.datetime: ...\n\nclass USTimeZone(datetime.tzinfo):\n    stdoffset: datetime.timedelta\n    reprname: str\n    stdname: str\n    dstname: str\n    def __init__(self, hours: float, reprname: str, stdname: str, dstname: str) -> None: ...\n    def tzname(self, dt: datetime.datetime | None) -> str: ...\n    def utcoffset(self, dt: datetime.datetime | None) -> datetime.timedelta: ...\n    def dst(self, dt: datetime.datetime | None) -> datetime.timedelta: ...\n\nEastern: USTimeZone\nCentral: USTimeZone\nMountain: USTimeZone\nPacific: USTimeZone\n",
    "/typeshed/pytz/pytz/tzfile.pyi": "from typing import IO\n\nfrom pytz.tzinfo import DstTzInfo\n\ndef build_tzinfo(zone: str, fp: IO[bytes]) -> DstTzInfo: ...\n",
    "/typeshed/pytz/pytz/tzinfo.pyi": "import datetime\nfrom abc import abstractmethod\nfrom typing import Any, overload\n\nclass BaseTzInfo(datetime.tzinfo):\n    _utcoffset: datetime.timedelta | None\n    _tzname: str | None\n    zone: str | None  # Actually None but should be set on concrete subclasses\n    # The following abstract methods don't exist in the implementation, but\n    # are implemented by all sub-classes.\n    @abstractmethod\n    def localize(self, dt: datetime.datetime) -> datetime.datetime: ...\n    @abstractmethod\n    def normalize(self, dt: datetime.datetime) -> datetime.datetime: ...\n    @abstractmethod\n    def tzname(self, dt: datetime.datetime | None) -> str: ...\n    @abstractmethod\n    def utcoffset(self, dt: datetime.datetime | None) -> datetime.timedelta | None: ...\n    @abstractmethod\n    def dst(self, dt: datetime.datetime | None) -> datetime.timedelta | None: ...\n\nclass StaticTzInfo(BaseTzInfo):\n    def fromutc(self, dt: datetime.datetime) -> datetime.datetime: ...\n    def localize(self, dt: datetime.datetime, is_dst: bool | None = False) -> datetime.datetime: ...\n    def normalize(self, dt: datetime.datetime, is_dst: bool | None = False) -> datetime.datetime: ...\n    def tzname(self, dt: datetime.datetime | None, is_dst: bool | None = None) -> str: ...\n    def utcoffset(self, dt: datetime.datetime | None, is_dst: bool | None = None) -> datetime.timedelta: ...\n    def dst(self, dt: datetime.datetime | None, is_dst: bool | None = None) -> datetime.timedelta: ...\n\nclass DstTzInfo(BaseTzInfo):\n    def __init__(self, _inf: Any = None, _tzinfos: Any = None) -> None: ...\n    def fromutc(self, dt: datetime.datetime) -> datetime.datetime: ...\n    def localize(self, dt: datetime.datetime, is_dst: bool | None = False) -> datetime.datetime: ...\n    def normalize(self, dt: datetime.datetime) -> datetime.datetime: ...\n    def tzname(self, dt: datetime.datetime | None, is_dst: bool | None = None) -> str: ...\n    # https://github.com/python/mypy/issues/12379\n    @overload  # type: ignore[override]\n    def utcoffset(self, dt: None, is_dst: bool | None = None) -> None: ...\n    @overload\n    def utcoffset(self, dt: datetime.datetime, is_dst: bool | None = None) -> datetime.timedelta: ...\n    def dst(self, dt: datetime.datetime | None, is_dst: bool | None = None) -> datetime.timedelta | None: ...\n",
    "/typeshed/numpy/__init__.pyi": "\"\"\"Public API of numpy\"\"\"\nimport os\nfrom typing import (\n    Any,\n    Callable,\n    Dict,\n    Generic,\n    Iterator,\n    IO,\n    List,\n    Optional,\n    Sequence,\n    Tuple,\n    Type,\n    TypeVar,\n    Union,\n    overload,\n    Iterable,\n    Generator,\n)\nfrom typing_extensions import Protocol, Literal\nfrom pathlib import Path\nimport builtins\n\nfrom . import testing, random, ma, linalg\n\nfrom pandas import Series\n\n_T = TypeVar(\"_T\")\n\n_Scalar = TypeVar(\"_Scalar\", bound=void)\n\n# void is the base class of all the types that an ndarray can have\nclass void:\n    @property\n    def dtype(self: _DTypeObj) -> _dtype[_DTypeObj]: ...\n    def astype(self, dtype: Type[_DType]) -> _DType: ...\n    def copy(self: _Scalar) -> _Scalar: ...\n\n# a smaller-bit integer can act like a bigger integer in the sense that if you add an int16 and an\n# int64, then numpy will upgrade the int16 to an int64 and add them\n# and this is why we let int32 be a subclass of int64; and similarly for float32 and float64\n# the same logic applies when adding unsigned and signed values (uint + int -> int)\n\n# this would be the correct definition, but it makes `int` conflict with `float`\n# class float64(void, float): ...\nclass float64(void, int):\n    def __float__(self) -> float: ...\n\nclass float32(float64): ...\nclass float16(float32): ...\n\nfloating = float64\nnumber = float64\n\nclass int64(float64): ...\nclass int32(int64, float64): ...\nclass int16(int32, float32): ...\nclass int8(int16, float16): ...\nclass uint64(int64): ...\nclass uint32(uint64, int32): ...\nclass uint16(uint32, int16): ...\nclass uint8(uint16, int8): ...\nclass bool_(int8): ...\nclass str_(void, str): ...\nclass object_(void): ...\n\ninteger = int64\n\n_DType = TypeVar(\n    \"_DType\",\n    bool_,\n    float16,\n    float32,\n    float64,\n    int8,\n    int16,\n    int32,\n    int64,\n    str_,\n    uint8,\n    uint16,\n    uint32,\n    uint64,\n    covariant=True,\n)\n_DType2 = TypeVar(\n    \"_DType2\",\n    bool_,\n    float16,\n    float32,\n    float64,\n    int8,\n    int16,\n    int32,\n    int64,\n    str_,\n    uint8,\n    uint16,\n    uint32,\n    uint64,\n    covariant=True,\n)\n_DTypeObj = TypeVar(\"_DTypeObj\", bound=Union[void, int, float])\n_ShapeType = Union[int, Tuple[int, ...], List[int]]\n_AxesType = Union[int, Tuple[int, ...], List[int]]\n_InterpolationType = Literal[\"linear\", \"lower\", \"higher\", \"midpoint\", \"nearest\"]\n_OrderType = Union[str, Sequence[str]]\n_ScalarLike = Union[_DType, str, int, float]\n_ConditionType = Union[ndarray[bool_], bool_, bool]\nnewaxis: None = ...\n\n_AnyNum = Union[int, float, bool]\n# generic types that are only allowed to take on dtype values\n\n_Float = TypeVar(\"_Float\", float16, float32, float64)\n_FloatLike = TypeVar(\"_FloatLike\", bound=Union[float64, float])\n_Int = TypeVar(\"_Int\", bool_, int8, int16, int32, int64, uint8, uint16, uint32, uint64)\n_IntLike = TypeVar(\"_IntLike\", bound=Union[int64, int])\n_BoolLike = TypeVar(\"_BoolLike\", bound=Union[bool_, bool])\n\n_NestedList = Union[List[_T], List[List[_T]], List[List[List[_T]]], List[List[List[List[_T]]]]]\n\nclass dtype(Generic[_DTypeObj]):\n    @overload\n    def __init__(self: dtype[_DTypeObj], obj: Type[_DTypeObj]) -> None: ...\n    @overload\n    def __init__(self, obj: str) -> None: ...\n    @property\n    def type(self) -> Type[_DTypeObj]: ...\n\n_dtype = dtype\n\nclass ndarray(Generic[_DType]):\n    \"\"\"\n    The main object in the numpy library.\n    \"\"\"\n\n    #\n    # Array-like structures attributes\n    #\n    dtype: _dtype[_DType]\n    size: int\n    ndim: int\n    shape: Tuple[int, ...]\n\n    #\n    # Array-like methods\n    #\n    def __init__(\n        self,\n        shape: Tuple[int, ...],\n        dtype: Optional[Type[_DType]] = ...,\n        buffer: Optional[Any] = ...,\n        offset: Optional[int] = ...,\n        strides: Optional[Tuple[int, ...]] = ...,\n        order: Optional[str] = ...,\n    ) -> None: ...\n    def all(self, axis: Optional[_AxesType] = ..., keepdims: bool = ...) -> ndarray[_DType]: ...\n    def any(self, axis: Optional[_AxesType] = ..., keepdims: bool = ...) -> ndarray[_DType]: ...\n    def argmax(self, axis: Optional[int] = ...) -> ndarray[_DType]: ...\n    def argmin(self, axis: Optional[int] = ...) -> ndarray[_DType]: ...\n    # def argpartition(self, kth: Union[int, Sequence[int]], axis: Optional[int]=-1,\n    #                  kind: str='introselect', order: _OrderType=None) -> ndarray[_DType]: ...\n    def argsort(\n        self, axis: Optional[int] = ..., kind: str = ..., order: Optional[_OrderType] = ...\n    ) -> ndarray[_DType]: ...\n    # _DType has to be split up like this for some reason; I don't fully understand it\n    @overload\n    def astype(self, dtype: Type[_Int], copy: bool = ...) -> ndarray[_Int]: ...\n    @overload\n    def astype(self, dtype: Type[_Float], copy: bool = ...) -> ndarray[_Float]: ...\n    @overload\n    def astype(self, dtype: Type[str_], copy: bool = ...) -> ndarray[str_]: ...\n    # the bool overload has to come before the int overload because bool is a subclass of int\n    @overload\n    def astype(self, dtype: Type[bool], copy: bool = ...) -> ndarray[bool_]: ...\n    @overload\n    def astype(self, dtype: Type[int], copy: bool = ...) -> ndarray[int64]: ...\n    @overload\n    def astype(self, dtype: Type[float], copy: bool = ...) -> ndarray[float64]: ...\n    @overload\n    def astype(self, dtype: Type[str], copy: bool = ...) -> ndarray[str_]: ...\n    def byteswap(self, inplace: bool = ...) -> ndarray[_DType]: ...\n    def choose(self, choices: Sequence[ndarray[_DType]], mode: str = ...) -> ndarray[_DType]: ...\n    def clip(self, a_min: _AnyNum, a_max: _AnyNum) -> ndarray[_DType]: ...\n    def compress(self, condition: Sequence[bool], axis: Optional[int] = ...) -> ndarray[_DType]: ...\n    def conj(self) -> ndarray[_DType]: ...\n    def conjugate(self) -> ndarray[_DType]: ...\n    def copy(self, order: str = ...) -> ndarray[_DType]: ...\n    def cumprod(self, axis: Optional[int] = ..., dtype: Optional[Any] = ...) -> ndarray[_DType]: ...\n    def cumsum(\n        self, axis: Optional[int] = ..., dtype: Optional[Type[_DType]] = ...\n    ) -> ndarray[_DType]: ...\n    def diagonal(\n        self, offset: int = ..., axis1: int = ..., axis2: int = ...\n    ) -> ndarray[_DType]: ...\n    def dot(self, b: ndarray[_DType]) -> ndarray[_DType]: ...\n    def dump(self, file: str) -> None: ...\n    def dumps(self) -> str: ...\n    # def fill(self, value: _S) -> None: ...\n    def flatten(self, order: str = ...) -> ndarray[_DType]: ...\n    def getfield(self, dtype: Type[_DType], offset: int = ...) -> ndarray[_DType]: ...\n    def item(self) -> _DType: ...\n    def itemset(self, arg0: Union[int, Tuple[int, ...]], arg1: Optional[Any] = ...) -> None: ...\n    def max(self) -> _DType: ...\n    @overload\n    def mean(self: ndarray[float32]) -> float32: ...\n    @overload\n    def mean(self: ndarray[float32], axis: _AxesType) -> ndarray[float32]: ...\n    @overload\n    def mean(self) -> float64: ...\n    @overload\n    def mean(self, axis: _AxesType) -> ndarray[float64]: ...\n    def min(self) -> _DType: ...\n    def newbyteorder(self, new_order: str = ...) -> ndarray[_DType]: ...\n    def nonzero(self) -> Tuple[ndarray[int64], ...]: ...\n    def partition(\n        self, kth: _AxesType, axis: int = ..., kind: str = ..., order: Optional[_OrderType] = ...\n    ) -> None: ...\n    def prod(\n        self,\n        axis: Optional[_AxesType] = ...,\n        dtype: Optional[Type[_DType]] = ...,\n        keepdims: bool = ...,\n    ) -> ndarray[_DType]: ...\n    def ptp(self, axis: Optional[int] = ...) -> ndarray[_DType]: ...\n    def put(self, ind: ndarray[_DType], v: ndarray[_DType], mode: str = ...) -> None: ...\n    def ravel(self, order: str = ...) -> ndarray[_DType]: ...\n    def repeat(\n        self, repeats: Union[int, Sequence[int]], axis: Optional[int] = ...\n    ) -> ndarray[_DType]: ...\n    @overload\n    def reshape(self, *newshape: int) -> ndarray[_DType]: ...\n    @overload\n    def reshape(\n        self, newshape: Union[Tuple[int, ...], List[int]], order: str = ...\n    ) -> ndarray[_DType]: ...\n    def resize(self, new_shape: _ShapeType, refcheck: bool = ...) -> None: ...\n    def round(self, decimals: int = ...) -> ndarray[_DType]: ...\n    # def searchsorted(self, v: Union[_S, ndarray[_DType]], side: str='left',\n    #                  sorter: ndarray[_DType]=None) -> ndarray[_DType]: ...\n    def setfield(self, val: Any, dtype: Type[_DType], offset: int = ...) -> None: ...\n    def setflags(\n        self, write: Optional[bool] = ..., align: Optional[bool] = ..., uic: Optional[bool] = ...\n    ) -> None: ...\n    def sort(self, axis: int = ..., kind: str = ..., order: Optional[_OrderType] = ...) -> None: ...\n    def squeeze(self, axis: Optional[_AxesType] = ...) -> ndarray[_DType]: ...\n    @overload\n    def std(self: ndarray[float32]) -> float32: ...\n    @overload\n    def std(self) -> float64: ...\n    @overload\n    def std(\n        self,\n        axis: _AxesType,\n        dtype: Optional[Type[_DType]] = ...,\n        ddof: int = ...,\n        keepdims: bool = ...,\n    ) -> ndarray[_DType]: ...\n    @overload\n    def sum(self) -> _DType: ...\n    @overload\n    def sum(self, axis: Optional[_AxesType], keepdims: bool = ...) -> ndarray[_DType]: ...\n    def swapaxes(self, axis1: int, axis2: int) -> ndarray[_DType]: ...\n    def take(\n        self, indices: Sequence[int], axis: Optional[int] = ..., mode: str = ...\n    ) -> ndarray[_DType]: ...\n    def tobytes(self, order: str = ...) -> bytes: ...\n    def tofile(\n        self,\n        fid: object,\n        sep: str = ...,  # TODO fix fid definition (There's a bug in mypy io's namespace https://github.com/python/mypy/issues/1462)\n        format: str = ...,\n    ) -> None: ...\n    # for some reason, you can not use _Float to narrow down the type of ndarray here:\n    @overload\n    def tolist(\n        self: Union[ndarray[bool_], ndarray[int8], ndarray[int16], ndarray[int32], ndarray[int64]]\n    ) -> Sequence[int]: ...\n    @overload\n    def tolist(self: Union[ndarray[float32], ndarray[float64]]) -> Sequence[float]: ...\n    @overload\n    def tolist(self: ndarray[str_]) -> Sequence[str]: ...\n    def tostring(self, order: str = ...) -> bytes: ...\n    def trace(\n        self,\n        offset: int = ...,\n        axis1: int = ...,\n        axis2: int = ...,\n        dtype: Optional[Type[_DType]] = ...,\n    ) -> ndarray[_DType]: ...\n    def transpose(self, axes: Optional[_AxesType] = ...) -> ndarray[_DType]: ...\n    def var(\n        self,\n        axis: Optional[_AxesType] = ...,\n        dtype: Optional[Type[_DType]] = ...,\n        ddof: int = ...,\n        keepdims: bool = ...,\n    ) -> ndarray[_DType]: ...\n    def view(\n        self,\n        dtype: Optional[Union[Type[_DType], Type[ndarray[_DType]]]] = ...,\n        type: Optional[type] = ...,\n    ) -> ndarray[_DType]: ...\n    #\n    # Magic methods\n    #\n    def __abs__(self) -> ndarray[_DType]: ...\n    @overload\n    def __add__(self, value: ndarray[_DType]) -> ndarray[_DType]: ...\n    @overload\n    def __add__(self, value: _DType) -> ndarray[_DType]: ...\n    @overload\n    def __add__(self, value: float) -> ndarray[float64]: ...\n    def __and__(self, value: object) -> ndarray[_DType]: ...\n    @overload\n    def __array__(self) -> ndarray[_DType]: ...\n    @overload\n    def __array__(self, dtype: Type[_DType2]) -> ndarray[_DType2]: ...\n    def __array_prepare__(self, context: Optional[object] = ...) -> ndarray[_DType]: ...\n    def __array_wrap__(self, context: Optional[object] = ...) -> ndarray[_DType]: ...\n    def __bool__(self) -> bool: ...\n    def __complex__(self) -> complex: ...\n    def __contains__(self, key: object) -> bool: ...\n    def __copy__(self) -> ndarray[_DType]: ...\n    def __deepcopy__(self) -> ndarray[_DType]: ...\n    def __delattr__(self, name: str) -> None: ...\n    def __delitem__(self, key: str) -> None: ...\n    def __dir__(self) -> List[str]: ...\n    def __divmod__(self, value: object) -> Tuple[ndarray[_DType], ndarray[_DType]]: ...\n    def __eq__(self, value: object) -> ndarray[bool_]: ...  # type: ignore\n    def __float__(self) -> float: ...\n    def __floordiv__(self, value: object) -> ndarray[_DType]: ...\n    def __ge__(self, value: object) -> ndarray[bool_]: ...\n    def __getattribute__(self, name: str) -> Any: ...\n    @overload\n    def __getitem__(self, key: Union[int, Tuple[int, ...]]) -> _DType: ...\n    @overload\n    def __getitem__(\n        self,\n        key: Union[\n            None,\n            slice,\n            str,\n            ndarray[_Int],\n            List[int],\n            Tuple[int, Union[slice, ellipsis, None]],\n            Tuple[Union[slice, ellipsis, None], int],\n            Tuple[Union[slice, ellipsis, None], Union[slice, ellipsis, None], int],\n            Tuple[Union[ndarray[_Int], slice, ellipsis, None], ...],\n        ],\n    ) -> ndarray[_DType]: ...\n    def __gt__(self, value: object) -> ndarray[bool_]: ...\n    @overload\n    def __iadd__(self, value: ndarray[_DType]) -> ndarray[_DType]: ...\n    @overload\n    def __iadd__(self, value: _DType) -> ndarray[_DType]: ...\n    @overload\n    def __iadd__(self, value: float) -> ndarray[float64]: ...\n    def __iand__(self, value: object) -> ndarray[bool_]: ...\n    def __ifloordiv__(self, value: object) -> None: ...\n    def __ilshift__(self, value: object) -> None: ...\n    def __imatmul__(self, value: ndarray[_DType]) -> None: ...\n    def __imod__(self, value: object) -> None: ...\n    def __imul__(self, value: object) -> None: ...\n    def __index__(self) -> int: ...\n    def __int__(self) -> int: ...\n    def __invert__(self) -> ndarray[_DType]: ...\n    def __ior__(self, value: object) -> None: ...\n    def __ipow__(self, value: object) -> None: ...\n    def __irshift__(self, value: object) -> None: ...\n    def __isub__(self, value: object) -> None: ...\n    def __iter__(self) -> Iterator[_DType]: ...\n    def __itruediv__(self, value: object) -> ndarray[float64]: ...\n    def __ixor__(self, value: object) -> None: ...\n    def __le__(self, value: object) -> ndarray[_DType]: ...\n    def __len__(self) -> int: ...\n    def __lshift__(self, value: object) -> ndarray[_DType]: ...\n    def __lt__(self, value: object) -> ndarray[_DType]: ...\n    def __matmul__(self, value: ndarray[_DType]) -> ndarray[_DType]: ...\n    def __mod__(self, value: object) -> ndarray[_DType]: ...\n    def __mul__(self, value: object) -> ndarray[_DType]: ...\n    def __ne__(self, value: object) -> ndarray[_DType]: ...  # type: ignore\n    def __neg__(self) -> ndarray[_DType]: ...\n    def __or__(self, value: object) -> ndarray[_DType]: ...\n    def __pos__(self) -> ndarray[_DType]: ...\n    def __pow__(self, value: object) -> ndarray[_DType]: ...\n    @overload\n    def __radd__(self, value: ndarray[_DType]) -> ndarray[_DType]: ...\n    @overload\n    def __radd__(self, value: _DType) -> ndarray[_DType]: ...\n    def __rand__(self, value: object) -> ndarray[_DType]: ...\n    def __rdivmod__(self, value: object) -> Tuple[ndarray[_DType], ndarray[_DType]]: ...\n    def __rfloordiv__(self, value: object) -> ndarray[_DType]: ...\n    def __rlshift__(self, value: object) -> ndarray[_DType]: ...\n    def __rmatmul__(self, value: object) -> ndarray[_DType]: ...\n    def __rmod__(self, value: object) -> ndarray[_DType]: ...\n    def __rmul__(self, value: object) -> ndarray[_DType]: ...\n    def __ror__(self, value: object) -> ndarray[_DType]: ...\n    def __rpow__(self, value: object) -> ndarray[_DType]: ...\n    def __rrshift__(self, value: object) -> ndarray[_DType]: ...\n    def __rshift__(self, value: object) -> ndarray[_DType]: ...\n    def __rsub__(self, value: object) -> ndarray[_DType]: ...\n    @overload\n    def __rtruediv__(\n        self: ndarray[float32], value: Union[ndarray[float32], float32, float]\n    ) -> ndarray[float32]: ...\n    @overload\n    def __rtruediv__(self, value: object) -> ndarray[float64]: ...\n    def __rxor__(self, value: object) -> ndarray[_DType]: ...\n    def __setattr__(self, name: str, value: Any) -> None: ...\n    def __setitem__(self, key: Any, value: Any) -> None: ...\n    def __str__(self) -> str: ...\n    def __sub__(self, value: object) -> ndarray[_DType]: ...\n    @overload\n    def __truediv__(\n        self: ndarray[float32], value: Union[ndarray[float32], float32, float]\n    ) -> ndarray[float32]: ...\n    @overload\n    def __truediv__(self, value: object) -> ndarray[float64]: ...\n    def __xor__(self, value: object) -> ndarray[_DType]: ...\n\nclass Array(Protocol[_DType]):\n    def __array__(self) -> Union[ndarray[_DType], Sequence[Sequence[_DType]]]: ...\n\n_ArrayLike = Union[Array[_DType], Sequence[_DType]]\n_Coercable = Union[_ArrayLike, _DTypeObj]\n\n######\n# numpy's scalar hierarchy (http://docs.scipy.org/doc/numpy/reference/arrays.scalars.html#scalars)\n######\n# class bool_: ...\n# class number: ...\n# class integer(number, int): ...\n# class signedinteger(integer): ...\n# class byte(signedinteger): ...\n# class short(signedinteger): ...\n# class intc(signedinteger): ...\n# class int_(signedinteger): ...\n# class longlong(signedinteger): ...\n# class int8(signedinteger): ...\n# class int16(signedinteger): ...\n# class int32(signedinteger): ...\n# class int64(signedinteger): ...\n# class unsignedinteger(integer): ...\n# class ubyte(unsignedinteger): ...\n# class ushort(unsignedinteger): ...\n# class uintc(unsignedinteger): ...\n# class uint(unsignedinteger): ...\n# class ulonglong(unsignedinteger): ...\n# class uint8(signedinteger): ...\n# class uint16(signedinteger): ...\n# class uint32(signedinteger): ...\n# class uint64(signedinteger): ...\n# class inexact(number[float]): ...\n# class floating(inexact): ...\n# class half(floating): ...\n# class single(floating): ...\n# class float_(floating): ...\n# class longfloat_(floating): ...\n# class float16(floating): ...\n# class float64(floating): ...\n# class float128(floating): ...\n# class complexfloating(inexact): ...\n# class csingle(complexfloating): ...\n# class complex_(complexfloating): ...\n# class clongfloat(complexfloating): ...\n# class complex64(complexfloating): ...\n# class complex128(complexfloating): ...\n# class complex256(complexfloating): ...\n# class flexible(generic[_Scalar], Generic[_Scalar]): ...\n# class character(flexible[str]): ...\n# class str_(character): ...\n# class unicode_(character): ...\n# class void(flexible[None]): ...\n\n#\n# Array creation routines\n#\n# np.array: first check if the dtype has been set explicitly\n@overload\ndef array(\n    object: Union[_NestedList[Any], Iterable[ndarray], ndarray], dtype: Type[_DType]\n) -> ndarray[_DType]: ...\n@overload\ndef array(\n    object: Union[_NestedList[Any], Iterable[ndarray], ndarray], dtype: Type[int]\n) -> ndarray[int64]: ...\n@overload\ndef array(\n    object: Union[_NestedList[Any], Iterable[ndarray], ndarray], dtype: Type[float]\n) -> ndarray[float64]: ...\n\n# np.array: then check if it is a list of some type. check the most specific first\n@overload\ndef array(object: _NestedList[bool]) -> ndarray[bool_]: ...\n@overload\ndef array(object: _NestedList[_Int]) -> ndarray[_Int]: ...\n@overload\ndef array(object: _NestedList[_Float]) -> ndarray[_Float]: ...\n@overload\ndef array(object: _NestedList[int]) -> ndarray[int64]: ...\n@overload\ndef array(object: _NestedList[float]) -> ndarray[float64]: ...\n@overload\ndef array(object: _NestedList[str]) -> ndarray[str_]: ...\n@overload\ndef array(object: str) -> ndarray[str_]: ...\n@overload\ndef array(object: Union[ndarray[_DType], _NestedList[ndarray[_DType]]]) -> ndarray[_DType]: ...\n@overload\ndef array(object: Tuple) -> ndarray[bool_]: ...\n@overload\ndef arange(start: int, stop: int = ..., step: int = ...) -> ndarray[int64]: ...\n@overload\ndef arange(start: float, stop: float = ..., step: float = ...) -> ndarray[float64]: ...\n@overload\ndef arange(range_: int, dtype: Type[_DType]) -> ndarray[_DType]: ...\n@overload\ndef arange(range_: float) -> ndarray[float64]: ...\ndef ascontiguousarray(a: Any, dtype: Optional[Type[_DType]] = ...) -> ndarray: ...\ndef copy(a: Any, order: Optional[str] = ...) -> ndarray: ...\ndef cumprod(\n    a: ndarray[_DType], axis: Optional[int] = ..., dtype: Optional[Type[_DType]] = ...\n) -> ndarray[_DType]: ...\ndef cumsum(\n    a: ndarray[_DType], axis: Optional[int] = ..., dtype: Optional[Type[_DType]] = ...\n) -> ndarray[_DType]: ...\ndef delete(\n    arr: ndarray[_DType], object: Union[int, List[int], slice], axis: Optional[int] = ...\n) -> ndarray[_DType]: ...\n@overload\ndef empty(shape: _ShapeType, dtype: Type[_Int]) -> ndarray[_Int]: ...\n@overload\ndef empty(shape: _ShapeType, dtype: Type[_Float]) -> ndarray[_Float]: ...\n@overload\ndef empty(shape: _ShapeType, dtype: Type[str_]) -> ndarray[str_]: ...\n@overload\ndef empty(shape: _ShapeType, dtype: Type[bool]) -> ndarray[bool_]: ...\n@overload\ndef empty(shape: _ShapeType, dtype: Type[int]) -> ndarray[int64]: ...\n@overload\ndef empty(shape: _ShapeType, dtype: Type[float] = ...) -> ndarray[float64]: ...\n@overload\ndef empty(shape: _ShapeType, dtype: Type[str]) -> ndarray[str_]: ...\ndef empty_like(\n    a: Any, dtype: Optional[Any] = ..., order: str = ..., subok: bool = ...\n) -> ndarray: ...\ndef eye(N: int, M: Optional[int] = ..., k: int = ..., dtype: Type[_DType] = ...) -> ndarray: ...\ndef flatnonzero(a: ndarray[_DType]) -> ndarray[int64]: ...\ndef full(\n    shape: _ShapeType, fill_value: Any, dtype: Optional[Type[_DType]] = ..., order: str = ...\n) -> ndarray: ...\ndef full_like(\n    a: Any,\n    fill_value: Any,\n    dtype: Optional[Type[_DType]] = ...,\n    order: str = ...,\n    subok: bool = ...,\n) -> ndarray: ...\n\n# def fromfunction(\n#     function: Callable[..., _S], shape: _ShapeType, dtype: Type[_DType] = float\n# ) -> ndarray[_S]: ...\ndef fromiter(iterable: Iterator, dtype: Type[_DType], count: int = ...) -> ndarray: ...\ndef fromstring(\n    string: str, dtype: Type[_DType] = ..., count: int = ..., sep: str = ...\n) -> ndarray: ...\ndef frombuffer(\n    buffer: Union[bytes, bytearray, memoryview],\n    dtype: Type[_DType] = ...,\n    count: int = ...,\n    offset: int = ...,\n) -> ndarray: ...\ndef histogramdd(\n    a: ndarray,\n    bins: Optional[Union[ndarray, Series, List, int]],\n    range: Optional[List[Tuple[number, number]]] = ...,\n    density: bool = ...,\n    normed: bool = ...,\n    weights: Optional[Union[ndarray, Series, List[number]]] = ...,\n) -> Tuple[ndarray, List[number]]: ...\ndef identity(n: int, dtype: Optional[Type[_DType]] = ...) -> ndarray: ...\ndef insert(arr: ndarray[_DType], index: int, value: _DType) -> ndarray[_DType]: ...\n@overload\ndef linspace(\n    start: float, stop: float, num: int = ..., endpoint: bool = ...\n) -> ndarray[float64]: ...\n@overload\ndef linspace(\n    start: float, stop: float, *, dtype: Type[_DType], num: int = ..., endpoint: bool = ...\n) -> ndarray[_DType]: ...\ndef load(file: Union[str, os.PathLike, IO], encoding: str = ...) -> Dict[str, ndarray]: ...\ndef loadtxt(\n    fname: Any,\n    dtype: Type[_DType] = ...,\n    comments: Union[str, Sequence[str]] = ...,\n    delimiter: Optional[str] = ...,\n    converters: Optional[Dict[int, Callable[[Any], float]]] = ...,\n    skiprows: int = ...,\n    usecols: Optional[Sequence[int]] = ...,\n    unpack: bool = ...,\n    ndmin: int = ...,\n) -> ndarray: ...\n@overload\ndef ones(shape: _ShapeType, order: str = ...) -> ndarray[float64]: ...\n@overload\ndef ones(shape: _ShapeType, dtype: Type[_DType] = ..., order: str = ...) -> ndarray[_DType]: ...\n@overload\ndef ones_like(a: ndarray[_DType], subok: bool = ...) -> ndarray[_DType]: ...\n@overload\ndef ones_like(a: ndarray, dtype: Type[_DType], subok: bool = ...) -> ndarray[_DType]: ...\n@overload\ndef repeat(a: _DType, repeats: _IntLike) -> ndarray[_DType]: ...\n@overload\ndef repeat(a: int, repeats: _IntLike) -> ndarray[int64]: ...\n@overload\ndef repeat(a: float, repeats: _IntLike) -> ndarray[float64]: ...\n@overload\ndef repeat(a: ndarray[_DType], repeats: _IntLike) -> ndarray[_DType]: ...\n@overload\ndef zeros(shape: _ShapeType, order: str = ...) -> ndarray[float64]: ...\n@overload\ndef zeros(shape: _ShapeType, dtype: Type[_DType] = ..., order: str = ...) -> ndarray[_DType]: ...\n@overload\ndef zeros_like(a: ndarray[_DType], order: str = ..., subok: bool = ...) -> ndarray[_DType]: ...\n@overload\ndef zeros_like(a: ndarray, dtype: Type[_DType], subok: bool = ...) -> ndarray[_DType]: ...\n\n#\n# Array transformation routines\n#\ndef abs(x: ndarray[_DType]) -> ndarray[_DType]: ...\ndef add(x1: ndarray[_DType], x2: ndarray[_DType]) -> ndarray[_DType]: ...\n@overload\ndef all(a: ndarray[_DType]) -> bool_: ...\n@overload\ndef all(a: ndarray[_DType], axis: _AxesType) -> ndarray[bool_]: ...\n@overload\ndef amax(a: ndarray[_DType]) -> _DType: ...\n@overload\ndef amax(a: ndarray[_DType], axis: _AxesType) -> ndarray[_DType]: ...\ndef append(a: _ArrayLike, b: _ArrayLike, axis: _AxesType = ...) -> ndarray: ...\n@overload\ndef argmin(a: Sequence, axis: _AxesType = ...) -> int64: ...\n@overload\ndef argmin(\n    a: ndarray[_DType], axis: _AxesType = ..., out: Optional[ndarray[_DType]] = ...\n) -> ndarray[int64]: ...\n@overload\ndef argmax(a: Sequence, axis: _AxesType = ...) -> int64: ...\n@overload\ndef argmax(\n    a: ndarray[_DType], axis: _AxesType = ..., out: Optional[ndarray[_DType]] = ...\n) -> ndarray[int64]: ...\ndef argsort(a: ndarray[_DType], axis: _AxesType = ...) -> ndarray[_DType]: ...\ndef array_equal(a1: ndarray[_DType], a2: ndarray[_DType]) -> bool: ...\ndef array_split(\n    ary: ndarray[_DType], indices_or_sections: Union[int, List[int]], axis: int = ...\n) -> List[ndarray[_DType]]: ...\ndef asscaler(x: _Int) -> int: ...\n\n# np.asarray\n@overload\ndef asarray(a: ndarray, dtype: Type[_Int]) -> ndarray[_Int]: ...\n@overload\ndef asarray(a: ndarray, dtype: Type[_Float]) -> ndarray[_Float]: ...\n@overload\ndef asarray(a: ndarray, dtype: Type[str_]) -> ndarray[str_]: ...\n\n# the bool overload has to come before the int overload because bool is a subclass of int\n@overload\ndef asarray(a: ndarray, dtype: Type[bool]) -> ndarray[bool_]: ...\n@overload\ndef asarray(a: ndarray, dtype: Type[int]) -> ndarray[int64]: ...\n@overload\ndef asarray(a: ndarray, dtype: Type[float]) -> ndarray[float64]: ...\n@overload\ndef asarray(a: ndarray, dtype: Type[str]) -> ndarray[str_]: ...\n@overload\ndef atleast_2d(ary: _Coercable) -> ndarray: ...\n@overload\ndef atleast_2d(ar: _Coercable, *ary: _Coercable) -> List[ndarray]: ...\n@overload\ndef ceil(a: _FloatLike) -> _FloatLike: ...\n@overload\ndef ceil(a: ndarray[_DType]) -> ndarray[_DType]: ...\ndef clip(a: ndarray[_DType], a_min: _DType, a_max: _DType) -> ndarray[_DType]: ...\ndef concatenate(arrays: Sequence[_ArrayLike[_DType]], axis: _AxesType = ...) -> ndarray[_DType]: ...\ndef corrcoef(\n    x: ndarray[_DType], y: Optional[ndarray[_DType]] = ..., rowvar: Optional[bool] = ...\n) -> ndarray[float64]: ...\ndef cos(\n    x: Union[_DType, ndarray[_DType], int, float, List[int], List[float]],\n    out: Optional[Union[ndarray[_DType], Tuple[ndarray[_DType], None]]] = ...,\n    where: Optional[_ArrayLike] = ...,\n) -> Union[_DType, ndarray[_DType]]: ...\ndef cov(m: ndarray[_DType], rowvar: Optional[bool]) -> ndarray[float64]: ...\ndef deg2rad(\n    x: Union[_DType, ndarray[_DType], int, float, List[int], List[float]],\n    out: Optional[Union[ndarray[_DType], Tuple[ndarray[_DType], None]]] = ...,\n    where: Optional[_ArrayLike] = ...,\n) -> Union[_DType, ndarray[_DType]]: ...\ndef diag(a: ndarray[_DType]) -> ndarray[_DType]: ...\ndef diff(\n    a: ndarray[_DType],\n    n: _IntLike = ...,\n    axis: _AxesType = ...,\n    prepend: ndarray[_DType] = ...,\n    append: ndarray[_DType] = ...,\n) -> ndarray[_DType]: ...\ndef digitize(x: ndarray[_DType], bins: ndarray[_DType], right: bool = ...) -> ndarray[_DType]: ...\n@overload\ndef divide(x1: float32, x2: float32) -> float32: ...\n@overload\ndef divide(x1: _DTypeObj, x2: _DTypeObj) -> float64: ...\n@overload\ndef divide(x1: ndarray[float32], x2: Union[ndarray[float32], float32]) -> ndarray[float32]: ...\n@overload\ndef divide(x1: ndarray, x2: Union[ndarray, _DTypeObj]) -> ndarray[float64]: ...\n@overload\ndef divide(x1: Sequence[_AnyNum], x2: _DTypeObj) -> ndarray[float64]: ...\n@overload\ndef dot(x1: _Int, x2: _Int) -> _Int: ...\n@overload\ndef dot(x1: ndarray, x2: ndarray) -> ndarray: ...\n@overload\ndef exp(a: _DTypeObj) -> _DTypeObj: ...\n@overload\ndef exp(a: ndarray[_DType]) -> ndarray[_DType]: ...\ndef expand_dims(a: ndarray[_DType], axis: _AxesType) -> ndarray[_DType]: ...\ndef fill_diagonal(a: ndarray[_DType], val: _FloatLike, wrap: bool = ...) -> None: ...\n@overload\ndef floor(x: _FloatLike) -> _FloatLike: ...\n@overload\ndef floor(x: ndarray[_Float]) -> ndarray[_Float]: ...\ndef genfromtxt(\n    fname: Union[IO, str, Path, List[str], Generator[str, None, None]],\n    dtype: Type[_DType] = ...,\n    comments: str = ...,\n    delimiter: Optional[str] = ...,\n    skip_header: int = ...,\n    skip_footer: int = ...,\n    converters: Any = ...,\n    missing_values: Any = ...,\n    filling_values: Any = ...,\n    usecols: Sequence[int] = ...,\n    names: Optional[Union[Literal[True], str, Sequence[str]]] = ...,\n    excludelist: Sequence[str] = ...,\n    deletechars: str = ...,\n    replace_space: str = ...,\n    autostrip: bool = ...,\n    case_sensitive: Literal[True, False, \"upper\", \"lower\"] = ...,\n    defaultfmt: str = ...,\n    unpack: bool = ...,\n    usemask: bool = ...,\n    loose: bool = ...,\n    invalid_raise: bool = ...,\n    max_rows: int = ...,\n    encoding: str = ...,\n) -> ndarray[_DType]: ...\ndef hstack(tup: Union[List[ndarray[_DType]], Tuple[ndarray[_DType], ...]]) -> ndarray[_DType]: ...\ndef isclose(\n    a: _ArrayLike, b: _ArrayLike, rtol: float = ..., atol: float = ..., equal_nan: bool = ...\n) -> ndarray: ...\ndef in1d(\n    ar1: ndarray[_DType], ar2: ndarray[_DType], assume_unique: bool = ..., inverse: bool = ...\n) -> ndarray[bool_]: ...\ndef interp(\n    x: _ArrayLike,\n    xp: Sequence[float],\n    fp: Sequence[Union[float, complex]],\n    left: Optional[Union[float, complex]] = ...,\n    right: Optional[Union[float, complex]] = ...,\n    period: Optional[float] = ...,\n) -> ndarray: ...\ndef isin(element: Sequence[_DType], test_element: _DType) -> ndarray[_DType]: ...\n@overload\ndef isnan(x: float64) -> bool: ...\n@overload\ndef isnan(x: ndarray[_DType]) -> ndarray[bool_]: ...\n@overload\ndef ix_(x: ndarray[_DType]) -> ndarray[_DType]: ...\n@overload\ndef ix_(x1: ndarray[_DType], x2: ndarray[_DType]) -> Tuple[ndarray[_DType], ndarray[_DType]]: ...\n@overload\ndef log(a: _FloatLike) -> _FloatLike: ...\n@overload\ndef log(a: ndarray[_DType]) -> ndarray[_DType]: ...\n@overload\ndef log2(a: _FloatLike) -> _FloatLike: ...\n@overload\ndef log2(a: ndarray[_DType]) -> ndarray[_DType]: ...\n@overload\ndef log10(a: _FloatLike) -> _FloatLike: ...\n@overload\ndef log10(a: ndarray[_DType]) -> ndarray[_DType]: ...\ndef logical_and(x1: ndarray[bool_], x2: ndarray[bool_]) -> ndarray[bool_]: ...\ndef matmul(a: ndarray[_DType], b: ndarray[_DType]) -> ndarray[_DType]: ...\n@overload\ndef max(a: ndarray[_DType], axis: None = ...) -> _DType: ...\n@overload\ndef max(a: ndarray[_DType], axis: _AxesType, keepdims: bool = ...) -> ndarray[_DType]: ...\ndef maximum(a: ndarray[_DType], b: ndarray[_DType]) -> ndarray[_DType]: ...\n@overload\ndef mean(a: ndarray[_Float]) -> _Float: ...\n@overload\ndef mean(a: ndarray[_Float], axis: _AxesType, keepdims: bool = ...) -> ndarray[_Float]: ...\ndef median(\n    a: ndarray,\n    axis: _IntLike = ...,\n    out: ndarray = ...,\n    overwrite_input: bool = ...,\n    keepdims: bool = ...,\n) -> ndarray[float64]: ...\n@overload\ndef min(a: ndarray[_DType], axis: None = ...) -> _DType: ...\n@overload\ndef min(a: ndarray[_DType], axis: _AxesType, keepdims: bool = ...) -> ndarray[_DType]: ...\ndef minimum(a: ndarray[_DType], b: ndarray[_DType]) -> ndarray[_DType]: ...\ndef nan_to_num(\n    x: ndarray[_DType],\n    copy: bool = ...,\n    nan: _AnyNum = ...,\n    posinf: _AnyNum = ...,\n    neginf: _AnyNum = ...,\n) -> ndarray[_DType]: ...\ndef nonzero(a: ndarray) -> Tuple[ndarray[int64], ...]: ...\ndef outer(a: ndarray[_DType], b: ndarray[_DType]) -> ndarray[_DType]: ...\n@overload\ndef percentile(\n    a: ndarray[_DType],\n    q: _FloatLike,\n    interpolation: _InterpolationType = ...,\n    axis: _AxesType = ...,\n) -> _DType: ...\n@overload\ndef percentile(\n    a: ndarray[_DType],\n    q: _ArrayLike,\n    interpolation: _InterpolationType = ...,\n    axis: _AxesType = ...,\n) -> ndarray[_DType]: ...\ndef power(x1: ndarray[_DType], x2: Union[_AnyNum, ndarray[_DType]]) -> ndarray[_DType]: ...\n@overload\ndef prod(a: ndarray[_DType], axis: None = ...) -> _DType: ...\n@overload\ndef prod(a: ndarray[_DType], axis: _AxesType, keepdims: bool = ...) -> ndarray[_DType]: ...\ndef ravel(a: ndarray[_DType]) -> ndarray[_DType]: ...\ndef reshape(a: ndarray[_DType], newshape: _ShapeType) -> ndarray[_DType]: ...\ndef round(a: ndarray[_DType], decimals: _IntLike = ...) -> ndarray[_DType]: ...\ndef save(\n    file: Union[str, os.PathLike, IO],\n    arr: ndarray,\n    allow_pickle: bool = ...,\n    fix_imports: bool = ...,\n) -> None: ...\n@overload\ndef searchsorted(a: ndarray[_DType], v: _DType, side: str = ...) -> int64: ...\n@overload\ndef searchsorted(a: ndarray[_DType], v: ndarray[_DType], side: str = ...) -> ndarray[int64]: ...\ndef setdiff1d(\n    ar1: Union[ndarray[_DType], List[_ScalarLike]],\n    ar2: Union[ndarray[_DType], List[_ScalarLike]],\n    assume_unique: bool = ...,\n) -> ndarray[_DType]: ...\ndef sin(\n    x: Union[_DType, ndarray[_DType], int, float, List[int], List[float]],\n    out: Optional[Union[ndarray[_DType], Tuple[ndarray[_DType], None]]] = ...,\n    where: Optional[_ArrayLike] = ...,\n) -> Union[_DType, ndarray[_DType]]: ...\ndef sign(x: ndarray[_DType]) -> ndarray[_DType]: ...\ndef sort(a: ndarray[_DType]) -> ndarray[_DType]: ...\ndef split(\n    ary: ndarray[_DType], indices_or_sections: Union[int, List[int]], axis: int = ...\n) -> List[ndarray[_DType]]: ...\ndef square(x: ndarray[_DType]) -> ndarray[_DType]: ...\ndef squeeze(a: ndarray[_DType], axis: _AxesType = ...) -> ndarray[_DType]: ...\n@overload\ndef sqrt(a: float) -> float: ...\n@overload\ndef sqrt(a: ndarray) -> ndarray[float64]: ...\ndef stack(arrays: List[ndarray[_DType]], axis: _AxesType = ...) -> ndarray[_DType]: ...\n@overload\ndef std(a: ndarray[_Float]) -> _Float: ...\n@overload\ndef std(a: ndarray[_Float], axis: _AxesType, keepdims: bool = ...) -> ndarray[_Float]: ...\ndef subtract(\n    x1: ndarray[_DType], x2: ndarray[_DType], axis: Optional[int] = ...\n) -> ndarray[_DType]: ...\n@overload\ndef sum(a: ndarray[_DType], axis: None = ...) -> _DType: ...\n@overload\ndef sum(a: ndarray[_DType], axis: _AxesType, keepdims: bool = ...) -> ndarray[_DType]: ...\ndef take(a: ndarray[_DType], indices: ndarray[_Int], axis: _AxesType = ...) -> ndarray[_DType]: ...\ndef take_along_axis(\n    arr: ndarray[_DType], indices: ndarray[_Int], axis: _AxesType = ...\n) -> ndarray[_DType]: ...\ndef tan(\n    x: Union[_DType, ndarray[_DType], int, float, List[int], List[float]],\n    out: Optional[Union[ndarray[_DType], Tuple[ndarray[_DType], None]]] = ...,\n    where: Optional[_ArrayLike] = ...,\n) -> Union[_DType, ndarray[_DType]]: ...\ndef tile(a: ndarray[_DType], reps: Union[_NestedList[int], ndarray[_Int]]) -> ndarray[_DType]: ...\ndef trace(a: ndarray[_DType]) -> _DType: ...\ndef transpose(a: ndarray[_DType]) -> ndarray[_DType]: ...\ndef tril(m: ndarray[_DType], k: Optional[int] = ...) -> ndarray[_DType]: ...\ndef tril_indices(n: _IntLike, k: _IntLike = ..., m: _IntLike = ...) -> Tuple[ndarray, ndarray]: ...\ndef triu(m: ndarray[_DType], k: Optional[int] = ...) -> ndarray[_DType]: ...\n@overload\ndef unique(a: ndarray[_DType], axis: Optional[int] = ...) -> ndarray[_DType]: ...\n@overload\ndef unique(\n    a: ndarray[_DType], return_counts: bool = ..., axis: Optional[int] = ...\n) -> Tuple[ndarray[_DType], ndarray[_DType]]: ...\n@overload\ndef unique(\n    a: ndarray[_DType], return_inverse: bool = ..., axis: Optional[int] = ...\n) -> Tuple[ndarray[_DType], ndarray[_DType]]: ...\ndef vstack(tup: Sequence[ndarray[_DType]]) -> ndarray[_DType]: ...\n@overload\ndef where(condition: _ConditionType, x: ndarray[_DType], y: ndarray[_DType]) -> ndarray[_DType]: ...\n@overload\ndef where(condition: _ConditionType, x: _ScalarLike, y: ndarray[_DType]) -> ndarray[_DType]: ...\n@overload\ndef where(condition: _ConditionType, x: ndarray[_DType], y: _ScalarLike) -> ndarray[_DType]: ...\n@overload\ndef where(condition: _ConditionType, x: _DType, y: _DType) -> ndarray[_DType]: ...\n@overload\ndef where(condition: _ConditionType, x: int, y: int) -> ndarray[int64]: ...\n@overload\ndef where(condition: _ConditionType, x: float, y: float) -> ndarray[float64]: ...\n@overload\ndef where(condition: _ConditionType) -> Tuple[ndarray[int64], ...]: ...\n\n#\n# nan series methods\n#\nnancumprod = cumprod\nnancumsum = cumsum\nnanmean = mean\nnanstd = std\nnansum = sum\nnanmin = min\nnanmax = max\n\n#\n# Saving methods\n#\ndef savetxt(\n    fname: str,\n    X: ndarray,\n    *,\n    header: str = ...,\n    delimiter: str = ...,\n    newline: str = ...,\n    comments: str = ...,\n) -> None: ...\ndef savez(file: Path, *args: ndarray, **kwds: ndarray) -> None: ...\ndef savez_compressed(file: Path, *args: ndarray, **kwds: ndarray) -> None: ...\n\n#\n# weird classes\n#\nclass matrix:\n    def __init__(self, data: Union[List, str], dtype: Type[_DType] = ..., copy: bool = ...): ...\n    def reshape(self, shape: _ShapeType) -> matrix: ...\n\nclass finfo(Generic[_Float]):\n    eps: _Float\n    resolution: _Float\n    min: _Float\n    max: _Float\n    dtype: _Float\n    @overload\n    def __init__(self, dtype: _Float): ...\n    @overload\n    def __init__(self, dtype: Type[_Float]): ...\n    @overload\n    def __init__(self: finfo[float64], dtype: Union[float, Type[float]]): ...\n\n#\n# module functions\n#\ndef set_printoptions(\n    precision: Any = ...,\n    threshold: Any = ...,\n    edgeitems: Any = ...,\n    linewidth: Any = ...,\n    suppress: Any = ...,\n    nanstr: Any = ...,\n    infstr: Any = ...,\n    formatter: Any = ...,\n    sign: Any = ...,\n    floatmode: Any = ...,\n    *,\n    legacy: Any = ...,\n) -> None: ...\n\n#\n# Specific values\n#\ne: float\ninf: float\nnan: float\nNaN: float\nNAN: float\npi: float\n\n# Local Variables:\n# blacken-line-length: 100\n# blacken-allow-py36: t\n# blacken-skip-string-normalization: t\n# End:\n",
    "/typeshed/numpy/linalg.pyi": "from typing import Tuple, Union, overload\nfrom typing_extensions import Literal\n\nfrom numpy import ndarray, _Int, float64, _DType\n\ndef slogdet(\n    a: ndarray[_DType],\n) -> Union[Tuple[float64, float64], Tuple[ndarray[float64], ndarray[float64]]]: ...\n@overload\ndef svd(\n    a: ndarray[_DType],\n    full_matrices: bool = ...,\n    compute_uv: Literal[True] = ...,\n    hermitian: bool = ...,\n) -> Tuple[ndarray[_DType], ndarray[_DType], ndarray[_DType]]: ...\n@overload\ndef svd(\n    a: ndarray[_DType],\n    *,\n    compute_uv: Literal[False],\n    full_matrices: bool = ...,\n    hermitian: bool = ...,\n) -> ndarray[_DType]: ...\n",
    "/typeshed/numpy/ma.pyi": "from numpy import ndarray, _DType, bool_\nfrom typing import Generic\n\nclass MaskedArray(ndarray[_DType]): ...\n\ndef array(data: ndarray[_DType], mask: ndarray[bool_] = ...) -> MaskedArray[_DType]: ...\ndef dot(a: MaskedArray[_DType], b: MaskedArray[_DType]) -> MaskedArray[_DType]: ...\ndef masked_array(data: ndarray[_DType], mask: ndarray[_DType]) -> MaskedArray[_DType]: ...\ndef median(data: MaskedArray[_DType]) -> _DType: ...\n",
    "/typeshed/numpy/random.pyi": "from typing import Iterable, List, Optional, Sequence, Tuple, TypeVar, Union, overload\nfrom typing_extensions import Literal\n\nfrom . import (\n    _ArrayLike,\n    _DType,\n    _Float,\n    _FloatLike,\n    _Int,\n    _IntLike,\n    _ShapeType,\n    float64,\n    int64,\n    ndarray,\n)\n\n_T = TypeVar(\"_T\")\n@overload\ndef binomial(n: _IntLike, p: _FloatLike) -> _Int: ...\n@overload\ndef binomial(n: _IntLike, p: _FloatLike, size: _IntLike) -> ndarray[_Int]: ...\n@overload\ndef binomial(n: _IntLike, p: _ArrayLike[_Float], size: ndarray[_Int] = ...) -> ndarray[_Int]: ...\n@overload\ndef binomial(n: _ArrayLike[_Int], p: _FloatLike, size: ndarray[_Int] = ...) -> ndarray[_Int]: ...\n@overload\ndef binomial(\n    n: _ArrayLike[_Int], p: _ArrayLike[_Float], size: ndarray[_Int] = ...\n) -> ndarray[_Int]: ...\n@overload\ndef choice(a: _IntLike) -> _IntLike: ...\n@overload\ndef choice(a: _Int, size: int) -> ndarray[_Int]: ...\n@overload\ndef choice(a: int, size: int) -> ndarray[int64]: ...\n@overload\ndef choice(a: _IntLike, size: _IntLike, replace: bool) -> ndarray[int64]: ...\n@overload\ndef choice(\n    a: List[_T], p: Union[List[_FloatLike], ndarray[_Float]] = ..., replace: bool = ...\n) -> _T: ...\n@overload\ndef choice(\n    a: range, size: _IntLike, replace: bool = ..., p: Union[List[_FloatLike], ndarray[_Float]] = ...\n) -> ndarray[int64]: ...\n@overload\ndef choice(\n    a: range, *, replace: bool = ..., p: Union[List[_FloatLike], ndarray[_Float]] = ...\n) -> int64: ...\n@overload\ndef choice(\n    a: ndarray[_DType],\n    size: _IntLike,\n    replace: bool = ...,\n    p: Union[List[_FloatLike], ndarray[_Float]] = ...,\n) -> ndarray[_DType]: ...\n@overload\ndef choice(\n    a: ndarray[_DType], *, replace: bool = ..., p: Union[List[_FloatLike], ndarray[_Float]] = ...\n) -> _DType: ...\ndef default_rng(seed: Optional[int] = ...) -> Generator: ...\ndef dirichlet(alpha: ndarray[_DType], size: _IntLike = ...) -> ndarray[_DType]: ...\n@overload\ndef exponential(scale: _FloatLike) -> _Float: ...\n@overload\ndef exponential(scale: _FloatLike, size: Sequence[_IntLike]) -> ndarray[float64]: ...\n@overload\ndef exponential(scale: Sequence[_FloatLike], size: Sequence[_IntLike]) -> ndarray[float64]: ...\ndef geometric(p: float, size: _IntLike) -> ndarray[float64]: ...\ndef get_state() -> Tuple[str, ndarray[_Int], _IntLike, _IntLike, _FloatLike]: ...\ndef normal(loc: float, scale: float, size: Union[int, Tuple[int, ...]]) -> ndarray[float64]: ...\n@overload\ndef permutation(size: int) -> ndarray[int64]: ...\n@overload\ndef permutation(size: Iterable[_DType]) -> ndarray[_DType]: ...\ndef rand(*args: int) -> ndarray[_Float]: ...\ndef randn(*args: int) -> ndarray[_Float]: ...\n@overload\ndef randint(low: int, high: int = ...) -> int64: ...\n@overload\ndef randint(low: int, size: Tuple[int, ...], high: int = ...) -> ndarray[int64]: ...\n@overload\ndef randint(low: int, size: int, high: int = ...) -> ndarray[int64]: ...\ndef seed(s: int) -> None: ...\ndef set_state(state: Tuple[str, ndarray[_Int], _IntLike, _IntLike, _FloatLike]) -> None: ...\ndef shuffle(x: ndarray) -> None: ...\n@overload\ndef uniform() -> float64: ...\n@overload\ndef uniform(size: _ShapeType) -> ndarray: ...\n@overload\ndef uniform(low: float, high: float, size: _ShapeType) -> ndarray: ...\n\nclass Generator:\n    def __init__(self, seed: int = ...): ...\n    @overload\n    def choice(self, a: _IntLike) -> _IntLike: ...\n    @overload\n    def choice(self, a: _Int, size: int) -> ndarray[_Int]: ...\n    @overload\n    def choice(self, a: int, size: int) -> ndarray[int64]: ...\n    @overload\n    def choice(self, a: _IntLike, size: _IntLike, replace: bool) -> ndarray[int64]: ...\n    @overload\n    def choice(\n        self, a: List[_T], p: Union[List[_FloatLike], ndarray[_Float]] = ..., replace: bool = ...\n    ) -> _T: ...\n    @overload\n    def choice(\n        self,\n        a: range,\n        size: _IntLike,\n        replace: bool = ...,\n        p: Union[List[_FloatLike], ndarray[_Float]] = ...,\n    ) -> ndarray[int64]: ...\n    @overload\n    def choice(\n        self, a: range, *, replace: bool = ..., p: Union[List[_FloatLike], ndarray[_Float]] = ...\n    ) -> int64: ...\n    @overload\n    def choice(\n        self,\n        a: ndarray[_DType],\n        size: _IntLike,\n        replace: bool = ...,\n        p: Union[List[_FloatLike], ndarray[_Float]] = ...,\n    ) -> ndarray[_DType]: ...\n    @overload\n    def choice(\n        self,\n        a: ndarray[_DType],\n        *,\n        replace: bool = ...,\n        p: Union[List[_FloatLike], ndarray[_Float]] = ...,\n    ) -> _DType: ...\n    def normal(\n        self,\n        loc: Union[float, ndarray[_DType]] = ...,\n        scale: Union[float, ndarray[_DType]] = ...,\n        size: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...\n    def permutation(self, size: int) -> ndarray[int64]: ...\n    def shuffle(self, x: ndarray) -> None: ...\n    def beta(\n        self,\n        a: Union[float, ndarray[_DType]] = ...,\n        b: Union[float, ndarray[_DType]] = ...,\n        size: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...  # Draw samples from a Beta distribution.\n    def binomial(\n        self,\n        n: Union[int, ndarray[_DType]] = ...,\n        p: Union[float, ndarray[_DType]] = ...,\n        size: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...  # Draw samples from a binomial distribution.\n    def chisquare(\n        self, df: Union[float, ndarray[_DType]] = ..., size: Optional[_ShapeType] = ...\n    ) -> ndarray[_DType]: ...  # Draw samples from a chi-square distribution.\n    def dirichlet(\n        self, alpha: Union[float, ndarray[_DType]] = ..., size: Optional[_ShapeType] = ...\n    ) -> ndarray[_DType]: ...  # Draw samples from the Dirichlet distribution.\n    def exponential(\n        self, scale: float, size: Optional[_ShapeType] = ...\n    ) -> ndarray[_DType]: ...  # Draw samples from an exponential distribution.\n    def f(\n        self,\n        dfnum: Union[float, ndarray[_DType]] = ...,\n        dfden: Union[float, ndarray[_DType]] = ...,\n        size: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...  # Draw samples from an F distribution.\n    def gamma(\n        self,\n        shape: Union[float, ndarray[_DType]] = ...,\n        scale: Union[float, ndarray[_DType]] = ...,\n        size: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...  # Draw samples from a Gamma distribution.\n    def geometric(\n        self, p: Union[float, ndarray[_DType]] = ..., size: Optional[_ShapeType] = ...\n    ) -> ndarray[_DType]: ...  # Draw samples from the geometric distribution.\n    def gumbel(\n        self,\n        loc: Union[float, ndarray[_DType]] = ...,\n        scale: Union[float, ndarray[_DType]] = ...,\n        size: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...  # Draw samples from a Gumbel distribution.\n    def hypergeometric(\n        self,\n        ngood: Union[int, ndarray[_DType]] = ...,\n        nbad: Union[int, ndarray[_DType]] = ...,\n        nsample: Union[int, ndarray[_DType]] = ...,\n        size: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...  # Draw samples from a Hypergeometric distribution.\n    def laplace(\n        self,\n        loc: Union[float, ndarray[_DType]] = ...,\n        scale: Union[float, ndarray[_DType]] = ...,\n        size: Optional[_ShapeType] = ...,\n    ) -> ndarray[\n        _DType\n    ]: ...  # Draw samples from the Laplace or double exponential distribution with specified location (or mean) and scale (decay).\n    def logistic(\n        self,\n        loc: Union[float, ndarray[_DType]] = ...,\n        scale: Union[float, ndarray[_DType]] = ...,\n        size: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...  # Draw samples from a logistic distribution.\n    def lognormal(\n        self,\n        mean: Union[float, ndarray[_DType]] = ...,\n        sigma: Union[float, ndarray[_DType]] = ...,\n        size: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...  # Draw samples from a log-normal distribution.\n    def logseries(\n        self, p: Union[float, ndarray[_DType]] = ..., size: Optional[_ShapeType] = ...\n    ) -> ndarray[_DType]: ...  # Draw samples from a logarithmic series distribution.\n    def multimonial(\n        self,\n        n: Union[int, ndarray[_DType]] = ...,\n        pvals: ndarray[_DType] = ...,\n        size: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...  # Draw samples from a multinomial distribution.\n    def multivariate_hypergeometric(\n        self, colors: Sequence[int], nsample: int\n    ) -> ndarray[_DType]: ...  # Generate variates from a multivariate hypergeometric distribution.\n    def multivariate_normal(\n        self,\n        mean: ndarray[_DType] = ...,\n        cov: ndarray[_DType] = ...,\n        size: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...  # Draw samples from a multivariate normal distribution.\n    def negative_binomial(\n        self,\n        n: Union[float, ndarray[_DType]] = ...,\n        p: Union[float, ndarray[_DType]] = ...,\n        size: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...  # Draw samples from a negative binomial distribution.\n    def noncentral_chisquare(\n        self,\n        df: Union[float, ndarray[_DType]] = ...,\n        nonc: Union[float, ndarray[_DType]] = ...,\n        size: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...  # Draw samples from a noncentral chi-square distribution.\n    def noncentral_f(\n        self,\n        dfnum: Union[float, ndarray[_DType]] = ...,\n        dfden: Union[float, ndarray[_DType]] = ...,\n        nonc: Union[float, ndarray[_DType]] = ...,\n        size: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...  # Draw samples from the noncentral F distribution.\n    def pareto(\n        self, a: Union[float, ndarray[_DType]] = ..., size: Optional[_ShapeType] = ...\n    ) -> ndarray[\n        _DType\n    ]: ...  # Draw samples from a Pareto II or Lomax distribution with specified shape.\n    def poisson(\n        self, lam: Union[float, ndarray[_DType]] = ..., size: Optional[_ShapeType] = ...\n    ) -> ndarray[_DType]: ...  # Draw samples from a Poisson distribution.\n    def power(\n        self, a: Union[float, ndarray[_DType]] = ..., size: Optional[_ShapeType] = ...\n    ) -> ndarray[\n        _DType\n    ]: ...  # Draws samples in [0, 1] from a power distribution with positive exponent a - 1.\n    def rayleigh(\n        self, scale: Union[float, ndarray[_DType]] = ..., size: Optional[_ShapeType] = ...\n    ) -> ndarray[_DType]: ...  # Draw samples from a Rayleigh distribution.\n    def standard_cauchy(\n        self, size: Optional[_ShapeType] = ...\n    ) -> ndarray[_DType]: ...  # Draw samples from a standard Cauchy distribution with mode = 0.\n    def standard_exponential(\n        self,\n        size: Union[int, ndarray[_DType]] = ...,\n        dtype: Optional[_DType] = ...,\n        method: Optional[Literal[\"inv\", \"zig\"]] = ...,\n        out: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...  # Draw samples from the standard exponential distribution.\n    def standard_gamma(\n        self,\n        shape: Union[float, ndarray[_DType]] = ...,\n        size: Union[float, ndarray[_DType]] = ...,\n        dtype: Optional[_DType] = ...,\n        out: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...  # Draw samples from a standard Gamma distribution.\n    def standard_normal(\n        self,\n        size: Union[int, ndarray[_DType]] = ...,\n        dtype: Optional[_DType] = ...,\n        out: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...  # Draw samples from a standard Normal distribution (mean=0, stdev=1).\n    def standard_t(\n        self, df: Union[float, ndarray[_DType]] = ..., size: Optional[_ShapeType] = ...\n    ) -> ndarray[\n        _DType\n    ]: ...  # Draw samples from a standard Student\u2019s t distribution with df degrees of freedom.\n    def triangular(\n        self,\n        left: Union[float, ndarray[_DType]] = ...,\n        mode: Union[float, ndarray[_DType]] = ...,\n        right: Union[float, ndarray[_DType]] = ...,\n        size: Optional[_ShapeType] = ...,\n    ) -> ndarray[\n        _DType\n    ]: ...  # Draw samples from the triangular distribution over the interval [left, right].\n    def uniform(\n        self,\n        low: Union[float, ndarray[_DType]] = ...,\n        high: Union[float, ndarray[_DType]] = ...,\n        size: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...  # Draw samples from a uniform distribution.\n    def vonmises(\n        self,\n        mu: Union[float, ndarray[_DType]] = ...,\n        kappa: Union[float, ndarray[_DType]] = ...,\n        size: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...  # Draw samples from a von Mises distribution.\n    def wald(\n        self,\n        mean: Union[float, ndarray[_DType]] = ...,\n        scale: Union[float, ndarray[_DType]] = ...,\n        size: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...  # Draw samples from a Wald, or inverse Gaussian, distribution.\n    def weibull(\n        self, a: Union[float, ndarray[_DType]] = ..., size: Optional[_ShapeType] = ...\n    ) -> ndarray[_DType]: ...  # Draw samples from a Weibull distribution.\n    def zipf(\n        self, a: Union[float, ndarray[_DType]] = ..., size: Optional[_ShapeType] = ...\n    ) -> ndarray[_DType]: ...  # Draw samples from a Zipf distribution.\n\nclass RandomState:\n    def __init__(self, seed: int = ...): ...\n    def multivariate_normal(\n        self,\n        mean: ndarray[_DType] = ...,\n        cov: ndarray[_DType] = ...,\n        size: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...\n    def normal(\n        self,\n        loc: Union[float, ndarray[_DType]] = ...,\n        scale: Union[float, ndarray[_DType]] = ...,\n        size: Optional[_ShapeType] = ...,\n    ) -> ndarray[_DType]: ...\n    def permutation(self, size: int) -> ndarray[int64]: ...\n    def shuffle(self, x: ndarray) -> None: ...\n    def uniform(self, size: _ShapeType) -> ndarray: ...\n    @overload\n    def choice(self, a: _IntLike) -> _IntLike: ...\n    @overload\n    def choice(self, a: _Int, size: int) -> ndarray[_Int]: ...\n    @overload\n    def choice(self, a: int, size: int) -> ndarray[int64]: ...\n    @overload\n    def choice(self, a: _IntLike, size: _IntLike, replace: bool) -> ndarray[int64]: ...\n    @overload\n    def choice(\n        self, a: List[_T], p: Union[List[_FloatLike], ndarray[_Float]] = ..., replace: bool = ...\n    ) -> _T: ...\n    @overload\n    def choice(\n        self,\n        a: range,\n        size: _IntLike,\n        replace: bool = ...,\n        p: Union[List[_FloatLike], ndarray[_Float]] = ...,\n    ) -> ndarray[int64]: ...\n    @overload\n    def choice(\n        self, a: range, *, replace: bool = ..., p: Union[List[_FloatLike], ndarray[_Float]] = ...\n    ) -> int64: ...\n    @overload\n    def choice(\n        self,\n        a: ndarray[_DType],\n        size: _IntLike,\n        replace: bool = ...,\n        p: Union[List[_FloatLike], ndarray[_Float]] = ...,\n    ) -> ndarray[_DType]: ...\n    @overload\n    def choice(\n        self,\n        a: ndarray[_DType],\n        *,\n        replace: bool = ...,\n        p: Union[List[_FloatLike], ndarray[_Float]] = ...,\n    ) -> _DType: ...\n",
    "/typeshed/numpy/testing.pyi": "from typing import overload\n\nfrom . import ndarray\n\ndef assert_allclose(\n    actual: ndarray, desired: ndarray, rtol: float = ..., atol: float = ...\n) -> None: ...\ndef assert_array_equal(actual: ndarray, desired: ndarray) -> None: ...\n@overload\ndef assert_almost_equal(actual: ndarray, desired: ndarray, decimal: float) -> None: ...\n@overload\ndef assert_almost_equal(actual: float, desired: float, decimal: float) -> None: ...\n",
    "/typeshed/requests/requests/__init__.pyi": "from .__version__ import (\n    __author__ as __author__,\n    __author_email__ as __author_email__,\n    __build__ as __build__,\n    __cake__ as __cake__,\n    __copyright__ as __copyright__,\n    __description__ as __description__,\n    __license__ as __license__,\n    __title__ as __title__,\n    __url__ as __url__,\n    __version__ as __version__,\n)\nfrom .api import (\n    delete as delete,\n    get as get,\n    head as head,\n    options as options,\n    patch as patch,\n    post as post,\n    put as put,\n    request as request,\n)\nfrom .exceptions import (\n    ConnectionError as ConnectionError,\n    ConnectTimeout as ConnectTimeout,\n    FileModeWarning as FileModeWarning,\n    HTTPError as HTTPError,\n    JSONDecodeError as JSONDecodeError,\n    ReadTimeout as ReadTimeout,\n    RequestException as RequestException,\n    Timeout as Timeout,\n    TooManyRedirects as TooManyRedirects,\n    URLRequired as URLRequired,\n)\nfrom .models import PreparedRequest as PreparedRequest, Request as Request, Response as Response\nfrom .sessions import Session as Session, session as session\nfrom .status_codes import codes as codes\n\ndef check_compatibility(urllib3_version: str, chardet_version: str | None, charset_normalizer_version: str | None) -> None: ...\n",
    "/typeshed/requests/requests/__version__.pyi": "__title__: str\n__description__: str\n__url__: str\n__version__: str\n__build__: int\n__author__: str\n__author_email__: str\n__license__: str\n__copyright__: str\n__cake__: str\n",
    "/typeshed/requests/requests/adapters.pyi": "from collections.abc import Mapping\nfrom typing import Any\n\nfrom urllib3.contrib.socks import SOCKSProxyManager as SOCKSProxyManager\nfrom urllib3.exceptions import (\n    ConnectTimeoutError as ConnectTimeoutError,\n    MaxRetryError as MaxRetryError,\n    ProtocolError as ProtocolError,\n    ReadTimeoutError as ReadTimeoutError,\n    ResponseError as ResponseError,\n)\nfrom urllib3.poolmanager import PoolManager as PoolManager, proxy_from_url as proxy_from_url\nfrom urllib3.util.retry import Retry as Retry\n\nfrom .cookies import extract_cookies_to_jar as extract_cookies_to_jar\nfrom .exceptions import (\n    ConnectionError as ConnectionError,\n    ConnectTimeout as ConnectTimeout,\n    ProxyError as ProxyError,\n    ReadTimeout as ReadTimeout,\n    RetryError as RetryError,\n    SSLError as SSLError,\n)\nfrom .models import PreparedRequest, Response as Response\nfrom .structures import CaseInsensitiveDict as CaseInsensitiveDict\nfrom .utils import (\n    DEFAULT_CA_BUNDLE_PATH as DEFAULT_CA_BUNDLE_PATH,\n    get_auth_from_url as get_auth_from_url,\n    get_encoding_from_headers as get_encoding_from_headers,\n    prepend_scheme_if_needed as prepend_scheme_if_needed,\n    urldefragauth as urldefragauth,\n)\n\nDEFAULT_POOLBLOCK: bool\nDEFAULT_POOLSIZE: int\nDEFAULT_RETRIES: int\nDEFAULT_POOL_TIMEOUT: float | None\n\nclass BaseAdapter:\n    def __init__(self) -> None: ...\n    def send(\n        self,\n        request: PreparedRequest,\n        stream: bool = False,\n        timeout: None | float | tuple[float, float] | tuple[float, None] = None,\n        verify: bool | str = True,\n        cert: None | bytes | str | tuple[bytes | str, bytes | str] = None,\n        proxies: Mapping[str, str] | None = None,\n    ) -> Response: ...\n    def close(self) -> None: ...\n\nclass HTTPAdapter(BaseAdapter):\n    __attrs__: Any\n    max_retries: Retry\n    config: Any\n    proxy_manager: Any\n    def __init__(\n        self, pool_connections: int = 10, pool_maxsize: int = 10, max_retries: Retry | int | None = 0, pool_block: bool = False\n    ) -> None: ...\n    poolmanager: Any\n    def init_poolmanager(self, connections, maxsize, block=False, **pool_kwargs): ...\n    def proxy_manager_for(self, proxy, **proxy_kwargs): ...\n    def cert_verify(self, conn, url, verify, cert): ...\n    def build_response(self, req, resp): ...\n    def get_connection(self, url, proxies=None): ...\n    def close(self): ...\n    def request_url(self, request, proxies): ...\n    def add_headers(self, request, **kwargs): ...\n    def proxy_headers(self, proxy): ...\n    def send(\n        self,\n        request: PreparedRequest,\n        stream: bool = False,\n        timeout: None | float | tuple[float, float] | tuple[float, None] = None,\n        verify: bool | str = True,\n        cert: None | bytes | str | tuple[bytes | str, bytes | str] = None,\n        proxies: Mapping[str, str] | None = None,\n    ) -> Response: ...\n",
    "/typeshed/requests/requests/api.pyi": "from _typeshed import Incomplete\nfrom collections.abc import Mapping\nfrom typing_extensions import TypeAlias\n\nfrom .models import Response\nfrom .sessions import RequestsCookieJar, _Auth, _Cert, _Data, _Files, _HooksInput, _Params, _TextMapping, _Timeout, _Verify\n\n_HeadersMapping: TypeAlias = Mapping[str, str | bytes | None]\n\ndef request(\n    method: str | bytes,\n    url: str | bytes,\n    *,\n    params: _Params | None = ...,\n    data: _Data | None = ...,\n    headers: _HeadersMapping | None = ...,\n    cookies: RequestsCookieJar | _TextMapping | None = ...,\n    files: _Files | None = ...,\n    auth: _Auth | None = ...,\n    timeout: _Timeout | None = ...,\n    allow_redirects: bool = ...,\n    proxies: _TextMapping | None = ...,\n    hooks: _HooksInput | None = ...,\n    stream: bool | None = ...,\n    verify: _Verify | None = ...,\n    cert: _Cert | None = ...,\n    json: Incomplete | None = ...,\n) -> Response: ...\ndef get(\n    url: str | bytes,\n    params: _Params | None = None,\n    *,\n    data: _Data | None = ...,\n    headers: _HeadersMapping | None = ...,\n    cookies: RequestsCookieJar | _TextMapping | None = ...,\n    files: _Files | None = ...,\n    auth: _Auth | None = ...,\n    timeout: _Timeout | None = ...,\n    allow_redirects: bool = ...,\n    proxies: _TextMapping | None = ...,\n    hooks: _HooksInput | None = ...,\n    stream: bool | None = ...,\n    verify: _Verify | None = ...,\n    cert: _Cert | None = ...,\n    json: Incomplete | None = ...,\n) -> Response: ...\ndef options(\n    url: str | bytes,\n    *,\n    params: _Params | None = ...,\n    data: _Data | None = ...,\n    headers: _HeadersMapping | None = ...,\n    cookies: RequestsCookieJar | _TextMapping | None = ...,\n    files: _Files | None = ...,\n    auth: _Auth | None = ...,\n    timeout: _Timeout | None = ...,\n    allow_redirects: bool = ...,\n    proxies: _TextMapping | None = ...,\n    hooks: _HooksInput | None = ...,\n    stream: bool | None = ...,\n    verify: _Verify | None = ...,\n    cert: _Cert | None = ...,\n    json: Incomplete | None = ...,\n) -> Response: ...\ndef head(\n    url: str | bytes,\n    *,\n    params: _Params | None = ...,\n    data: _Data | None = ...,\n    headers: _HeadersMapping | None = ...,\n    cookies: RequestsCookieJar | _TextMapping | None = ...,\n    files: _Files | None = ...,\n    auth: _Auth | None = ...,\n    timeout: _Timeout | None = ...,\n    allow_redirects: bool = ...,\n    proxies: _TextMapping | None = ...,\n    hooks: _HooksInput | None = ...,\n    stream: bool | None = ...,\n    verify: _Verify | None = ...,\n    cert: _Cert | None = ...,\n    json: Incomplete | None = ...,\n) -> Response: ...\ndef post(\n    url: str | bytes,\n    data: _Data | None = None,\n    json: Incomplete | None = None,\n    *,\n    params: _Params | None = ...,\n    headers: _HeadersMapping | None = ...,\n    cookies: RequestsCookieJar | _TextMapping | None = ...,\n    files: _Files | None = ...,\n    auth: _Auth | None = ...,\n    timeout: _Timeout | None = ...,\n    allow_redirects: bool = ...,\n    proxies: _TextMapping | None = ...,\n    hooks: _HooksInput | None = ...,\n    stream: bool | None = ...,\n    verify: _Verify | None = ...,\n    cert: _Cert | None = ...,\n) -> Response: ...\ndef put(\n    url: str | bytes,\n    data: _Data | None = None,\n    *,\n    params: _Params | None = ...,\n    headers: _HeadersMapping | None = ...,\n    cookies: RequestsCookieJar | _TextMapping | None = ...,\n    files: _Files | None = ...,\n    auth: _Auth | None = ...,\n    timeout: _Timeout | None = ...,\n    allow_redirects: bool = ...,\n    proxies: _TextMapping | None = ...,\n    hooks: _HooksInput | None = ...,\n    stream: bool | None = ...,\n    verify: _Verify | None = ...,\n    cert: _Cert | None = ...,\n    json: Incomplete | None = ...,\n) -> Response: ...\ndef patch(\n    url: str | bytes,\n    data: _Data | None = None,\n    *,\n    params: _Params | None = ...,\n    headers: _HeadersMapping | None = ...,\n    cookies: RequestsCookieJar | _TextMapping | None = ...,\n    files: _Files | None = ...,\n    auth: _Auth | None = ...,\n    timeout: _Timeout | None = ...,\n    allow_redirects: bool = ...,\n    proxies: _TextMapping | None = ...,\n    hooks: _HooksInput | None = ...,\n    stream: bool | None = ...,\n    verify: _Verify | None = ...,\n    cert: _Cert | None = ...,\n    json: Incomplete | None = ...,\n) -> Response: ...\ndef delete(\n    url: str | bytes,\n    *,\n    params: _Params | None = ...,\n    data: _Data | None = ...,\n    headers: _HeadersMapping | None = ...,\n    cookies: RequestsCookieJar | _TextMapping | None = ...,\n    files: _Files | None = ...,\n    auth: _Auth | None = ...,\n    timeout: _Timeout | None = ...,\n    allow_redirects: bool = ...,\n    proxies: _TextMapping | None = ...,\n    hooks: _HooksInput | None = ...,\n    stream: bool | None = ...,\n    verify: _Verify | None = ...,\n    cert: _Cert | None = ...,\n    json: Incomplete | None = ...,\n) -> Response: ...\n",
    "/typeshed/requests/requests/auth.pyi": "from typing import Any\n\nfrom . import cookies, models, utils\n\nextract_cookies_to_jar = cookies.extract_cookies_to_jar\nparse_dict_header = utils.parse_dict_header\nto_native_string = utils.to_native_string\n\nCONTENT_TYPE_FORM_URLENCODED: Any\nCONTENT_TYPE_MULTI_PART: Any\n\ndef _basic_auth_str(username: bytes | str, password: bytes | str) -> str: ...\n\nclass AuthBase:\n    def __call__(self, r: models.PreparedRequest) -> models.PreparedRequest: ...\n\nclass HTTPBasicAuth(AuthBase):\n    username: bytes | str\n    password: bytes | str\n    def __init__(self, username: bytes | str, password: bytes | str) -> None: ...\n    def __call__(self, r): ...\n\nclass HTTPProxyAuth(HTTPBasicAuth):\n    def __call__(self, r): ...\n\nclass HTTPDigestAuth(AuthBase):\n    username: bytes | str\n    password: bytes | str\n    last_nonce: Any\n    nonce_count: Any\n    chal: Any\n    pos: Any\n    num_401_calls: Any\n    def __init__(self, username: bytes | str, password: bytes | str) -> None: ...\n    def build_digest_header(self, method, url): ...\n    def handle_redirect(self, r, **kwargs): ...\n    def handle_401(self, r, **kwargs): ...\n    def __call__(self, r): ...\n    def init_per_thread_state(self) -> None: ...\n",
    "/typeshed/requests/requests/certs.pyi": "# no public data\n",
    "/typeshed/requests/requests/compat.pyi": "from builtins import bytes as bytes, str as str\nfrom collections import OrderedDict as OrderedDict\nfrom typing import Literal\nfrom typing_extensions import TypeAlias\nfrom urllib.parse import (\n    quote as quote,\n    quote_plus as quote_plus,\n    unquote as unquote,\n    unquote_plus as unquote_plus,\n    urldefrag as urldefrag,\n    urlencode as urlencode,\n    urljoin as urljoin,\n    urlparse as urlparse,\n    urlsplit as urlsplit,\n    urlunparse as urlunparse,\n)\nfrom urllib.request import getproxies as getproxies, parse_http_list as parse_http_list, proxy_bypass as proxy_bypass\n\nis_py2: Literal[False]\nis_py3: Literal[True]\nhas_simplejson: bool\n\nbuiltin_str: TypeAlias = str  # noqa: Y042\nbasestring: tuple[type, ...]\nnumeric_types: tuple[type, ...]\ninteger_types: tuple[type, ...]\n",
    "/typeshed/requests/requests/cookies.pyi": "from collections.abc import MutableMapping\nfrom http.cookiejar import CookieJar\nfrom typing import Any\n\nclass MockRequest:\n    type: Any\n    def __init__(self, request) -> None: ...\n    def get_type(self): ...\n    def get_host(self): ...\n    def get_origin_req_host(self): ...\n    def get_full_url(self): ...\n    def is_unverifiable(self): ...\n    def has_header(self, name): ...\n    def get_header(self, name, default=None): ...\n    def add_header(self, key, val): ...\n    def add_unredirected_header(self, name, value): ...\n    def get_new_headers(self): ...\n    @property\n    def unverifiable(self): ...\n    @property\n    def origin_req_host(self): ...\n    @property\n    def host(self): ...\n\nclass MockResponse:\n    def __init__(self, headers) -> None: ...\n    def info(self): ...\n    def getheaders(self, name): ...\n\ndef extract_cookies_to_jar(jar, request, response): ...\ndef get_cookie_header(jar, request): ...\ndef remove_cookie_by_name(cookiejar, name, domain=None, path=None): ...\n\nclass CookieConflictError(RuntimeError): ...\n\nclass RequestsCookieJar(CookieJar, MutableMapping[Any, Any]):\n    def get(self, name, default=None, domain=None, path=None): ...\n    def set(self, name, value, **kwargs): ...\n    def iterkeys(self): ...\n    def keys(self): ...\n    def itervalues(self): ...\n    def values(self): ...\n    def iteritems(self): ...\n    def items(self): ...\n    def list_domains(self): ...\n    def list_paths(self): ...\n    def multiple_domains(self): ...\n    def get_dict(self, domain=None, path=None): ...\n    def __getitem__(self, name): ...\n    def __setitem__(self, name, value) -> None: ...\n    def __delitem__(self, name) -> None: ...\n    def set_cookie(self, cookie, *args, **kwargs): ...\n    def update(self, other): ...\n    def copy(self): ...\n    def get_policy(self): ...\n\ndef create_cookie(name, value, **kwargs): ...\ndef morsel_to_cookie(morsel): ...\ndef cookiejar_from_dict(cookie_dict, cookiejar=None, overwrite=True): ...\ndef merge_cookies(cookiejar, cookies): ...\n",
    "/typeshed/requests/requests/exceptions.pyi": "from typing import Any\n\nfrom urllib3.exceptions import HTTPError as BaseHTTPError\n\nfrom .models import Request, Response\nfrom .sessions import PreparedRequest\n\nclass RequestException(OSError):\n    response: Response | None\n    request: Request | PreparedRequest | None\n    def __init__(\n        self, *args: object, request: Request | PreparedRequest | None = ..., response: Response | None = ...\n    ) -> None: ...\n\nclass InvalidJSONError(RequestException): ...\nclass JSONDecodeError(InvalidJSONError): ...\n\nclass HTTPError(RequestException):\n    request: Request | PreparedRequest | Any\n    response: Response | Any\n\nclass ConnectionError(RequestException): ...\nclass ProxyError(ConnectionError): ...\nclass SSLError(ConnectionError): ...\nclass Timeout(RequestException): ...\nclass ConnectTimeout(ConnectionError, Timeout): ...\nclass ReadTimeout(Timeout): ...\nclass URLRequired(RequestException): ...\nclass TooManyRedirects(RequestException): ...\nclass MissingSchema(RequestException, ValueError): ...\nclass InvalidSchema(RequestException, ValueError): ...\nclass InvalidURL(RequestException, ValueError): ...\nclass InvalidHeader(RequestException, ValueError): ...\nclass InvalidProxyURL(InvalidURL): ...\nclass ChunkedEncodingError(RequestException): ...\nclass ContentDecodingError(RequestException, BaseHTTPError): ...\nclass StreamConsumedError(RequestException, TypeError): ...\nclass RetryError(RequestException): ...\nclass UnrewindableBodyError(RequestException): ...\nclass RequestsWarning(Warning): ...\nclass FileModeWarning(RequestsWarning, DeprecationWarning): ...\nclass RequestsDependencyWarning(RequestsWarning): ...\n",
    "/typeshed/requests/requests/help.pyi": "from typing import TypedDict\n\nclass _VersionDict(TypedDict):\n    version: str\n\nclass _OptionalVersionDict(TypedDict):\n    version: str | None\n\nclass _PlatformDict(TypedDict):\n    system: str\n    release: str\n\nclass _ImplementationDict(_VersionDict):\n    name: str\n\nclass _PyOpenSSLDict(_OptionalVersionDict):\n    openssl_version: str\n\nclass _InfoDict(TypedDict):\n    platform: _PlatformDict\n    implementation: _ImplementationDict\n    system_ssl: _VersionDict\n    using_pyopenssl: bool\n    using_charset_normalizer: bool\n    pyOpenSSL: _PyOpenSSLDict\n    urllib3: _VersionDict\n    chardet: _OptionalVersionDict\n    charset_normalizer: _OptionalVersionDict\n    cryptography: _VersionDict\n    idna: _VersionDict\n    requests: _VersionDict\n\ndef info() -> _InfoDict: ...\ndef main() -> None: ...\n",
    "/typeshed/requests/requests/hooks.pyi": "from typing import Any\n\nHOOKS: Any\n\ndef default_hooks(): ...\ndef dispatch_hook(key, hooks, hook_data, **kwargs): ...\n",
    "/typeshed/requests/requests/models.pyi": "import datetime\nfrom _typeshed import Unused\nfrom collections.abc import Callable, Iterator\nfrom json import JSONDecoder\nfrom typing import Any\nfrom typing_extensions import Self\n\nfrom urllib3 import exceptions as urllib3_exceptions, fields, filepost, util\n\nfrom . import auth, cookies, exceptions, hooks, status_codes, utils\nfrom .cookies import RequestsCookieJar\nfrom .structures import CaseInsensitiveDict as CaseInsensitiveDict\n\ndefault_hooks = hooks.default_hooks\nHTTPBasicAuth = auth.HTTPBasicAuth\ncookiejar_from_dict = cookies.cookiejar_from_dict\nget_cookie_header = cookies.get_cookie_header\nRequestField = fields.RequestField\nencode_multipart_formdata = filepost.encode_multipart_formdata\nparse_url = util.parse_url\nDecodeError = urllib3_exceptions.DecodeError\nReadTimeoutError = urllib3_exceptions.ReadTimeoutError\nProtocolError = urllib3_exceptions.ProtocolError\nLocationParseError = urllib3_exceptions.LocationParseError\nHTTPError = exceptions.HTTPError\nMissingSchema = exceptions.MissingSchema\nInvalidURL = exceptions.InvalidURL\nChunkedEncodingError = exceptions.ChunkedEncodingError\nContentDecodingError = exceptions.ContentDecodingError\nConnectionError = exceptions.ConnectionError\nStreamConsumedError = exceptions.StreamConsumedError\nguess_filename = utils.guess_filename\nget_auth_from_url = utils.get_auth_from_url\nrequote_uri = utils.requote_uri\nstream_decode_response_unicode = utils.stream_decode_response_unicode\nto_key_val_list = utils.to_key_val_list\nparse_header_links = utils.parse_header_links\niter_slices = utils.iter_slices\nguess_json_utf = utils.guess_json_utf\nsuper_len = utils.super_len\nto_native_string = utils.to_native_string\ncodes = status_codes.codes\n\nREDIRECT_STATI: Any\nDEFAULT_REDIRECT_LIMIT: Any\nCONTENT_CHUNK_SIZE: Any\nITER_CHUNK_SIZE: Any\n\nclass RequestEncodingMixin:\n    @property\n    def path_url(self) -> str: ...\n\nclass RequestHooksMixin:\n    def register_hook(self, event, hook): ...\n    def deregister_hook(self, event, hook): ...\n\nclass Request(RequestHooksMixin):\n    hooks: Any\n    method: Any\n    url: Any\n    headers: Any\n    files: Any\n    data: Any\n    json: Any\n    params: Any\n    auth: Any\n    cookies: Any\n    def __init__(\n        self,\n        method=None,\n        url=None,\n        headers=None,\n        files=None,\n        data=None,\n        params=None,\n        auth=None,\n        cookies=None,\n        hooks=None,\n        json=None,\n    ) -> None: ...\n    def prepare(self) -> PreparedRequest: ...\n\nclass PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n    method: str | None\n    url: str | None\n    headers: CaseInsensitiveDict[str]\n    body: bytes | str | None\n    hooks: Any\n    def __init__(self) -> None: ...\n    def prepare(\n        self,\n        method=None,\n        url=None,\n        headers=None,\n        files=None,\n        data=None,\n        params=None,\n        auth=None,\n        cookies=None,\n        hooks=None,\n        json=None,\n    ) -> None: ...\n    def copy(self) -> PreparedRequest: ...\n    def prepare_method(self, method) -> None: ...\n    def prepare_url(self, url, params) -> None: ...\n    def prepare_headers(self, headers) -> None: ...\n    def prepare_body(self, data, files, json=None) -> None: ...\n    def prepare_content_length(self, body: bytes | str | None) -> None: ...\n    def prepare_auth(self, auth, url=\"\") -> None: ...\n    def prepare_cookies(self, cookies) -> None: ...\n    def prepare_hooks(self, hooks) -> None: ...\n\nclass Response:\n    __attrs__: Any\n    _content: bytes | None  # undocumented\n    status_code: int\n    headers: CaseInsensitiveDict[str]\n    raw: Any\n    url: str\n    encoding: str | None\n    history: list[Response]\n    reason: str\n    cookies: RequestsCookieJar\n    elapsed: datetime.timedelta\n    request: PreparedRequest\n    def __init__(self) -> None: ...\n    def __bool__(self) -> bool: ...\n    def __nonzero__(self) -> bool: ...\n    def __iter__(self) -> Iterator[bytes]: ...\n    def __enter__(self) -> Self: ...\n    def __exit__(self, *args: Unused) -> None: ...\n    @property\n    def next(self) -> PreparedRequest | None: ...\n    @property\n    def ok(self) -> bool: ...\n    @property\n    def is_redirect(self) -> bool: ...\n    @property\n    def is_permanent_redirect(self) -> bool: ...\n    @property\n    def apparent_encoding(self) -> str: ...\n    def iter_content(self, chunk_size: int | None = 1, decode_unicode: bool = False) -> Iterator[Any]: ...\n    def iter_lines(\n        self, chunk_size: int | None = 512, decode_unicode: bool = False, delimiter: str | bytes | None = None\n    ) -> Iterator[Any]: ...\n    @property\n    def content(self) -> bytes: ...\n    @property\n    def text(self) -> str: ...\n    def json(\n        self,\n        *,\n        cls: type[JSONDecoder] | None = ...,\n        object_hook: Callable[[dict[Any, Any]], Any] | None = ...,\n        parse_float: Callable[[str], Any] | None = ...,\n        parse_int: Callable[[str], Any] | None = ...,\n        parse_constant: Callable[[str], Any] | None = ...,\n        object_pairs_hook: Callable[[list[tuple[Any, Any]]], Any] | None = ...,\n        **kwds: Any,\n    ) -> Any: ...\n    @property\n    def links(self) -> dict[Any, Any]: ...\n    def raise_for_status(self) -> None: ...\n    def close(self) -> None: ...\n",
    "/typeshed/requests/requests/packages.pyi": "# requests also imports urllib3, idna, and chardet below\n# requests.packages. The stubs don't reflect that and it's recommended to\n# import these packages directly if needed.\n",
    "/typeshed/requests/requests/sessions.pyi": "from _typeshed import Incomplete, SupportsItems, SupportsRead, Unused\nfrom collections.abc import Callable, Iterable, Mapping, MutableMapping\nfrom typing import Any, TypedDict\nfrom typing_extensions import Self, TypeAlias\n\nfrom urllib3._collections import RecentlyUsedContainer\n\nfrom . import adapters, auth as _auth, compat, cookies, exceptions, hooks, models, status_codes, utils\nfrom .models import Response\nfrom .structures import CaseInsensitiveDict as CaseInsensitiveDict\n\n_BaseAdapter: TypeAlias = adapters.BaseAdapter\nOrderedDict = compat.OrderedDict\ncookiejar_from_dict = cookies.cookiejar_from_dict\nextract_cookies_to_jar = cookies.extract_cookies_to_jar\nRequestsCookieJar = cookies.RequestsCookieJar\nmerge_cookies = cookies.merge_cookies\nRequest = models.Request\nPreparedRequest = models.PreparedRequest\nDEFAULT_REDIRECT_LIMIT = models.DEFAULT_REDIRECT_LIMIT\ndefault_hooks = hooks.default_hooks\ndispatch_hook = hooks.dispatch_hook\nto_key_val_list = utils.to_key_val_list\ndefault_headers = utils.default_headers\nto_native_string = utils.to_native_string\nTooManyRedirects = exceptions.TooManyRedirects\nInvalidSchema = exceptions.InvalidSchema\nChunkedEncodingError = exceptions.ChunkedEncodingError\nContentDecodingError = exceptions.ContentDecodingError\nHTTPAdapter = adapters.HTTPAdapter\nrequote_uri = utils.requote_uri\nget_environ_proxies = utils.get_environ_proxies\nget_netrc_auth = utils.get_netrc_auth\nshould_bypass_proxies = utils.should_bypass_proxies\nget_auth_from_url = utils.get_auth_from_url\ncodes = status_codes.codes\nREDIRECT_STATI = models.REDIRECT_STATI\n\ndef merge_setting(request_setting, session_setting, dict_class=...): ...\ndef merge_hooks(request_hooks, session_hooks, dict_class=...): ...\n\nclass SessionRedirectMixin:\n    def resolve_redirects(\n        self,\n        resp,\n        req,\n        stream: bool = False,\n        timeout: Incomplete | None = None,\n        verify: bool = True,\n        cert: Incomplete | None = None,\n        proxies: Incomplete | None = None,\n        yield_requests: bool = False,\n        **adapter_kwargs,\n    ): ...\n    def rebuild_auth(self, prepared_request, response): ...\n    def rebuild_proxies(self, prepared_request, proxies): ...\n    def should_strip_auth(self, old_url, new_url): ...\n    def rebuild_method(self, prepared_request: PreparedRequest, response: Response) -> None: ...\n    def get_redirect_target(self, resp: Response) -> str | None: ...\n\n_Data: TypeAlias = (\n    # used in requests.models.PreparedRequest.prepare_body\n    #\n    # case: is_stream\n    # see requests.adapters.HTTPAdapter.send\n    # will be sent directly to http.HTTPConnection.send(...) (through urllib3)\n    Iterable[bytes]\n    # case: not is_stream\n    # will be modified before being sent to urllib3.HTTPConnectionPool.urlopen(body=...)\n    # see requests.models.RequestEncodingMixin._encode_params\n    # see requests.models.RequestEncodingMixin._encode_files\n    # note that keys&values are converted from Any to str by urllib.parse.urlencode\n    | str\n    | bytes\n    | SupportsRead[str | bytes]\n    | list[tuple[Any, Any]]\n    | tuple[tuple[Any, Any], ...]\n    | Mapping[Any, Any]\n)\n_Auth: TypeAlias = tuple[str, str] | _auth.AuthBase | Callable[[PreparedRequest], PreparedRequest]\n_Cert: TypeAlias = str | tuple[str, str]\n# Files is passed to requests.utils.to_key_val_list()\n_FileName: TypeAlias = str | None\n_FileContent: TypeAlias = SupportsRead[str | bytes] | str | bytes\n_FileContentType: TypeAlias = str\n_FileCustomHeaders: TypeAlias = Mapping[str, str]\n_FileSpecTuple2: TypeAlias = tuple[_FileName, _FileContent]\n_FileSpecTuple3: TypeAlias = tuple[_FileName, _FileContent, _FileContentType]\n_FileSpecTuple4: TypeAlias = tuple[_FileName, _FileContent, _FileContentType, _FileCustomHeaders]\n_FileSpec: TypeAlias = _FileContent | _FileSpecTuple2 | _FileSpecTuple3 | _FileSpecTuple4\n_Files: TypeAlias = Mapping[str, _FileSpec] | Iterable[tuple[str, _FileSpec]]\n_Hook: TypeAlias = Callable[[Response], Any]\n_HooksInput: TypeAlias = Mapping[str, Iterable[_Hook] | _Hook]\n\n_ParamsMappingKeyType: TypeAlias = str | bytes | int | float\n_ParamsMappingValueType: TypeAlias = str | bytes | int | float | Iterable[str | bytes | int | float] | None\n_Params: TypeAlias = (\n    SupportsItems[_ParamsMappingKeyType, _ParamsMappingValueType]\n    | tuple[_ParamsMappingKeyType, _ParamsMappingValueType]\n    | Iterable[tuple[_ParamsMappingKeyType, _ParamsMappingValueType]]\n    | str\n    | bytes\n)\n_TextMapping: TypeAlias = MutableMapping[str, str]\n_HeadersUpdateMapping: TypeAlias = Mapping[str, str | bytes | None]\n_Timeout: TypeAlias = float | tuple[float, float] | tuple[float, None]\n_Verify: TypeAlias = bool | str\n\nclass _Settings(TypedDict):\n    verify: _Verify | None\n    proxies: _TextMapping\n    stream: bool\n    cert: _Cert | None\n\nclass Session(SessionRedirectMixin):\n    __attrs__: Any\n    # See https://github.com/psf/requests/issues/5020#issuecomment-989082461:\n    # requests sets this as a CaseInsensitiveDict, but users may set it to any MutableMapping\n    headers: MutableMapping[str, str | bytes]\n    auth: _Auth | None\n    proxies: _TextMapping\n    # Don't complain if:\n    #   - value is assumed to be a list (which it is by default)\n    #   - a _Hook is assigned directly, without wrapping it in a list (also works)\n    hooks: dict[str, list[_Hook] | Any]\n    params: _Params\n    stream: bool\n    verify: _Verify | None\n    cert: _Cert | None\n    max_redirects: int\n    trust_env: bool\n    cookies: RequestsCookieJar\n    adapters: MutableMapping[Any, Any]\n    redirect_cache: RecentlyUsedContainer[Any, Any]\n    def __init__(self) -> None: ...\n    def __enter__(self) -> Self: ...\n    def __exit__(self, *args: Unused) -> None: ...\n    def prepare_request(self, request: Request) -> PreparedRequest: ...\n    def request(\n        self,\n        method: str | bytes,\n        url: str | bytes,\n        params: _Params | None = None,\n        data: _Data | None = None,\n        headers: _HeadersUpdateMapping | None = None,\n        cookies: None | RequestsCookieJar | _TextMapping = None,\n        files: _Files | None = None,\n        auth: _Auth | None = None,\n        timeout: _Timeout | None = None,\n        allow_redirects: bool = True,\n        proxies: _TextMapping | None = None,\n        hooks: _HooksInput | None = None,\n        stream: bool | None = None,\n        verify: _Verify | None = None,\n        cert: _Cert | None = None,\n        json: Incomplete | None = None,\n    ) -> Response: ...\n    def get(\n        self,\n        url: str | bytes,\n        *,\n        params: _Params | None = ...,\n        data: _Data | None = ...,\n        headers: _HeadersUpdateMapping | None = ...,\n        cookies: RequestsCookieJar | _TextMapping | None = ...,\n        files: _Files | None = ...,\n        auth: _Auth | None = ...,\n        timeout: _Timeout | None = ...,\n        allow_redirects: bool = ...,\n        proxies: _TextMapping | None = ...,\n        hooks: _HooksInput | None = ...,\n        stream: bool | None = ...,\n        verify: _Verify | None = ...,\n        cert: _Cert | None = ...,\n        json: Incomplete | None = ...,\n    ) -> Response: ...\n    def options(\n        self,\n        url: str | bytes,\n        *,\n        params: _Params | None = ...,\n        data: _Data | None = ...,\n        headers: _HeadersUpdateMapping | None = ...,\n        cookies: RequestsCookieJar | _TextMapping | None = ...,\n        files: _Files | None = ...,\n        auth: _Auth | None = ...,\n        timeout: _Timeout | None = ...,\n        allow_redirects: bool = ...,\n        proxies: _TextMapping | None = ...,\n        hooks: _HooksInput | None = ...,\n        stream: bool | None = ...,\n        verify: _Verify | None = ...,\n        cert: _Cert | None = ...,\n        json: Incomplete | None = ...,\n    ) -> Response: ...\n    def head(\n        self,\n        url: str | bytes,\n        *,\n        params: _Params | None = ...,\n        data: _Data | None = ...,\n        headers: _HeadersUpdateMapping | None = ...,\n        cookies: RequestsCookieJar | _TextMapping | None = ...,\n        files: _Files | None = ...,\n        auth: _Auth | None = ...,\n        timeout: _Timeout | None = ...,\n        allow_redirects: bool = ...,\n        proxies: _TextMapping | None = ...,\n        hooks: _HooksInput | None = ...,\n        stream: bool | None = ...,\n        verify: _Verify | None = ...,\n        cert: _Cert | None = ...,\n        json: Incomplete | None = ...,\n    ) -> Response: ...\n    def post(\n        self,\n        url: str | bytes,\n        data: _Data | None = None,\n        json: Incomplete | None = None,\n        *,\n        params: _Params | None = ...,\n        headers: _HeadersUpdateMapping | None = ...,\n        cookies: RequestsCookieJar | _TextMapping | None = ...,\n        files: _Files | None = ...,\n        auth: _Auth | None = ...,\n        timeout: _Timeout | None = ...,\n        allow_redirects: bool = ...,\n        proxies: _TextMapping | None = ...,\n        hooks: _HooksInput | None = ...,\n        stream: bool | None = ...,\n        verify: _Verify | None = ...,\n        cert: _Cert | None = ...,\n    ) -> Response: ...\n    def put(\n        self,\n        url: str | bytes,\n        data: _Data | None = None,\n        *,\n        params: _Params | None = ...,\n        headers: _HeadersUpdateMapping | None = ...,\n        cookies: RequestsCookieJar | _TextMapping | None = ...,\n        files: _Files | None = ...,\n        auth: _Auth | None = ...,\n        timeout: _Timeout | None = ...,\n        allow_redirects: bool = ...,\n        proxies: _TextMapping | None = ...,\n        hooks: _HooksInput | None = ...,\n        stream: bool | None = ...,\n        verify: _Verify | None = ...,\n        cert: _Cert | None = ...,\n        json: Incomplete | None = ...,\n    ) -> Response: ...\n    def patch(\n        self,\n        url: str | bytes,\n        data: _Data | None = None,\n        *,\n        params: _Params | None = ...,\n        headers: _HeadersUpdateMapping | None = ...,\n        cookies: RequestsCookieJar | _TextMapping | None = ...,\n        files: _Files | None = ...,\n        auth: _Auth | None = ...,\n        timeout: _Timeout | None = ...,\n        allow_redirects: bool = ...,\n        proxies: _TextMapping | None = ...,\n        hooks: _HooksInput | None = ...,\n        stream: bool | None = ...,\n        verify: _Verify | None = ...,\n        cert: _Cert | None = ...,\n        json: Incomplete | None = ...,\n    ) -> Response: ...\n    def delete(\n        self,\n        url: str | bytes,\n        *,\n        params: _Params | None = ...,\n        data: _Data | None = ...,\n        headers: _HeadersUpdateMapping | None = ...,\n        cookies: RequestsCookieJar | _TextMapping | None = ...,\n        files: _Files | None = ...,\n        auth: _Auth | None = ...,\n        timeout: _Timeout | None = ...,\n        allow_redirects: bool = ...,\n        proxies: _TextMapping | None = ...,\n        hooks: _HooksInput | None = ...,\n        stream: bool | None = ...,\n        verify: _Verify | None = ...,\n        cert: _Cert | None = ...,\n        json: Incomplete | None = ...,\n    ) -> Response: ...\n    def send(\n        self,\n        request: PreparedRequest,\n        *,\n        stream: bool | None = ...,\n        verify: _Verify | None = ...,\n        proxies: _TextMapping | None = ...,\n        cert: _Cert | None = ...,\n        timeout: _Timeout | None = ...,\n        allow_redirects: bool = ...,\n        **kwargs: Any,\n    ) -> Response: ...\n    def merge_environment_settings(\n        self,\n        url: str | bytes | None,\n        proxies: _TextMapping | None,\n        stream: bool | None,\n        verify: _Verify | None,\n        cert: _Cert | None,\n    ) -> _Settings: ...\n    def get_adapter(self, url: str) -> _BaseAdapter: ...\n    def close(self) -> None: ...\n    def mount(self, prefix: str | bytes, adapter: _BaseAdapter) -> None: ...\n\ndef session() -> Session: ...\n",
    "/typeshed/requests/requests/status_codes.pyi": "from typing import Any\n\ncodes: Any\n",
    "/typeshed/requests/requests/structures.pyi": "from collections.abc import Iterable, Iterator, Mapping, MutableMapping\nfrom typing import Any, Generic, TypeVar, overload\n\n_D = TypeVar(\"_D\")\n_VT = TypeVar(\"_VT\")\n\nclass CaseInsensitiveDict(MutableMapping[str, _VT], Generic[_VT]):\n    def __init__(self, data: Mapping[str, _VT] | Iterable[tuple[str, _VT]] | None = None, **kwargs: _VT) -> None: ...\n    def lower_items(self) -> Iterator[tuple[str, _VT]]: ...\n    def __setitem__(self, key: str, value: _VT) -> None: ...\n    def __getitem__(self, key: str) -> _VT: ...\n    def __delitem__(self, key: str) -> None: ...\n    def __iter__(self) -> Iterator[str]: ...\n    def __len__(self) -> int: ...\n    def copy(self) -> CaseInsensitiveDict[_VT]: ...\n\nclass LookupDict(dict[str, _VT]):\n    name: Any\n    def __init__(self, name: Any = None) -> None: ...\n    def __getitem__(self, key: str) -> _VT | None: ...  # type: ignore[override]\n    def __setattr__(self, __attr: str, __value: _VT) -> None: ...\n    @overload\n    def get(self, key: str, default: None = None) -> _VT | None: ...\n    @overload\n    def get(self, key: str, default: _D | _VT) -> _D | _VT: ...\n",
    "/typeshed/requests/requests/utils.pyi": "import sys\nfrom _typeshed import StrOrBytesPath\nfrom collections.abc import Generator, Iterable, Mapping\nfrom contextlib import _GeneratorContextManager\nfrom io import BufferedWriter\nfrom typing import Any, AnyStr\nfrom typing_extensions import TypeAlias\n\nfrom . import compat, cookies, exceptions, structures\nfrom .models import PreparedRequest, Request\n\n_Uri: TypeAlias = str | bytes\nOrderedDict = compat.OrderedDict\ncookiejar_from_dict = cookies.cookiejar_from_dict\nCaseInsensitiveDict = structures.CaseInsensitiveDict\nInvalidURL = exceptions.InvalidURL\n\nNETRC_FILES: tuple[str, str]\nDEFAULT_CA_BUNDLE_PATH: Any\nDEFAULT_PORTS: dict[str, int]\nDEFAULT_ACCEPT_ENCODING: str\n\ndef dict_to_sequence(d): ...\ndef super_len(o): ...\ndef get_netrc_auth(url: _Uri, raise_errors: bool = False) -> tuple[str, str] | None: ...\ndef guess_filename(obj): ...\ndef extract_zipped_paths(path): ...\ndef atomic_open(filename: StrOrBytesPath) -> _GeneratorContextManager[BufferedWriter]: ...\ndef from_key_val_list(value): ...\ndef to_key_val_list(value): ...\ndef parse_list_header(value): ...\ndef parse_dict_header(value): ...\ndef unquote_header_value(value, is_filename: bool = False): ...\ndef dict_from_cookiejar(cj): ...\ndef add_dict_to_cookiejar(cj, cookie_dict): ...\ndef get_encodings_from_content(content): ...\ndef get_encoding_from_headers(headers: Mapping[str, str]) -> str | None: ...\ndef stream_decode_response_unicode(iterator, r): ...\ndef iter_slices(string: str, slice_length: int | None) -> Generator[str, None, None]: ...\ndef get_unicode_from_response(r): ...\n\nUNRESERVED_SET: frozenset[str]\n\ndef unquote_unreserved(uri: str) -> str: ...\ndef requote_uri(uri: str) -> str: ...\ndef address_in_network(ip: str, net: str) -> bool: ...\ndef dotted_netmask(mask: int) -> str: ...\ndef is_ipv4_address(string_ip: str) -> bool: ...\ndef is_valid_cidr(string_network: str) -> bool: ...\ndef set_environ(env_name: str, value: None) -> _GeneratorContextManager[None]: ...\ndef should_bypass_proxies(url: _Uri, no_proxy: Iterable[str] | None) -> bool: ...\ndef get_environ_proxies(url: _Uri, no_proxy: Iterable[str] | None = None) -> dict[Any, Any]: ...\ndef select_proxy(url: _Uri, proxies: Mapping[Any, Any] | None): ...\ndef resolve_proxies(request: Request | PreparedRequest, proxies: Mapping[str, str] | None, trust_env: bool = True): ...\ndef default_user_agent(name: str = \"python-requests\") -> str: ...\ndef default_headers() -> CaseInsensitiveDict[str]: ...\ndef parse_header_links(value: str) -> list[dict[str, str]]: ...\ndef guess_json_utf(data): ...\ndef prepend_scheme_if_needed(url, new_scheme): ...\ndef get_auth_from_url(url: _Uri) -> tuple[str, str]: ...\ndef to_native_string(string, encoding=\"ascii\"): ...\ndef urldefragauth(url: _Uri): ...\ndef rewind_body(prepared_request: PreparedRequest) -> None: ...\ndef check_header_validity(header: tuple[AnyStr, AnyStr]) -> None: ...\n\nif sys.platform == \"win32\":\n    def proxy_bypass_registry(host: str) -> bool: ...\n    def proxy_bypass(host: str) -> bool: ...\n",
    "/typeshed/matplotlib/__init__.pyi": "from . import collections, color, cm, pyplot, style, artist, legend\n\ndef use(backend: str) -> None: ...\n",
    "/typeshed/matplotlib/artist.pyi": "class Artist:\n    def set_label(self, s: str) -> None: ...\n    def remove(self) -> None: ...\n\nclass Line2D(Artist): ...\nclass Collection(Artist): ...\nclass LineCollection(Collection): ...\nclass Patch(Artist): ...\nclass Rectangle(Patch): ...\n",
    "/typeshed/matplotlib/axes.pyi": "from typing import Union, Sequence, Tuple, List, Optional, TypeVar\nfrom typing_extensions import Literal\n\nimport numpy as _np\n\nfrom .artist import Artist, Line2D, LineCollection, Rectangle\nfrom .collections import PolyCollection, PathCollection\nfrom .color import Normalize\nfrom .pyplot import Figure\nfrom .legend import Legend\nfrom .pyplot import Data, NumericArray\nfrom .image import AxesImage\nfrom .text import Text\n\n_Float = TypeVar(\"_Float\", _np.float32, _np.float64)\n\n_LegendLocation = Literal[\n    \"best\",\n    \"upper right\",\n    \"upper left\",\n    \"lower left\",\n    \"lower right\",\n    \"center left\",\n    \"center right\",\n    \"lower center\",\n    \"upper center\",\n    \"center\",\n]\n\nclass Axes:\n    title: Text\n    def axvline(\n        self,\n        x: float = ...,\n        ymin: float = ...,\n        ymax: float = ...,\n        color: str = ...,\n        linestyle: Literal[\"-\", \"--\", \"-.\", \":\", \"\"] = ...,\n    ) -> Line2D: ...\n    def set_xlabel(self, xlabel: str) -> None: ...\n    def set_ylabel(self, ylabel: str) -> None: ...\n    def set_title(self, label: str, loc: Literal[\"left\", \"center\", \"right\"] = ...) -> None: ...\n    def set_xticks(self, ticks: Union[_np.ndarray[_Float], Sequence[float]]) -> None: ...\n    def set_yticks(self, ticks: Union[_np.ndarray[_Float], Sequence[float]]) -> None: ...\n    def set_xticklabels(self, labels: List[str]) -> Text: ...\n    def set_yticklabels(self, labels: List[str]) -> Text: ...\n    def grid(\n        self,\n        b: Optional[bool] = ...,\n        which: Literal[\"major\", \"minor\", \"both\"] = ...,\n        axis: Literal[\"both\", \"x\", \"y\"] = ...,\n    ) -> None: ...\n    def get_legend_handles_labels(\n        self,\n    ) -> Tuple[List[Union[Artist, Tuple[Artist, ...]]], List[str]]: ...\n    def get_figure(self) -> Figure: ...\n    def legend(\n        self,\n        handles: Sequence[Union[Artist, Tuple[Artist, ...]]] = ...,\n        labels: Sequence[str] = ...,\n        loc: _LegendLocation = ...,\n        bbox_to_anchor: Tuple[float, float] = ...,\n    ) -> Legend: ...\n    def errorbar(\n        self,\n        x: Data,\n        y: Data,\n        *,\n        barsabove: bool = ...,\n        capsize: float = ...,\n        capthick: float = ...,\n        color: Optional[str] = ...,\n        ecolor: str = ...,\n        elinewidth: float = ...,\n        errorevery: int = ...,\n        label: str = ...,\n        linestyle: Literal[\"-\", \"--\", \"-.\", \":\", \"\"] = ...,\n        lolims: bool = ...,\n        marker: str = ...,\n        markersize: float = ...,\n        uplims: bool = ...,\n        xerr: Optional[Data] = ...,\n        xlolims: bool = ...,\n        xuplims: bool = ...,\n        yerr: Optional[Data] = ...,\n        zorder: float = ...,\n    ) -> Tuple[Line2D, Line2D, LineCollection]: ...\n    def bar(\n        self,\n        x: Data,\n        height: Data,\n        width: Data = ...,\n        bottom: Data = ...,\n        *,\n        align: Literal[\"center\", \"edge\"] = ...,\n        color: Optional[str] = ...,\n        edgecolor: str = ...,\n        hatch: str = ...,\n        label: str = ...,\n        linewidth: float = ...,\n        zorder: float = ...,\n    ) -> Tuple[Rectangle, ...]: ...\n    def imshow(\n        self, X: Data, cmap: str = ..., vmin: float = ..., vmax: float = ...\n    ) -> AxesImage: ...\n    def hist(\n        self, x: Data, bins: Union[int, Sequence[float], _np.ndarray[_Float]]\n    ) -> Tuple[List[_np.ndarray], _np.ndarray, List]: ...\n    def plot(\n        self,\n        x: Data,\n        y: Data,\n        *,\n        color: Optional[str] = ...,\n        label: str = ...,\n        linestyle: Literal[\"-\", \"--\", \"-.\", \":\", \"\"] = ...,\n        marker: str = ...,\n        markerfacecolor: str = ...,\n        markersize: float = ...,\n        scalex: bool = ...,\n        scaley: bool = ...,\n        zorder: float = ...,\n    ) -> None: ...\n    def scatter(\n        self,\n        x: Data,\n        y: Data,\n        s: Optional[Union[float, Optional[NumericArray]]] = ...,\n        c: Optional[str] = ...,\n        cmap: Optional[str] = ...,\n        norm: Optional[Normalize] = ...,\n        vmin: Optional[float] = ...,\n        vmax: Optional[float] = ...,\n        marker: Optional[str] = ...,\n        alpha: Optional[float] = ...,\n        linewidths: Optional[float] = ...,\n        verts: Optional[List[Tuple]] = ...,\n        edgecolors: Optional[Union[Literal[\"face\", \"none\"], str, Sequence[str]]] = ...,\n        *,\n        plotnonfinite: bool = ...,\n        data: Optional[Data] = ...,\n        label: str = ...,\n    ) -> PathCollection: ...\n    def set_xlim(\n        self, xmin: float = ..., xmax: float = ..., auto: Optional[bool] = ...\n    ) -> None: ...\n    def set_ylim(\n        self, ymin: float = ..., ymax: float = ..., auto: Optional[bool] = ...\n    ) -> None: ...\n    def vlines(\n        self,\n        x: Union[_Float, NumericArray],\n        ymin: Union[_Float, NumericArray],\n        ymax: Union[_Float, NumericArray],\n        colors: Union[str, Union[List[str], Tuple[str]]] = ...,\n        linestyles: Literal[\"-\", \"--\", \"-.\", \":\", \"\"] = ...,\n    ) -> LineCollection: ...\n\nclass SubplotBase(Axes):\n    def is_first_col(self) -> bool: ...\n    def is_first_row(self) -> bool: ...\n    def is_last_row(self) -> bool: ...\n    def is_last_col(self) -> bool: ...\n",
    "/typeshed/matplotlib/backend_bases.pyi": "from typing import Optional\n\nclass Event: ...\nclass LocationEvent(Event): ...\nclass MouseEvent(LocationEvent): ...\n\nclass KeyEvent(Event):\n    key: Optional[str]\n",
    "/typeshed/matplotlib/cm.pyi": "class ScalarMappable: ...\n",
    "/typeshed/matplotlib/collections.pyi": "from .artist import Artist\nfrom .cm import ScalarMappable\n\nclass Collection(Artist, ScalarMappable): ...\nclass _CollectionWithSizes(Collection): ...\nclass PolyCollection(_CollectionWithSizes): ...\nclass PathCollection(_CollectionWithSizes): ...\n",
    "/typeshed/matplotlib/color.pyi": "class Normalize: ...\n",
    "/typeshed/matplotlib/font_manager.pyi": "class FontProperties: ...\n",
    "/typeshed/matplotlib/image.pyi": "class AxesImage: ...\n",
    "/typeshed/matplotlib/legend.pyi": "from .artist import Artist\n\nclass Legend(Artist):\n    def set_title(self, title: str) -> None: ...\n",
    "/typeshed/matplotlib/patheffects.pyi": "class AbstractPathEffect: ...\n",
    "/typeshed/matplotlib/style.pyi": "def use(style: str) -> None: ...\n",
    "/typeshed/matplotlib/text.pyi": "from typing import Optional\n\nfrom .artist import Artist\n\nclass Text(Artist):\n    def get_text(self) -> str: ...\n    def set_color(self, color: str) -> None: ...\n    def set_text(self, s: Optional[str]) -> None: ...\n",
    "/typeshed/matplotlib/transforms.pyi": "class TransformNode: ...\nclass Transform(TransformNode): ...\nclass BboxBase(TransformNode): ...\nclass Bbox(BboxBase): ...\n",
    "/typeshed/six/__init__.pyi": "import builtins\nimport operator\nimport types\nimport unittest\nfrom _typeshed import IdentityFunction, Unused, _KT_contra, _VT_co\nfrom builtins import next as next\nfrom collections.abc import Callable, ItemsView, Iterable, Iterator as _Iterator, KeysView, Mapping, ValuesView\nfrom functools import wraps as wraps\nfrom importlib.util import spec_from_loader as spec_from_loader\nfrom io import BytesIO as BytesIO, StringIO as StringIO\nfrom re import Pattern\nfrom typing import Any, AnyStr, Literal, NoReturn, Protocol, TypeVar, overload\n\nfrom six import moves as moves\n\n# TODO: We should switch to the _typeshed version of SupportsGetItem\n# once mypy updates its vendored copy of typeshed and makes a new release\nclass _SupportsGetItem(Protocol[_KT_contra, _VT_co]):\n    def __contains__(self, __x: Any) -> bool: ...\n    def __getitem__(self, __key: _KT_contra) -> _VT_co: ...\n\n_T = TypeVar(\"_T\")\n_K = TypeVar(\"_K\")\n_V = TypeVar(\"_V\")\n\n__author__: str\n__version__: str\n\nPY2: Literal[False]\nPY3: Literal[True]\nPY34: Literal[True]\n\nstring_types: tuple[type[str]]\ninteger_types: tuple[type[int]]\nclass_types: tuple[type[type]]\ntext_type = str\nbinary_type = bytes\n\nMAXSIZE: int\n\ncallable = builtins.callable\n\ndef get_unbound_function(unbound: types.FunctionType) -> types.FunctionType: ...\n\ncreate_bound_method = types.MethodType\n\ndef create_unbound_method(func: types.FunctionType, cls: type) -> types.FunctionType: ...\n\nIterator = object\n\ndef get_method_function(meth: types.MethodType) -> types.FunctionType: ...\ndef get_method_self(meth: types.MethodType) -> object: ...\ndef get_function_closure(fun: types.FunctionType) -> tuple[types._Cell, ...] | None: ...\ndef get_function_code(fun: types.FunctionType) -> types.CodeType: ...\ndef get_function_defaults(fun: types.FunctionType) -> tuple[Any, ...] | None: ...\ndef get_function_globals(fun: types.FunctionType) -> dict[str, Any]: ...\ndef iterkeys(d: Mapping[_K, Any]) -> _Iterator[_K]: ...\ndef itervalues(d: Mapping[Any, _V]) -> _Iterator[_V]: ...\ndef iteritems(d: Mapping[_K, _V]) -> _Iterator[tuple[_K, _V]]: ...\ndef viewkeys(d: Mapping[_K, Any]) -> KeysView[_K]: ...\ndef viewvalues(d: Mapping[Any, _V]) -> ValuesView[_V]: ...\ndef viewitems(d: Mapping[_K, _V]) -> ItemsView[_K, _V]: ...\ndef b(s: str) -> bytes: ...\ndef u(s: str) -> str: ...\n\nunichr = chr\n\ndef int2byte(i: int) -> bytes: ...\n\n# Should be `byte2int: operator.itemgetter[int]`. But a bug in mypy prevents using TypeVar in itemgetter.__call__\ndef byte2int(obj: _SupportsGetItem[int, _T]) -> _T: ...\n\nindexbytes = operator.getitem\niterbytes = iter\n\ndef assertCountEqual(self: unittest.TestCase, first: Iterable[_T], second: Iterable[_T], msg: str | None = ...) -> None: ...\n@overload\ndef assertRaisesRegex(self: unittest.TestCase, msg: str | None = ...) -> Any: ...\n@overload\ndef assertRaisesRegex(self: unittest.TestCase, callable_obj: Callable[..., object], *args: Any, **kwargs: Any) -> Any: ...\ndef assertRegex(self: unittest.TestCase, text: AnyStr, expected_regex: AnyStr | Pattern[AnyStr], msg: Any = ...) -> None: ...\ndef assertNotRegex(self: unittest.TestCase, text: AnyStr, expected_regex: AnyStr | Pattern[AnyStr], msg: Any = ...) -> None: ...\n\nexec_ = exec\n\ndef reraise(tp: type[BaseException] | None, value: BaseException | None, tb: types.TracebackType | None = None) -> NoReturn: ...\ndef raise_from(value: BaseException | type[BaseException], from_value: BaseException | None) -> NoReturn: ...\n\nprint_ = print\n\ndef with_metaclass(meta: type, *bases: type) -> type: ...\ndef add_metaclass(metaclass: type) -> IdentityFunction: ...\ndef ensure_binary(s: bytes | str, encoding: str = \"utf-8\", errors: str = \"strict\") -> bytes: ...\ndef ensure_str(s: bytes | str, encoding: str = \"utf-8\", errors: str = \"strict\") -> str: ...\ndef ensure_text(s: bytes | str, encoding: str = \"utf-8\", errors: str = \"strict\") -> str: ...\ndef python_2_unicode_compatible(klass: _T) -> _T: ...\n\nclass _LazyDescr:\n    name: str\n    def __init__(self, name: str) -> None: ...\n    def __get__(self, obj: object, tp: Unused) -> Any: ...\n\nclass MovedModule(_LazyDescr):\n    mod: str\n    def __init__(self, name: str, old: str, new: str | None = None) -> None: ...\n    def __getattr__(self, attr: str) -> Any: ...\n\nclass MovedAttribute(_LazyDescr):\n    mod: str\n    attr: str\n    def __init__(\n        self, name: str, old_mod: str, new_mod: str, old_attr: str | None = None, new_attr: str | None = None\n    ) -> None: ...\n\ndef add_move(move: MovedModule | MovedAttribute) -> None: ...\ndef remove_move(name: str) -> None: ...\n",
    "/typeshed/six/moves/BaseHTTPServer.pyi": "from http.server import *\n",
    "/typeshed/six/moves/CGIHTTPServer.pyi": "from http.server import *\n",
    "/typeshed/six/moves/SimpleHTTPServer.pyi": "from http.server import *\n",
    "/typeshed/six/moves/__init__.pyi": "# Stubs for six.moves\n#\n# Note: Commented out items means they weren't implemented at the time.\n# Uncomment them when the modules have been added to the typeshed.\nimport importlib\nimport shlex\nfrom builtins import filter as filter, input as input, map as map, range as range, zip as zip\nfrom collections import UserDict as UserDict, UserList as UserList, UserString as UserString\nfrom functools import reduce as reduce\nfrom io import StringIO as StringIO\nfrom itertools import filterfalse as filterfalse, zip_longest as zip_longest\nfrom os import getcwd as getcwd, getcwdb as getcwdb\nfrom sys import intern as intern\n\n# import tkinter.font as tkinter_font\n# import tkinter.messagebox as tkinter_messagebox\n# import tkinter.simpledialog as tkinter_tksimpledialog\n# import tkinter.dnd as tkinter_dnd\n# import tkinter.colorchooser as tkinter_colorchooser\n# import tkinter.scrolledtext as tkinter_scrolledtext\n# import tkinter.simpledialog as tkinter_simpledialog\n# import tkinter.tix as tkinter_tix\n# import dbm.gnu as dbm_gnu\nfrom . import (\n    BaseHTTPServer as BaseHTTPServer,\n    CGIHTTPServer as CGIHTTPServer,\n    SimpleHTTPServer as SimpleHTTPServer,\n    _dummy_thread as _dummy_thread,\n    _thread as _thread,\n    builtins as builtins,\n    configparser as configparser,\n    copyreg as copyreg,\n    cPickle as cPickle,\n    email_mime_base as email_mime_base,\n    email_mime_multipart as email_mime_multipart,\n    email_mime_nonmultipart as email_mime_nonmultipart,\n    email_mime_text as email_mime_text,\n    html_entities as html_entities,\n    html_parser as html_parser,\n    http_client as http_client,\n    http_cookiejar as http_cookiejar,\n    http_cookies as http_cookies,\n    queue as queue,\n    reprlib as reprlib,\n    socketserver as socketserver,\n    tkinter as tkinter,\n    tkinter_commondialog as tkinter_commondialog,\n    tkinter_constants as tkinter_constants,\n    tkinter_dialog as tkinter_dialog,\n    tkinter_filedialog as tkinter_filedialog,\n    tkinter_tkfiledialog as tkinter_tkfiledialog,\n    tkinter_ttk as tkinter_ttk,\n    urllib as urllib,\n    urllib_error as urllib_error,\n    urllib_parse as urllib_parse,\n    urllib_robotparser as urllib_robotparser,\n)\n\n# import xmlrpc.client as xmlrpc_client\n# import xmlrpc.server as xmlrpc_server\n\nxrange = range\nreload_module = importlib.reload\ncStringIO = StringIO\nshlex_quote = shlex.quote\n",
    "/typeshed/six/moves/_dummy_thread.pyi": "import sys\n\nif sys.version_info >= (3, 9):\n    from _thread import *\nelse:\n    from _dummy_thread import *\n",
    "/typeshed/six/moves/_thread.pyi": "from _thread import *\n",
    "/typeshed/six/moves/builtins.pyi": "from builtins import *\n",
    "/typeshed/six/moves/cPickle.pyi": "from pickle import *\n",
    "/typeshed/six/moves/collections_abc.pyi": "from collections.abc import *\n",
    "/typeshed/six/moves/configparser.pyi": "# Error is not included in __all__ so export it explicitly\nfrom configparser import *\nfrom configparser import Error as Error\n",
    "/typeshed/six/moves/copyreg.pyi": "from copyreg import *\n",
    "/typeshed/six/moves/email_mime_base.pyi": "from email.mime.base import *\n",
    "/typeshed/six/moves/email_mime_multipart.pyi": "from email.mime.multipart import *\n",
    "/typeshed/six/moves/email_mime_nonmultipart.pyi": "from email.mime.nonmultipart import *\n",
    "/typeshed/six/moves/email_mime_text.pyi": "from email.mime.text import *\n",
    "/typeshed/six/moves/html_entities.pyi": "from html.entities import *\n",
    "/typeshed/six/moves/html_parser.pyi": "from html.parser import *\n",
    "/typeshed/six/moves/http_client.pyi": "# Many definitions are not included in http.client.__all__\nfrom http.client import *\nfrom http.client import (\n    ACCEPTED as ACCEPTED,\n    BAD_GATEWAY as BAD_GATEWAY,\n    BAD_REQUEST as BAD_REQUEST,\n    CONFLICT as CONFLICT,\n    CONTINUE as CONTINUE,\n    CREATED as CREATED,\n    EXPECTATION_FAILED as EXPECTATION_FAILED,\n    FAILED_DEPENDENCY as FAILED_DEPENDENCY,\n    FORBIDDEN as FORBIDDEN,\n    FOUND as FOUND,\n    GATEWAY_TIMEOUT as GATEWAY_TIMEOUT,\n    GONE as GONE,\n    HTTP_PORT as HTTP_PORT,\n    HTTP_VERSION_NOT_SUPPORTED as HTTP_VERSION_NOT_SUPPORTED,\n    HTTPS_PORT as HTTPS_PORT,\n    IM_USED as IM_USED,\n    INSUFFICIENT_STORAGE as INSUFFICIENT_STORAGE,\n    INTERNAL_SERVER_ERROR as INTERNAL_SERVER_ERROR,\n    LENGTH_REQUIRED as LENGTH_REQUIRED,\n    LOCKED as LOCKED,\n    METHOD_NOT_ALLOWED as METHOD_NOT_ALLOWED,\n    MOVED_PERMANENTLY as MOVED_PERMANENTLY,\n    MULTI_STATUS as MULTI_STATUS,\n    MULTIPLE_CHOICES as MULTIPLE_CHOICES,\n    NETWORK_AUTHENTICATION_REQUIRED as NETWORK_AUTHENTICATION_REQUIRED,\n    NO_CONTENT as NO_CONTENT,\n    NON_AUTHORITATIVE_INFORMATION as NON_AUTHORITATIVE_INFORMATION,\n    NOT_ACCEPTABLE as NOT_ACCEPTABLE,\n    NOT_EXTENDED as NOT_EXTENDED,\n    NOT_FOUND as NOT_FOUND,\n    NOT_IMPLEMENTED as NOT_IMPLEMENTED,\n    NOT_MODIFIED as NOT_MODIFIED,\n    OK as OK,\n    PARTIAL_CONTENT as PARTIAL_CONTENT,\n    PAYMENT_REQUIRED as PAYMENT_REQUIRED,\n    PRECONDITION_FAILED as PRECONDITION_FAILED,\n    PRECONDITION_REQUIRED as PRECONDITION_REQUIRED,\n    PROCESSING as PROCESSING,\n    PROXY_AUTHENTICATION_REQUIRED as PROXY_AUTHENTICATION_REQUIRED,\n    REQUEST_ENTITY_TOO_LARGE as REQUEST_ENTITY_TOO_LARGE,\n    REQUEST_HEADER_FIELDS_TOO_LARGE as REQUEST_HEADER_FIELDS_TOO_LARGE,\n    REQUEST_TIMEOUT as REQUEST_TIMEOUT,\n    REQUEST_URI_TOO_LONG as REQUEST_URI_TOO_LONG,\n    REQUESTED_RANGE_NOT_SATISFIABLE as REQUESTED_RANGE_NOT_SATISFIABLE,\n    RESET_CONTENT as RESET_CONTENT,\n    SEE_OTHER as SEE_OTHER,\n    SERVICE_UNAVAILABLE as SERVICE_UNAVAILABLE,\n    SWITCHING_PROTOCOLS as SWITCHING_PROTOCOLS,\n    TEMPORARY_REDIRECT as TEMPORARY_REDIRECT,\n    TOO_MANY_REQUESTS as TOO_MANY_REQUESTS,\n    UNAUTHORIZED as UNAUTHORIZED,\n    UNPROCESSABLE_ENTITY as UNPROCESSABLE_ENTITY,\n    UNSUPPORTED_MEDIA_TYPE as UNSUPPORTED_MEDIA_TYPE,\n    UPGRADE_REQUIRED as UPGRADE_REQUIRED,\n    USE_PROXY as USE_PROXY,\n    HTTPMessage as HTTPMessage,\n    parse_headers as parse_headers,\n)\n",
    "/typeshed/six/moves/http_cookiejar.pyi": "from http.cookiejar import *\n",
    "/typeshed/six/moves/http_cookies.pyi": "# Morsel is not included in __all__ so export it explicitly\nfrom http.cookies import *\nfrom http.cookies import Morsel as Morsel\n",
    "/typeshed/six/moves/queue.pyi": "from queue import *\n",
    "/typeshed/six/moves/reprlib.pyi": "from reprlib import *\n",
    "/typeshed/six/moves/socketserver.pyi": "from socketserver import *\n",
    "/typeshed/six/moves/tkinter.pyi": "from tkinter import *\n",
    "/typeshed/six/moves/tkinter_commondialog.pyi": "from tkinter.commondialog import *\n",
    "/typeshed/six/moves/tkinter_constants.pyi": "from tkinter.constants import *\n",
    "/typeshed/six/moves/tkinter_dialog.pyi": "from tkinter.dialog import *\n",
    "/typeshed/six/moves/tkinter_filedialog.pyi": "from tkinter.filedialog import *\n",
    "/typeshed/six/moves/tkinter_tkfiledialog.pyi": "from tkinter.filedialog import *\n",
    "/typeshed/six/moves/tkinter_ttk.pyi": "from tkinter.ttk import *\n",
    "/typeshed/six/moves/urllib_error.pyi": "from urllib.error import *\n",
    "/typeshed/six/moves/urllib_parse.pyi": "from urllib.parse import *\n",
    "/typeshed/six/moves/urllib_request.pyi": "from .urllib.request import *\n",
    "/typeshed/six/moves/urllib_response.pyi": "from .urllib.response import *\n",
    "/typeshed/six/moves/urllib_robotparser.pyi": "from urllib.robotparser import *\n",
    "/typeshed/six/moves/urllib/__init__.pyi": "from six.moves.urllib import error as error, parse as parse, request as request, response as response, robotparser as robotparser\n",
    "/typeshed/six/moves/urllib/error.pyi": "from urllib.error import ContentTooShortError as ContentTooShortError, HTTPError as HTTPError, URLError as URLError\n",
    "/typeshed/six/moves/urllib/parse.pyi": "# Stubs for six.moves.urllib.parse\n#\n# Note: Commented out items means they weren't implemented at the time.\n# Uncomment them when the modules have been added to the typeshed.\n# from urllib.parse import splitquery as splitquery\n# from urllib.parse import splittag as splittag\n# from urllib.parse import splituser as splituser\nfrom urllib.parse import (\n    ParseResult as ParseResult,\n    SplitResult as SplitResult,\n    parse_qs as parse_qs,\n    parse_qsl as parse_qsl,\n    quote as quote,\n    quote_plus as quote_plus,\n    unquote as unquote,\n    unquote_plus as unquote_plus,\n    unquote_to_bytes as unquote_to_bytes,\n    urldefrag as urldefrag,\n    urlencode as urlencode,\n    urljoin as urljoin,\n    urlparse as urlparse,\n    urlsplit as urlsplit,\n    urlunparse as urlunparse,\n    urlunsplit as urlunsplit,\n    uses_fragment as uses_fragment,\n    uses_netloc as uses_netloc,\n    uses_params as uses_params,\n    uses_query as uses_query,\n    uses_relative as uses_relative,\n)\n",
    "/typeshed/six/moves/urllib/request.pyi": "# Stubs for six.moves.urllib.request\n#\n# Note: Commented out items means they weren't implemented at the time.\n# Uncomment them when the modules have been added to the typeshed.\n# from urllib.request import proxy_bypass as proxy_bypass\nfrom urllib.request import (\n    AbstractBasicAuthHandler as AbstractBasicAuthHandler,\n    AbstractDigestAuthHandler as AbstractDigestAuthHandler,\n    BaseHandler as BaseHandler,\n    CacheFTPHandler as CacheFTPHandler,\n    FancyURLopener as FancyURLopener,\n    FileHandler as FileHandler,\n    FTPHandler as FTPHandler,\n    HTTPBasicAuthHandler as HTTPBasicAuthHandler,\n    HTTPCookieProcessor as HTTPCookieProcessor,\n    HTTPDefaultErrorHandler as HTTPDefaultErrorHandler,\n    HTTPDigestAuthHandler as HTTPDigestAuthHandler,\n    HTTPErrorProcessor as HTTPErrorProcessor,\n    HTTPHandler as HTTPHandler,\n    HTTPPasswordMgr as HTTPPasswordMgr,\n    HTTPPasswordMgrWithDefaultRealm as HTTPPasswordMgrWithDefaultRealm,\n    HTTPRedirectHandler as HTTPRedirectHandler,\n    HTTPSHandler as HTTPSHandler,\n    OpenerDirector as OpenerDirector,\n    ProxyBasicAuthHandler as ProxyBasicAuthHandler,\n    ProxyDigestAuthHandler as ProxyDigestAuthHandler,\n    ProxyHandler as ProxyHandler,\n    Request as Request,\n    UnknownHandler as UnknownHandler,\n    URLopener as URLopener,\n    build_opener as build_opener,\n    getproxies as getproxies,\n    install_opener as install_opener,\n    parse_http_list as parse_http_list,\n    parse_keqv_list as parse_keqv_list,\n    pathname2url as pathname2url,\n    url2pathname as url2pathname,\n    urlcleanup as urlcleanup,\n    urlopen as urlopen,\n    urlretrieve as urlretrieve,\n)\n",
    "/typeshed/six/moves/urllib/response.pyi": "# Stubs for six.moves.urllib.response\n#\n# Note: Commented out items means they weren't implemented at the time.\n# Uncomment them when the modules have been added to the typeshed.\n# from urllib.response import addbase as addbase\n# from urllib.response import addclosehook as addclosehook\n# from urllib.response import addinfo as addinfo\nfrom urllib.response import addinfourl as addinfourl\n",
    "/typeshed/six/moves/urllib/robotparser.pyi": "from urllib.robotparser import RobotFileParser as RobotFileParser\n",
    "/typeshed/pandas/__init__.pyi": "\"\"\"Pandas public API\"\"\"\nfrom pathlib import Path\nfrom typing import (\n    IO,\n    Any,\n    Callable,\n    Dict,\n    List,\n    Mapping,\n    Optional,\n    Sequence,\n    Tuple,\n    Type,\n    TypeVar,\n    Union,\n    overload,\n)\n\nimport numpy as _np\nfrom typing_extensions import Literal\n\nfrom . import testing\nfrom .core.arrays.integer import Int8Dtype as Int8Dtype\nfrom .core.arrays.integer import Int16Dtype as Int16Dtype\nfrom .core.arrays.integer import Int32Dtype as Int32Dtype\nfrom .core.arrays.integer import Int64Dtype as Int64Dtype\nfrom .core.arrays.integer import UInt8Dtype as UInt8Dtype\nfrom .core.arrays.integer import UInt16Dtype as UInt16Dtype\nfrom .core.arrays.integer import UInt32Dtype as UInt32Dtype\nfrom .core.arrays.integer import UInt64Dtype as UInt64Dtype\nfrom .core.frame import DataFrame as DataFrame\nfrom .core.frame import _AxisType, _ListLike\nfrom .core.indexes import Index as Index\nfrom .core.indexes import MultiIndex as MultiIndex\nfrom .core.series import Series as Series\n\ndef concat(\n    dataframes: Union[Sequence[DataFrame], Mapping[str, DataFrame]],\n    axis: _AxisType = ...,\n    sort: Optional[bool] = ...,\n    ignore_index: bool = ...,\n) -> DataFrame: ...\ndef cut(arr: _np.ndarray, bins: int) -> Tuple[Union[Series, _np.ndarray], _np.ndarray]: ...\ndef get_dummies(df: Union[DataFrame, Series], columns: Optional[_ListLike] = ...) -> DataFrame: ...\n@overload\ndef isna(obj: Union[float, str]) -> bool: ...\n@overload\ndef isna(obj: DataFrame) -> DataFrame: ...\n@overload\ndef isna(obj: Series) -> Series[bool]: ...\n@overload\ndef isna(obj: Union[Index, _np.ndarray]) -> _np.ndarray[_np.bool_]: ...\n@overload\ndef isnull(obj: Union[None, float, str]) -> bool: ...\n@overload\ndef isnull(obj: DataFrame) -> DataFrame: ...\n@overload\ndef isnull(obj: Series) -> Series[bool]: ...\n@overload\ndef isnull(obj: Union[Index, _np.ndarray]) -> _np.ndarray[_np.bool_]: ...\n@overload\ndef merge(left: DataFrame, right: DataFrame, on: str = ...) -> DataFrame: ...\n@overload\ndef merge(\n    left: DataFrame, right: DataFrame, left_on: str, right_on: str, how: str\n) -> DataFrame: ...\n@overload\ndef merge(\n    left: DataFrame, right: DataFrame, left_on: List[str], right_on: List[str], how: str\n) -> DataFrame: ...\n@overload\ndef merge(\n    left: DataFrame,\n    right: DataFrame,\n    left_index: bool = ...,\n    right_index: bool = ...,\n    how: str = ...,\n) -> DataFrame: ...\ndef read_parquet(\n    path: Union[str, Path, IO],\n    engine: Literal[\"auto\", \"pyarrow\", \"fastparquet\"] = ...,\n    columns: Optional[List[str]] = ...,\n    **kwargs: Any,\n) -> DataFrame: ...\ndef read_pickle(\n    path: Union[str, Path, IO],\n    compression: Optional[Literal[\"infer\", \"gzip\", \"bz2\", \"zip\", \"xz\"]] = ...,\n) -> DataFrame: ...\ndef read_csv(\n    filepath_or_buffer: Union[str, Path, IO],\n    sep: str = ...,\n    delimiter: Optional[str] = ...,  # only an alias to sep\n    header: Optional[Union[int, List[int], Literal[\"infer\"]]] = ...,\n    names: Optional[List[str]] = ...,\n    index_col: Optional[Union[str, int, List[str], Tuple[str, ...], Sequence[int], bool]] = ...,\n    usecols: Optional[Union[List[str], List[int], Callable]] = ...,\n    squeeze: bool = ...,\n    prefix: Optional[str] = ...,\n    mangle_dupe_cols: bool = ...,\n    dtype: Optional[Union[Type, str, Mapping[str, Union[str, Type]]]] = ...,\n    engine: Optional[Union[Literal[\"c\"], Literal[\"python\"]]] = ...,\n    converters: Dict[Union[str, int], Callable] = ...,\n    true_values: Optional[List] = ...,\n    false_values: Optional[List] = ...,\n    skipinitialspace: bool = ...,\n    skiprows: Optional[Union[int, _ListLike, Callable]] = ...,\n    skipfooter: int = ...,\n    nrows: Optional[int] = ...,\n    na_values: Optional[Union[str, List[str]]] = ...,\n    keep_default_na: bool = ...,\n    na_filter: bool = ...,\n    verbose: bool = ...,\n    skip_blank_line: bool = ...,\n    parse_dates: Union[bool, List[int], List[str], List[List[int]], Dict[str, List[int]]] = ...,\n    infer_datetime_format: bool = ...,\n    keep_date_col: bool = ...,\n    date_parser: Optional[Callable] = ...,\n    dayfirst: bool = ...,\n    cache_dates: bool = ...,\n    iterator: bool = ...,\n    chunksize: Optional[int] = ...,\n    compression: Optional[Literal[\"infer\", \"gzip\", \"bz3\", \"zip\", \"xz\"]] = ...,\n    thousands: Optional[str] = ...,\n    decimal: Optional[str] = ...,\n    lineterminator: Optional[str] = ...,\n    quotechar: Optional[str] = ...,\n    quoting: Optional[Literal[0, 1, 2, 3]] = ...,\n    doublequote: bool = ...,\n    escapechar: Optional[str] = ...,\n    comment: Optional[str] = ...,\n    encoding: Optional[str] = ...,\n    dialect: Any = ...,  # TODO str or csv.Dialect Optional\n    error_bad_lines: bool = ...,\n    warn_bad_lines: bool = ...,\n    delim_whitespace: bool = ...,\n    low_memory: bool = ...,\n    memory_map: bool = ...,\n    float_precision: Optional[str] = ...,\n) -> DataFrame: ...\ndef read_sql(\n    sql: Union[str, Any],\n    con: Union[str, Any] = ...,\n    index_col: Optional[Union[str, List[str]]] = ...,\n    coerce_float: bool = ...,\n    params: Optional[Union[List[str], Tuple[str, ...], Dict[str, str]]] = ...,\n    parse_dates: Optional[Union[List[str], Dict[str, str], Dict[str, Dict[str, Any]]]] = ...,\n    columns: List[str] = ...,\n    chunksize: int = ...,\n) -> DataFrame: ...\ndef read_feather(p: Union[Path, IO]) -> DataFrame: ...\ndef read_json(\n    path_or_buf: str = ...,\n    orient: Optional[Literal[\"split\", \"records\", \"index\", \"columns\", \"values\", \"table\"]] = ...,\n    typ: Literal[\"frame\", \"series\"] = ...,\n    dtype: Optional[Union[bool, Dict[str, str]]] = ...,\n    convert_axes: Optional[bool] = ...,\n    convert_dates: Optional[Union[bool, List[str]]] = ...,\n    keep_default_dates: Optional[bool] = ...,\n    numpy: Optional[bool] = ...,\n    precise_float: Optional[bool] = ...,\n    date_unit: Optional[str] = ...,\n    encoding: str = ...,\n    lines: bool = ...,\n    chunksize: Optional[int] = ...,\n    compression: Optional[Literal[\"infer\", \"gzip\", \"bz3\", \"zip\", \"xz\"]] = ...,\n    nrows: Optional[int] = ...,\n) -> Union[DataFrame, Series]: ...\ndef to_numeric(\n    arg: Union[int, float, List, Tuple, _np.ndarray, Series],\n    errors: Literal[\"ignore\", \"raise\", \"coerce\"] = ...,\n    downcast: Literal[\"integer\", \"signed\", \"unsigned\", \"float\"] = ...,\n) -> Union[Series, _np.ndarray]: ...\ndef unique(values: Series) -> _np.ndarray: ...\n",
    "/typeshed/pandas/testing.pyi": "from typing import Optional\n\nfrom .core.frame import DataFrame\nfrom .core.series import Series\nfrom .core.indexes import Index\n\ndef assert_frame_equal(\n    left: DataFrame,\n    right: DataFrame,\n    check_like: Optional[bool] = ...,\n    check_exact: Optional[bool] = ...,\n    check_dtype: bool = ...,\n) -> None: ...\ndef assert_index_equal(left: Index, right: Index) -> None: ...\ndef assert_series_equal(\n    left: Series, right: Series, check_names: bool = ..., check_dtype: bool = ...\n) -> None: ...\n",
    "/typeshed/pandas/core/__init__.pyi": "",
    "/typeshed/pandas/core/api.pyi": "from .arrays.integer import (\n    Int8Dtype,\n    Int16Dtype,\n    Int32Dtype,\n    Int64Dtype,\n    UInt8Dtype,\n    UInt16Dtype,\n    UInt32Dtype,\n    UInt64Dtype,\n)\n",
    "/typeshed/pandas/core/frame.pyi": "import sre_compile\nimport sys\nfrom pathlib import Path\nfrom typing import (\n    Any,\n    Callable,\n    Dict,\n    Hashable,\n    Iterable,\n    Iterator,\n    List,\n    Mapping,\n    NamedTuple,\n    Optional,\n    Pattern,\n    Sequence,\n    Tuple,\n    Type,\n    Union,\n    overload,\n)\n\nimport matplotlib\nimport numpy as _np\nfrom typing_extensions import Literal\n\nfrom .groupby.generic import DataFrameGroupBy\nfrom .indexes import Index\nfrom .indexing import _AtIndexerFrame, _iLocIndexerFrame, _LocIndexerFrame\nfrom .series import Series, _DTypeNp\n\n_str = str  # needed because Series has a property called \"str\"...\n\n_AxisType = Literal[\"columns\", \"index\", 0, 1]\n\n_ErrorType = Literal[\"raise\", \"ignore\"]\n\n_ListLike = Union[Series, Index, _np.ndarray, Sequence]\n\n_ColSubsetType = Union[Series, DataFrame, List[_str], _str, _np.ndarray[_np.str_]]\n\n_FunctionLike = Union[_str, Callable]\n\n_TypeLike = Union[_str, _np.dtype, Type[_np.void], Type[float], Type[_str]]\n\n_Label = Optional[Hashable]\n\n_Renamer = Union[Mapping[_Label, Any], Callable[[_Label], _Label]]\n\nclass DataFrame:\n    def __init__(\n        self,\n        data: Optional[Union[_ListLike, DataFrame, Dict[_str, _ListLike]]] = ...,\n        columns: Optional[_ListLike] = ...,\n        index: Optional[_ListLike] = ...,\n        dtype: Optional[_TypeLike] = ...,\n    ): ...\n    #\n    # magic methods\n    def __add__(self, other: float) -> DataFrame: ...\n    def __and__(self, other: DataFrame) -> DataFrame: ...\n    def __eq__(self, other: Union[float, Series, DataFrame]) -> DataFrame: ...  # type: ignore\n    def __floordiv__(self, other: float) -> DataFrame: ...\n    def __ge__(self, other: float) -> DataFrame: ...\n    def __getattr__(self, name: _str) -> Series: ...\n    @overload\n    def __getitem__(self, idx: _str) -> Series: ...\n    @overload\n    def __getitem__(\n        self, idx: Union[Series, DataFrame, List[_str], Index[_str], _np.ndarray[_np.str_]]\n    ) -> DataFrame: ...\n    def __gt__(self, other: float) -> DataFrame: ...\n    def __iter__(self) -> Iterator: ...\n    def __le__(self, other: float) -> DataFrame: ...\n    def __len__(self) -> int: ...\n    def __lt__(self, other: float) -> DataFrame: ...\n    def __mul__(self, other: float) -> DataFrame: ...\n    def __ne__(self, other: Union[float, Series, DataFrame]) -> DataFrame: ...  # type: ignore\n    def __or__(self, other: DataFrame) -> DataFrame: ...\n    def __radd__(self, other: float) -> DataFrame: ...\n    def __rsub__(self, other: float) -> DataFrame: ...\n    def __setitem__(self, key: Any, value: Any) -> None: ...\n    def __sub__(self, other: float) -> DataFrame: ...\n    #\n    # properties\n    @property\n    def columns(self) -> Index[_str]: ...\n    @columns.setter  # setter needs to be right next to getter; otherwise mypy complains\n    def columns(self, cols: Union[List[_str], Index[_str]]) -> None: ...\n    @property\n    def dtypes(self) -> Series: ...\n    @property\n    def iloc(self) -> _iLocIndexerFrame: ...\n    @property\n    def index(self) -> Index[int]: ...\n    @index.setter\n    def index(self, idx: Index) -> None: ...\n    @property\n    def loc(self) -> _LocIndexerFrame: ...\n    @property\n    def shape(self) -> Tuple[int, ...]: ...\n    @property\n    def size(self) -> int: ...\n    @property\n    def T(self) -> DataFrame: ...\n    # this function is deprecated:\n    @property\n    def values(self) -> _np.ndarray: ...\n    @property\n    def empty(self) -> bool: ...\n    #\n    # methods\n    @overload\n    def any(\n        self, axis: Optional[_AxisType] = ..., bool_only: Optional[bool] = ..., skipna: bool = ...\n    ) -> Series: ...\n    @overload\n    def any(\n        self,\n        level: int,\n        axis: Optional[_AxisType] = ...,\n        bool_only: Optional[bool] = ...,\n        skipna: bool = ...,\n    ) -> DataFrame: ...\n    def append(\n        self, s: Union[DataFrame, Dict[_str, Any]], ignore_index: bool = ..., sort: bool = ...\n    ) -> DataFrame: ...\n    def apply(\n        self, f: Callable[[Series], Any], axis: _AxisType = ...\n    ) -> Union[Series, DataFrame]: ...\n    def assign(self, **kwargs: Any) -> DataFrame: ...\n    def astype(\n        self,\n        dtype: Union[_TypeLike, Dict[Hashable, _TypeLike]],\n        copy: bool = ...,\n        errors: _ErrorType = ...,\n    ) -> DataFrame: ...\n    def copy(self, deep: bool = ...) -> DataFrame: ...\n    def corr(self, method: Optional[_str] = ..., min_periods: Optional[int] = ...) -> DataFrame: ...\n    def count(self) -> Series: ...\n    @overload\n    def drop(\n        self, labels: Union[_str, List[_str], Index], axis: _AxisType = ..., inplace: bool = ...\n    ) -> DataFrame: ...\n    @overload\n    def drop(self, *, index: Union[List[_str], Index]) -> DataFrame: ...\n    @overload\n    def drop(self, *, columns: Union[_str, List[_str], Index]) -> DataFrame: ...\n    def drop_duplicates(self, keep: Union[_str, bool] = ...) -> DataFrame: ...\n    def transpose(self, *args: int, copy: bool = ...) -> DataFrame: ...\n    @overload\n    def dropna(\n        self,\n        inplace: Literal[False] = ...,\n        axis: Optional[_AxisType] = ...,\n        how: _str = ...,\n        subset: _ColSubsetType = ...,\n    ) -> DataFrame: ...\n    @overload\n    def dropna(\n        self,\n        inplace: Literal[True],\n        axis: Optional[_AxisType] = ...,\n        how: _str = ...,\n        subset: _ColSubsetType = ...,\n    ) -> None: ...\n    @overload\n    def fillna(\n        self,\n        value: Union[float, Dict, Series, DataFrame, _str] = ...,\n        method: _str = ...,\n        axis: Optional[_AxisType] = ...,\n        inplace: Literal[False] = ...,\n        limit: int = ...,\n        downcast: Dict = ...,\n    ) -> DataFrame: ...\n    @overload\n    def fillna(\n        self,\n        inplace: Literal[True],\n        value: Union[float, Dict, Series, DataFrame, _str] = ...,\n        method: _str = ...,\n        axis: Optional[_AxisType] = ...,\n        limit: int = ...,\n        downcast: Dict = ...,\n    ) -> None: ...\n    @overload\n    def filter(\n        self,\n        items: List[_str],\n        axis: _AxisType = ...,\n    ) -> DataFrame: ...\n    @overload\n    def filter(self, *, like: _str, axis: _AxisType = ...) -> DataFrame: ...\n    @overload\n    def filter(self, *, regex: _str, axis: _AxisType = ...) -> DataFrame: ...\n    @overload\n    def groupby(\n        self,\n        by: Union[\n            _str,\n            Tuple[_str, ...],\n            List[_str],\n            List[Tuple[_str, _str]],\n            List[Tuple[_str, _str, _str]],\n        ],\n        level: Union[int, _str] = ...,\n        as_index: bool = ...,\n        sort: bool = ...,\n        group_keys: bool = ...,\n        squeeze: bool = ...,\n        observed: bool = ...,\n    ) -> DataFrameGroupBy: ...\n    @overload\n    def groupby(\n        self,\n        by: Union[Series[_str], Dict[_str, _str], Callable],\n        axis: _AxisType = ...,\n        level: Union[int, _str] = ...,\n        sort: bool = ...,\n        group_keys: bool = ...,\n        squeeze: bool = ...,\n        observed: bool = ...,\n    ) -> DataFrameGroupBy: ...\n    def head(self, n: int = ...) -> DataFrame: ...\n    def idxmax(self, axis: _AxisType = ...) -> Series: ...\n    def idxmin(self, axis: _AxisType = ...) -> Series: ...\n    def insert(\n        self, loc: int, column: _str, value: _ListLike, allow_duplicates: bool = ...\n    ) -> None: ...\n    def isin(self, values: Union[Iterable, Series, DataFrame, Dict]) -> DataFrame: ...\n    def isna(self) -> DataFrame: ...\n    def isnull(self) -> DataFrame: ...\n    def iterrows(self) -> Iterator[Tuple[_Label, Series]]: ...\n    @overload\n    def itertuples(self, name: Literal[None], index: bool = ...) -> Iterator[Tuple[Any, ...]]: ...\n    @overload\n    def itertuples(self, name: _str, index: bool = ...) -> Iterator[NamedTuple]: ...\n    @overload\n    def itertuples(self, index: bool = ...) -> Iterator[NamedTuple]: ...\n    def max(self) -> Series: ...\n    def mean(self) -> Series: ...\n    @overload\n    def merge(\n        self,\n        right: DataFrame,\n        on: Union[_str, List[_str]],\n        how: Literal[\"left\", \"right\", \"inner\", \"outer\"] = ...,\n        suffixes: Iterable[_str] = ...,\n    ) -> DataFrame: ...\n    @overload\n    def merge(\n        self,\n        right: DataFrame,\n        left_on: Union[_str, List[_str]],\n        right_on: Union[_str, List[_str]],\n        how: Literal[\"left\", \"right\", \"inner\", \"outer\"] = ...,\n        suffixes: Iterable[_str] = ...,\n    ) -> DataFrame: ...\n    def min(self) -> Series: ...\n    def mode(self, axis: _AxisType = ...) -> DataFrame: ...\n    def median(\n        self, axis: int = ..., skipna: bool = ..., level: Union[int, _str] = ...\n    ) -> Union[DataFrame, Series]: ...\n    def notna(self) -> DataFrame: ...\n    def notnull(self) -> DataFrame: ...\n    def nunique(self) -> Series: ...\n    def plot(self, kind: _str, yerr: DataFrame) -> matplotlib.axes.Axes: ...\n    def query(self, expr: _str) -> DataFrame: ...\n    def rank(\n        self,\n        axis: _AxisType = ...,\n        method: _str = ...,\n        numeric_only: Optional[bool] = ...,\n        na_option: _str = ...,\n        ascending: bool = ...,\n        pct: bool = ...,\n    ) -> DataFrame: ...\n    @overload\n    def reindex(self, index: Index) -> DataFrame: ...\n    @overload\n    def reindex(self, columns: List[_str]) -> DataFrame: ...\n    # rename specifying mapper= and axis=\n    @overload\n    def rename(\n        self, mapper: _Renamer, *, inplace: Literal[True], axis: _AxisType = ...\n    ) -> None: ...\n    @overload\n    def rename(\n        self, mapper: _Renamer, axis: _AxisType = ..., inplace: Literal[False] = ...\n    ) -> DataFrame: ...\n    @overload\n    # rename specifying columns=\n    def rename(self, *, columns: _Renamer, inplace: Literal[True]) -> None: ...\n    @overload\n    def rename(self, *, columns: _Renamer, inplace: Literal[False] = ...) -> DataFrame: ...\n    # rename specifying index=\n    @overload\n    def rename(self, *, index: _Renamer, inplace: Literal[True]) -> None: ...\n    @overload\n    def rename(self, *, index: _Renamer, inplace: Literal[False] = ...) -> DataFrame: ...\n    def replace(\n        self,\n        a: Union[_np.dtype, _str, Pattern[_str]],\n        b: Union[_np.dtype, float, _str],\n        regex: bool = ...,\n        inplace: bool = ...,\n    ) -> DataFrame: ...\n    @overload\n    def reset_index(self, drop: bool = ...) -> DataFrame: ...\n    @overload\n    def reset_index(self, inplace: Literal[True], drop: bool = ...) -> None: ...\n    @overload\n    def sample(self, frac: float, random_state: int = ..., replace: bool = ...) -> DataFrame: ...\n    @overload\n    def sample(self, n: int, random_state: int = ..., replace: bool = ...) -> DataFrame: ...\n    @overload\n    def sample(self, n: int, random_state: int = ..., axis: _AxisType = ...) -> DataFrame: ...\n    @overload\n    def sample(self, axis: _str, frac: float) -> DataFrame: ...\n    def set_index(self, index: Union[_str, List[_str]]) -> DataFrame: ...\n    def sort_index(\n        self,\n        axis: _AxisType = ...,\n        level: Optional[Union[int, _str, List[int], List[_str]]] = ...,\n        ascending: bool = ...,\n        inplace: bool = ...,\n        kind: _str = ...,\n        na_position: _str = ...,\n        sort_remaining: bool = ...,\n        ignore_index: bool = ...,\n    ) -> Optional[DataFrame]: ...\n    @overload\n    def sort_values(\n        self,\n        by: Union[_str, List[_str]],\n        inplace: Literal[True],\n        axis: _AxisType = ...,\n        ascending: Union[bool, List[bool]] = ...,\n    ) -> None: ...\n    @overload\n    def sort_values(\n        self,\n        by: Union[_str, List[_str]],\n        inplace: Optional[Literal[False]] = ...,\n        axis: _AxisType = ...,\n        ascending: Union[bool, List[bool]] = ...,\n    ) -> DataFrame: ...\n    def std(self) -> Series: ...\n    def sum(self, axis: _AxisType = ...) -> Series: ...\n    def tail(self, n: int = ...) -> DataFrame: ...\n    def to_csv(\n        self,\n        path_or_buf: Optional[Union[Path, _str]] = ...,\n        sep: _str = ...,\n        na_rep: _str = ...,\n        float_format: Optional[_str] = ...,\n        columns: Optional[Sequence[Optional[Hashable]]] = ...,\n        header: Union[bool, List[_str]] = ...,\n        index: bool = ...,\n        index_label: Optional[Union[bool, _str, Sequence[Optional[Hashable]]]] = ...,\n        mode: _str = ...,\n        encoding: Optional[_str] = ...,\n        compression: Optional[\n            Union[Literal[\"infer\", \"gzip\", \"bz3\", \"zip\", \"xz\"], Mapping[_str, _str]]\n        ] = ...,\n        quoting: Optional[int] = ...,\n        quotechar: _str = ...,\n        line_terminator: Optional[_str] = ...,\n        chunksize: Optional[int] = ...,\n        date_format: Optional[_str] = ...,\n        doublequote: bool = ...,\n        escape_char: Optional[_str] = ...,\n        decimal: _str = ...,\n    ) -> Optional[_str]: ...\n    @overload\n    def to_dict(self) -> Dict[_str, Any]: ...\n    @overload\n    def to_dict(self, orient: _str) -> List[Dict[_str, Any]]: ...\n    def to_feather(self, filename: Path) -> None: ...\n    def to_html(\n        self,\n        columns: Optional[Sequence[_str]] = ...,\n        col_space: Optional[int] = ...,\n        header: bool = ...,\n        index: bool = ...,\n        na_rep: _str = ...,\n        formatters: Optional[\n            Union[List[Callable[[_str], _str]], Dict[_str, Callable[[_str], _str]]]\n        ] = ...,\n        float_format: Optional[Callable[[_str], _str]] = ...,\n        sparsify: Optional[bool] = ...,\n        index_names: bool = ...,\n        justify: Optional[\n            Literal[\n                \"left\",\n                \"right\",\n                \"center\",\n                \"justify\",\n                \"justify-all\",\n                \"start\",\n                \"end\",\n                \"inherit\",\n                \"match-parent\",\n                \"initial\",\n                \"unset\",\n            ]\n        ] = ...,\n        bold_rows: bool = ...,\n        classes: Optional[Union[_str, List[_str], Tuple[_str, ...]]] = ...,\n        escape: bool = ...,\n        max_rows: Optional[int] = ...,\n        max_cols: Optional[int] = ...,\n        show_dimensions: bool = ...,\n        notebook: bool = ...,\n        decimal: _str = ...,\n        border: Optional[int] = ...,\n        table_id: Optional[_str] = ...,\n    ) -> _str: ...\n    @overload\n    def to_numpy(self) -> _np.ndarray: ...\n    @overload\n    def to_numpy(self, dtype: Type[_DTypeNp]) -> _np.ndarray[_DTypeNp]: ...\n    def to_parquet(\n        self,\n        path: Union[Path, _str],\n        engine: Literal[\"auto\", \"pyarrow\", \"fastparquet\"] = ...,\n        compression: Union[Literal[\"snappy\", \"gzip\", \"brotli\"], None] = ...,\n        index: Optional[bool] = ...,\n        partition_colslist: Optional[List[_str]] = ...,\n        **kwargs: Any,\n    ) -> None: ...\n    def to_pickle(\n        self,\n        path: Union[Path, _str],\n        compression: Optional[Literal[\"infer\", \"gzip\", \"bz2\", \"zip\", \"xz\"]] = ...,\n        protocol: int = ...,\n    ) -> None: ...\n    def unique(self) -> DataFrame: ...\n    def update(self, other: Union[DataFrame, Series]) -> None: ...\n    def where(self, cond: Union[Series, DataFrame, _np.ndarray]) -> DataFrame: ...\n    @property\n    def at(self) -> _AtIndexerFrame: ...\n\n# Local Variables:\n# blacken-line-length: 100\n# blacken-allow-py36: t\n# blacken-skip-string-normalization: t\n# End:\n",
    "/typeshed/pandas/core/indexing.pyi": "from typing import Union, overload, Tuple, List, Generic, Hashable\nimport numpy as _np\n\nfrom .series import Series, _DType\nfrom .frame import DataFrame\nfrom .indexes import Index\n\n_IndexType = Union[slice, _np.ndarray[_np.int64], Index[int], List[int], Series[int]]\n_MaskType = Union[Series[bool], _np.ndarray[_np.bool_], List[bool]]\n_StrLike = Union[str, _np.str_]\n\nclass _iLocIndexerFrame:\n    # get item\n    @overload\n    def __getitem__(self, idx: int) -> Series: ...\n    @overload\n    def __getitem__(self, idx: Tuple[int, int]) -> float: ...\n    @overload\n    def __getitem__(self, idx: _IndexType) -> DataFrame: ...\n    @overload\n    def __getitem__(self, idx: Tuple[_IndexType, _IndexType]) -> DataFrame: ...\n    @overload\n    def __getitem__(self, idx: Tuple[_IndexType, int]) -> Series: ...\n    @overload\n    def __getitem__(self, idx: Tuple[int, _IndexType]) -> Series: ...\n    # set item\n    @overload\n    def __setitem__(self, idx: int, value: Union[float, Series]) -> None: ...\n    @overload\n    def __setitem__(self, idx: Tuple[int, int], value: float) -> None: ...\n    @overload\n    def __setitem__(self, idx: _IndexType, value: Union[float, Series, DataFrame]) -> None: ...\n    @overload\n    def __setitem__(\n        self, idx: Tuple[_IndexType, _IndexType], value: Union[float, Series, DataFrame]\n    ) -> None: ...\n    @overload\n    def __setitem__(self, idx: Tuple[_IndexType, int], value: Union[float, Series]) -> None: ...\n    @overload\n    def __setitem__(self, idx: Tuple[int, _IndexType], value: Union[float, Series]) -> None: ...\n\nclass _iLocIndexerSeries(Generic[_DType]):\n    # get item\n    @overload\n    def __getitem__(self, idx: int) -> _DType: ...\n    @overload\n    def __getitem__(self, idx: _IndexType) -> Series[_DType]: ...\n    # set item\n    @overload\n    def __setitem__(self, idx: int, value: _DType) -> None: ...\n    @overload\n    def __setitem__(self, idx: _IndexType, value: Union[_DType, Series[_DType]]) -> None: ...\n\nclass _LocIndexerFrame:\n    # get item\n    @overload\n    def __getitem__(self, idx: Union[_MaskType, _IndexType]) -> DataFrame: ...\n    @overload\n    def __getitem__(self, idx: _StrLike) -> Series: ...\n    @overload\n    def __getitem__(self, idx: List[_StrLike]) -> DataFrame: ...\n    @overload\n    def __getitem__(\n        self,\n        idx: Tuple[\n            Union[slice, _MaskType, _IndexType, List[str]], Union[_MaskType, List[str], str]\n        ],\n    ) -> DataFrame: ...\n    @overload\n    def __getitem__(self, idx: Tuple[_StrLike, _StrLike]) -> float: ...\n    # set item\n    @overload\n    def __setitem__(\n        self, idx: Union[_MaskType, _IndexType], value: Union[float, _np.ndarray, DataFrame]\n    ) -> None: ...\n    @overload\n    def __setitem__(self, idx: _StrLike, value: Union[float, Series, _np.ndarray]) -> None: ...\n    @overload\n    def __setitem__(\n        self, idx: List[_StrLike], value: Union[float, _np.ndarray, DataFrame]\n    ) -> None: ...\n    @overload\n    def __setitem__(self, idx: Tuple[_IndexType, str], value: Union[_IndexType, float]) -> None: ...\n    @overload\n    def __setitem__(\n        self,\n        idx: Tuple[Union[_MaskType, _IndexType, List[str]], Union[_MaskType, List[str]]],\n        value: Union[DataFrame, Series, float],\n    ) -> None: ...\n\nclass _AtIndexerFrame:\n    # get item\n    def __getitem__(self, idx: Tuple[int, Hashable]) -> Union[int, float, str]: ...\n    # set item\n    def __setitem__(self, idx: Tuple[int, Hashable], value: Union[int, float, str]) -> None: ...\n\nclass _AtIndexerSeries(Generic[_DType]):\n    # get item\n    def __getitem__(self, idx: _StrLike) -> _DType: ...\n    # set item\n    def __setitem__(self, idx: _StrLike, value: _DType) -> None: ...\n\nclass _LocIndexerSeries(Generic[_DType]):\n    # get item\n    @overload\n    def __getitem__(self, idx: _MaskType) -> Series[_DType]: ...\n    @overload\n    def __getitem__(self, idx: str) -> _DType: ...\n    @overload\n    def __getitem__(self, idx: List[str]) -> Series[_DType]: ...\n    @overload\n    # set item\n    def __setitem__(\n        self, idx: _MaskType, value: Union[_DType, _np.ndarray, Series[_DType]]\n    ) -> None: ...\n    @overload\n    def __setitem__(self, idx: str, value: _DType) -> None: ...\n    @overload\n    def __setitem__(\n        self, idx: List[str], value: Union[_DType, _np.ndarray, Series[_DType]]\n    ) -> None: ...\n\n# Local Variables:\n# blacken-line-length: 100\n# blacken-allow-py36: t\n# blacken-skip-string-normalization: t\n# End:\n",
    "/typeshed/pandas/core/series.pyi": "from pathlib import Path\nfrom typing import (\n    List,\n    Set,\n    Tuple,\n    Type,\n    Union,\n    overload,\n    Optional,\n    Dict,\n    Mapping,\n    TypeVar,\n    Iterator,\n    Generic,\n    Sequence,\n    Callable,\n    Any,\n)\nfrom typing_extensions import Literal\nimport numpy as _np\n\nfrom .indexing import _LocIndexerSeries, _iLocIndexerSeries, _AtIndexerSeries\nfrom .frame import DataFrame, _AxisType\nfrom .indexes import Index\nfrom .strings import StringMethods\n\n_str = str  # needed because Series has a property called \"str\"...\n\n_DType = TypeVar(\"_DType\", str, bool, int, float, object, _np.ndarray, List, covariant=True)\n_DType2 = TypeVar(\"_DType2\", str, bool, int, float, object, _np.ndarray, List, covariant=True)\n_Number = TypeVar(\"_Number\", int, float, covariant=True)\n_ListLike = Union[_np.ndarray, List[_DType], Dict[_str, _np.ndarray]]\n# dtypes for numpy\n_DTypeNp = TypeVar(\n    \"_DTypeNp\",\n    _np.bool_,\n    _np.int8,\n    _np.int16,\n    _np.int32,\n    _np.int64,\n    _np.float32,\n    _np.float64,\n    _np.str_,\n)\n_SortKind = Literal[\"quicksort\", \"mergesort\", \"heapsort\"]\n_LevelType = Optional[Union[int, _str, List[int], List[_str]]]\n\nclass Series(Generic[_DType]):\n    def __init__(\n        self,\n        data: Optional[\n            Union[_ListLike[_DType], Series[_DType], Dict[int, _DType], Dict[_str, _DType], int]\n        ],\n        index: Union[_str, int, Series, Index, range] = ...,\n    ): ...\n    # magic methods\n    def __add__(self, other: Union[_Number, Series[_Number]]) -> Series[_Number]: ...\n    def __and__(self, other: Union[bool, Series[bool]]) -> Series[bool]: ...\n    def __eq__(self, other: object) -> Series: ...  # type: ignore\n    def __floordiv__(self, other: Union[int, Series[int]]) -> Series[int]: ...\n    def __ge__(self, other: Union[float, Series[float]]) -> Series[bool]: ...\n    @overload\n    def __getitem__(self, idx: Union[List[_str], Index[int], Series, slice]) -> Series: ...\n    @overload\n    def __getitem__(self, idx: Union[_str, int]) -> _DType: ...\n    def __gt__(self, other: Union[float, Series[float]]) -> Series[bool]: ...\n    def __invert__(self: Series[bool]) -> Series[bool]: ...\n    def __iter__(self) -> Iterator[_DType]: ...\n    def __le__(self, other: Union[float, Series[float]]) -> Series[bool]: ...\n    def __len__(self) -> int: ...\n    def __lt__(self, other: Union[float, Series[float]]) -> Series[bool]: ...\n    def __mod__(self, other: Union[int, Series[int]]) -> Series[int]: ...\n    def __mul__(self, other: Union[_Number, Series[_Number]]) -> Series[_Number]: ...\n    def __ne__(self, other: object) -> Series: ...  # type: ignore\n    def __or__(self, other: Union[bool, Series[bool]]) -> Series[bool]: ...\n    def __radd__(self, other: Union[_Number, Series[_Number]]) -> Series[_Number]: ...\n    def __rmul__(self, other: Union[_Number, Series[_Number]]) -> Series[_Number]: ...\n    def __rsub__(self, other: Union[_Number, Series[_Number]]) -> Series[_Number]: ...\n    def __sub__(self, other: Union[_Number, Series[_Number]]) -> Series[_Number]: ...\n    def __truediv__(self, other: Union[_Number, Series[_Number]]) -> Series[_Number]: ...\n    #\n    # properties\n    @property\n    def iloc(self) -> _iLocIndexerSeries[_DType]: ...\n    @property\n    def index(self) -> Index: ...\n    @property\n    def item(self) -> _DType: ...\n    @property\n    def loc(self) -> _LocIndexerSeries[_DType]: ...\n    @property\n    def shape(self) -> Tuple[int, ...]: ...\n    @property\n    def size(self) -> int: ...\n    @property\n    def str(self) -> StringMethods: ...\n    @property\n    def values(self) -> _np.ndarray: ...\n    #\n    # methods\n    def all(self, axis: Optional[_AxisType] = ..., bool_only: bool = ...) -> bool: ...\n    def any(self, axis: Optional[_AxisType] = ..., bool_only: bool = ...) -> bool: ...\n    def append(\n        self,\n        to_append: Union[Series, Sequence[Series]],\n        ignore_index: bool = ...,\n        verify_integrity: bool = ...,\n    ) -> Series: ...\n    def apply(\n        self, func: Callable, convert_dtype: bool = ..., args: Tuple = ..., **kwargs: Any\n    ) -> Series: ...\n    @overload\n    def astype(self, dtype: Type[int]) -> Series[int]: ...\n    @overload\n    def astype(self, dtype: Type[float]) -> Series[float]: ...\n    @overload\n    def astype(self, dtype: Type[_str]) -> Series[object]: ...\n    @overload\n    def astype(self, dtype: Type[object]) -> Series[object]: ...\n    @overload\n    def copy(self) -> Series[_DType]: ...\n    @overload\n    def copy(self, deep: bool = ...) -> Series[_DType]: ...\n    def corr(\n        self, other: Series, method: Literal[\"pearson\", \"kendall\", \"spearman\"] = ...\n    ) -> float: ...\n    def count(self) -> int: ...\n    @overload\n    def drop(\n        self, labels: Union[_str, List[_str], Index], axis: _AxisType = ..., inplace: bool = ...\n    ) -> Series[_DType]: ...\n    @overload\n    def drop(self, *, index: Union[List[_str], Index]) -> Series[_DType]: ...\n    @overload\n    def drop(self, *, columns: Union[_str, List[_str], Index]) -> Series[_DType]: ...\n    def drop_duplicates(self, keep: Union[_str, bool] = ...) -> Series[_DType]: ...\n    def duplicated(self, keep: Literal[\"first\", \"last\", False] = ...) -> Series[_DType]: ...\n    @overload\n    def fillna(\n        self,\n        value: Union[_DType, Dict, Series, DataFrame],\n        method: _str = ...,\n        axis: Optional[_AxisType] = ...,\n        inplace: Literal[True] = ...,\n        limit: int = ...,\n        downcast: Dict = ...,\n    ) -> None: ...\n    @overload\n    def fillna(\n        self,\n        value: Union[_DType, Dict, Series, DataFrame],\n        method: _str = ...,\n        axis: Optional[_AxisType] = ...,\n        inplace: Literal[False] = ...,\n        limit: int = ...,\n        downcast: Dict = ...,\n    ) -> Optional[Series]: ...\n    def head(self, n: int = ...) -> Series: ...\n    def isna(self) -> Series[bool]: ...\n    def isnull(self) -> Series[bool]: ...\n    def isin(self, values: Union[Set, List, Tuple, Series]) -> Series[bool]: ...\n    def ge(self, value: float) -> Series[bool]: ...\n    def map(\n        self, arg: Union[Callable, Mapping, Series], na_action: Optional[_str] = ...\n    ) -> Series: ...\n    def max(self) -> _DType: ...\n    def mean(self) -> float: ...\n    def median(self) -> float: ...\n    def min(self) -> _DType: ...\n    def mode(self) -> Series[_DType]: ...\n    def notnull(self) -> Series[bool]: ...\n    def nunique(self) -> int: ...\n    def rank(\n        self,\n        axis: _AxisType = ...,\n        method: Literal[\"average\", \"min\", \"max\", \"first\", \"dense\"] = ...,\n        numeric_only: Optional[bool] = ...,\n        na_option: Literal[\"keep\", \"top\", \"bottom\"] = ...,\n        ascending: bool = ...,\n        pct: bool = ...,\n    ) -> Series[float]: ...\n    @overload\n    def replace(\n        self, to_replace: Sequence[_DType2], value: Sequence[_DType2], inplace: Literal[False] = ...\n    ) -> Series[_DType]: ...\n    @overload\n    def replace(\n        self, to_replace: Sequence[_DType2], value: Sequence[_DType2], inplace: Literal[True]\n    ) -> None: ...\n    @overload\n    def replace(\n        self, to_replace: _DType2, value: _DType2, inplace: Literal[False] = ...\n    ) -> Series[_DType]: ...\n    @overload\n    def replace(self, to_replace: _DType2, value: _DType2, inplace: Literal[True]) -> None: ...\n    def reset_index(self, drop: bool = ...) -> Series: ...\n    @overload\n    def sort_index(\n        self,\n        axis: Optional[_AxisType] = ...,\n        level: _LevelType = ...,\n        ascending: bool = ...,\n        inplace: Literal[False] = ...,\n        kind: _SortKind = ...,\n        na_position: Literal[\"first\", \"last\"] = ...,\n        sort_remaining: bool = ...,\n        ignore_index: bool = ...,\n        key: Optional[Callable] = ...,\n    ) -> Series[_DType]: ...\n    @overload\n    def sort_index(\n        self,\n        axis: Optional[_AxisType],\n        level: _LevelType,\n        ascending: bool,\n        inplace: Literal[True],\n        kind: _SortKind = ...,\n        na_position: Literal[\"first\", \"last\"] = ...,\n        sort_remaining: bool = ...,\n        ignore_index: bool = ...,\n        key: Optional[Callable] = ...,\n    ) -> None: ...\n    @overload\n    def sort_index(\n        self,\n        *,\n        inplace: Literal[True],\n        axis: Optional[_AxisType] = ...,\n        level: _LevelType = ...,\n        ascending: bool = ...,\n        kind: _SortKind = ...,\n        na_position: Literal[\"first\", \"last\"] = ...,\n        sort_remaining: bool = ...,\n        ignore_index: bool = ...,\n        key: Optional[Callable] = ...,\n    ) -> None: ...\n    @overload\n    def sort_values(\n        self,\n        axis: Optional[_AxisType] = ...,\n        ascending: bool = ...,\n        inplace: Literal[False] = ...,\n        kind: _SortKind = ...,\n        na_position: Literal[\"first\", \"last\"] = ...,\n        ignore_index: bool = ...,\n        key: Optional[Callable] = ...,\n    ) -> Series[_DType]: ...\n    @overload\n    def sort_values(\n        self,\n        axis: Optional[_AxisType],\n        ascending: bool,\n        inplace: Literal[True],\n        kind: _SortKind = ...,\n        na_position: Literal[\"first\", \"last\"] = ...,\n        ignore_index: bool = ...,\n        key: Optional[Callable] = ...,\n    ) -> None: ...\n    @overload\n    def sort_values(\n        self,\n        *,\n        inplace: Literal[True],\n        axis: Optional[_AxisType] = ...,\n        ascending: bool = ...,\n        kind: _SortKind = ...,\n        na_position: Literal[\"first\", \"last\"] = ...,\n        ignore_index: bool = ...,\n        key: Optional[Callable] = ...,\n    ) -> None: ...\n    def shift(\n        self,\n        periods: int = ...,\n        freq: Optional[_str] = ...,\n        axis: Optional[_AxisType] = ...,\n        fill_value: Optional[object] = ...,\n    ) -> Series[_DType]: ...\n    def std(self) -> float: ...\n    def sum(self) -> float: ...\n    def to_csv(self, filename: Union[Path, _str], index: bool = ...) -> None: ...\n    def to_dict(self) -> Dict[Union[int, _str], _DType]: ...\n    def to_frame(self, name: Optional[_str] = ...) -> DataFrame: ...\n    @overload\n    def to_numpy(self: Series[bool]) -> _np.ndarray[_np.bool_]: ...\n    @overload\n    def to_numpy(self: Series[int]) -> _np.ndarray[_np.int64]: ...\n    @overload\n    def to_numpy(self: Series[float]) -> _np.ndarray[_np.float64]: ...\n    @overload\n    def to_numpy(self: Series[object]) -> _np.ndarray: ...\n    @overload\n    def to_numpy(self, dtype: Type[_DTypeNp]) -> _np.ndarray[_DTypeNp]: ...\n    def to_pickle(\n        self,\n        path: Union[Path, _str],\n        compression: Optional[Literal[\"infer\", \"gzip\", \"bz2\", \"zip\", \"xz\"]] = ...,\n        protocol: int = ...,\n    ) -> None: ...\n    def tolist(self) -> List[_DType]: ...\n    def unique(self) -> _np.ndarray: ...\n    def update(self, other: Series) -> None: ...\n    def where(self, cond: Union[Series, DataFrame, _np.ndarray]) -> Series[_DType]: ...\n    def value_counts(self, normalize: bool = ...) -> Series[_DType]: ...\n    @property\n    def at(self) -> _AtIndexerSeries[_DType]: ...\n\n# Local Variables:\n# blacken-line-length: 100\n# blacken-allow-py36: t\n# blacken-skip-string-normalization: t\n# End:\n",
    "/typeshed/pandas/core/strings.pyi": "from typing import List, Optional, Union\nfrom .frame import DataFrame\nfrom .series import Series\n\nclass StringMethods:\n    def contains(\n        self, pat: str, case: bool = ..., flags: int = ..., na: float = ..., regex: bool = ...\n    ) -> Series[bool]: ...\n    def count(self, pat: str, flags: int = ...) -> Series[int]: ...\n    def endswith(self, pat: str, na: float = ...) -> Series[bool]: ...\n    def find(self, sub: str, start: int, end: int) -> Series[int]: ...\n    def findall(self, sub: str, flags: int = ...) -> Series[list]: ...\n    def get(self, i: int) -> Series: ...\n    def index(self, sub: str, start: int, end: int) -> Series: ...\n    def join(self, sep: str) -> Series: ...\n    def len(self) -> Series[int]: ...\n    def ljust(self, width: int, fillchar: str) -> Series: ...\n    def lower(self) -> Series[str]: ...\n    def lstrip(self, to_strip: str = ...) -> Series: ...\n    def match(self, pat: str, case: bool = ..., flag: int = ..., na: float = ...) -> Series: ...\n    def pad(self, width: int, side: str = ..., fillchar: str = ...) -> Series: ...\n    def repeat(self, repeats: Union[int, List[int]]) -> Series: ...\n    def rfind(self, sub: str, start: int, end: int) -> Series[int]: ...\n    def rindex(self, sub: str, start: int, end: int) -> Series: ...\n    def rjust(self, width: int, fillchar: str) -> Series: ...\n    def rstrip(self, to_strip: Optional[str] = ...) -> Series: ...\n    def slice(self, start: Optional[int], stop: Optional[int], step: Optional[int]) -> Series: ...\n    def slice_replace(\n        self, start: Optional[int], stop: Optional[int], repl: Optional[str]\n    ) -> Series: ...\n    def split(self, pat: Optional[str], n: int = ..., expand: bool = ...) -> Series: ...\n    def rsplit(self, pat: Optional[str], n: int = ..., expand: bool = ...) -> Series: ...\n    def startswith(self, pat: str, na: float = ...) -> Series: ...\n    def strip(self, to_strip: Optional[str] = ...) -> Series: ...\n    def translate(self, table: dict) -> Series: ...\n    def wrap(\n        self,\n        width: int,\n        expand_tabs: Optional[bool],\n        replace_whitespace: Optional[bool],\n        drop_whitespace: Optional[bool],\n        break_long_words: Optional[bool],\n        break_on_hyphens: Optional[bool],\n    ) -> Series: ...\n    def zfill(self, width: int) -> Series: ...\n    def get_dummies(self, sep: str = ...) -> DataFrame: ...\n",
    "/typeshed/pandas/core/dtypes/__init__.pyi": "",
    "/typeshed/pandas/core/dtypes/base.pyi": "from typing import (\n    Any,\n    Callable,\n    Generator,\n    List,\n    Optional,\n    Sequence,\n    Tuple,\n    Type,\n    TypeVar,\n    Union,\n)\nfrom typing_extensions import Literal\n\nimport numpy as np\nfrom numpy import _ScalarLike\n\n_ArrayLike = TypeVar(\"_ArrayLike\", _ExtensionArray, np.ndarray)\n_DtypeObj = Union[np.dtype, ExtensionDtype]\n\nclass ExtensionDtype:\n    def __str__(self) -> str: ...\n    def __eq__(self, other: Any) -> bool: ...\n    def __hash__(self) -> int: ...\n    def __ne__(self, other: Any) -> bool: ...\n    @property\n    def na_value(self) -> object: ...\n    @property\n    def type(self) -> Type: ...\n    @property\n    def kind(self) -> str: ...\n    @property\n    def name(self) -> str: ...\n    @property\n    def names(self) -> Optional[List[str]]: ...\n    @classmethod\n    def construct_array_type(cls) -> Type[_ExtensionArray]: ...\n    @classmethod\n    def construct_from_string(cls, string: str) -> ExtensionDtype: ...\n    @classmethod\n    def is_dtype(cls, dtype: object) -> bool: ...\n    @property\n    def _is_numeric(self) -> bool: ...\n    @property\n    def _is_boolean(self) -> bool: ...\n    def _get_common_dtype(self, dtypes: List[_DtypeObj]) -> Optional[_DtypeObj]: ...\n\nclass _ExtensionArray:\n    @classmethod\n    def _from_sequence(\n        cls, scalars: Sequence[_ScalarLike], dtype: Optional[_DtypeObj] = ..., copy: bool = ...\n    ) -> _ExtensionArray: ...\n    @classmethod\n    def _from_sequence_of_strings(\n        cls, strings: Sequence[str], dtype: Optional[_DtypeObj] = ..., copy: bool = ...\n    ) -> _ExtensionArray: ...\n    @classmethod\n    def _from_factorized(cls, values: np.ndarray, original: _ExtensionArray) -> _ExtensionArray: ...\n    def __getitem__(self, item: Union[int, slice, np.ndarray]) -> Any: ...\n    def __setitem__(self, key: Union[int, slice, np.ndarray], value: Any) -> None: ...\n    def __len__(self) -> int: ...\n    def __iter__(self) -> Generator[Any, None, None]: ...\n    # The next two functions are complaining that we're changing the return type of the base class\n    # Which Pandas does. Instead of bool, it returns an array of bools\n    # So squelch those warnings\n    def __eq__(self, other: Any) -> _ArrayLike: ...  # type: ignore\n    def __ne__(self, other: Any) -> _ArrayLike: ...  # type: ignore\n    def to_numpy(\n        self,\n        dtype: Optional[_DtypeObj] = ...,\n        copy: bool = ...,\n        na_value: Optional[Any] = ...,\n    ) -> np.ndarray: ...\n    @property\n    def dtype(self) -> _DtypeObj: ...\n    @property\n    def shape(self) -> Tuple[int, ...]: ...\n    @property\n    def size(self) -> int: ...\n    @property\n    def ndim(self) -> int: ...\n    @property\n    def nbytes(self) -> int: ...\n    def astype(self, dtype: Union[str, _DtypeObj], copy: bool = ...) -> np.ndarray: ...\n    def isna(self) -> _ArrayLike: ...\n    def _values_for_argsort(self) -> np.ndarray: ...\n    def argsort(\n        self, ascending: bool = ..., kind: str = ..., *args: Any, **kwargs: Any\n    ) -> np.ndarray: ...\n    def argmin(self) -> int: ...\n    def argmax(self) -> int: ...\n    def fillna(\n        self,\n        value: Union[_ScalarLike, _ArrayLike] = ...,\n        method: Optional[Literal[\"backfill\", \"bfill\", \"pad\", \"ffill\"]] = ...,\n        limit: Optional[int] = ...,\n    ) -> _ExtensionArray: ...\n    def dropna(self) -> _ExtensionArray: ...\n    def shift(self, periods: int = ..., fill_value: object = ...) -> _ExtensionArray: ...\n    def unique(self) -> _ExtensionArray: ...\n    def searchsorted(\n        self,\n        value: _ArrayLike,\n        side: Optional[Literal[\"left\", \"right\"]] = ...,\n        sorter: Optional[_ArrayLike] = ...,\n    ) -> np.ndarray: ...\n    def equals(self, other: _ExtensionArray) -> bool: ...\n    def _values_for_factorize(self) -> Tuple[np.ndarray, Any]: ...\n    def factorize(self, na_sentinel: int = ...) -> Tuple[np.ndarray, _ExtensionArray]: ...\n    def repeat(\n        self, repeats: Union[int, np.ndarray], axis: Optional[int] = ...\n    ) -> _ExtensionArray: ...\n    def take(\n        self, indices: Sequence[int], allow_fill: bool = ..., fill_value: Any = ...\n    ) -> _ExtensionArray: ...\n    def copy(self) -> _ExtensionArray: ...\n    def view(self, dtype: _DtypeObj = ...) -> _ArrayLike: ...\n    def __repr__(self) -> str: ...\n    def _formatter(self, boxed: bool = ...) -> Callable[[Any], Optional[str]]: ...\n    def ravel(self, order: Optional[Literal[\"C\", \"F\", \"A\", \"K\"]] = ...) -> _ExtensionArray: ...\n    @classmethod\n    def _concat_same_type(cls, to_concat: Sequence[_ExtensionArray]) -> _ExtensionArray: ...\n    def _reduce(self, name: str, skipna: bool = ..., **kwargs: Any) -> _ScalarLike: ...\n    def __hash__(self) -> int: ...\n",
    "/typeshed/pandas/core/groupby/__init__.pyi": "",
    "/typeshed/pandas/core/groupby/generic.pyi": "from typing import overload, Union, List, Dict, Iterator\nfrom typing_extensions import Literal\nimport numpy as _np\n\nfrom pandas.core.frame import DataFrame\nfrom pandas.core.series import Series\nfrom ..frame import _FunctionLike\n\n_str = str  # needed because Series has a property called \"str\"...\n\nclass GroupBy: ...\n\nclass SeriesGroupBy(GroupBy):\n    def __getitem__(self, item: _str) -> Series: ...\n    def count(self) -> Series: ...\n    def head(self, n: int = ...) -> Series: ...\n    def max(self) -> Series: ...\n    def mean(self) -> Series: ...\n    def median(self) -> Series: ...\n    def min(self) -> Series: ...\n    def nunique(self, dropna: bool = ...) -> Series: ...\n    def quantile(self, q: float = ..., interpolation: str = ...) -> Series: ...\n    def rank(\n        self,\n        method: Literal[\"average\", \"min\", \"max\", \"first\", \"dense\"] = ...,\n        ascending: bool = ...,\n        na_option: Literal[\"keep\", \"top\", \"bottom\"] = ...,\n        pct: bool = ...,\n    ) -> Series: ...\n    def std(self, ddof: int = ...) -> Series: ...\n    def sum(self) -> Series: ...\n    def tail(self, n: int = ...) -> Series: ...\n    def unique(self) -> Series[_np.ndarray]: ...\n    def var(self, ddof: int = ...) -> Series: ...\n\nclass DataFrameGroupBy(GroupBy):\n    @overload\n    def __getitem__(self, item: _str) -> SeriesGroupBy: ...\n    @overload\n    def __getitem__(self, item: List[_str]) -> DataFrameGroupBy: ...\n    def __getattr__(self, name: _str) -> SeriesGroupBy: ...\n    def __iter__(self) -> Iterator: ...\n    def aggregate(\n        self, func: Union[_FunctionLike, List[_FunctionLike], Dict[_str, _FunctionLike]]\n    ) -> DataFrame: ...\n    agg = aggregate\n    def count(self) -> DataFrame: ...\n    def head(self, n: int = ...) -> DataFrame: ...\n    def max(self) -> DataFrame: ...\n    def mean(self) -> DataFrame: ...\n    def median(self) -> DataFrame: ...\n    def min(self) -> DataFrame: ...\n    def nunique(self, dropna: bool = ...) -> DataFrame: ...\n    def quantile(self, q: float = ..., interpolation: str = ...) -> DataFrame: ...\n    def rank(\n        self, method: str, ascending: bool, na_option: str, pct: bool, axis: int\n    ) -> DataFrame: ...\n    def std(self, ddof: int = ...) -> DataFrame: ...\n    def sum(self) -> DataFrame: ...\n    def tail(self, n: int = ...) -> DataFrame: ...\n    def var(self, ddof: int = ...) -> DataFrame: ...\n",
    "/typeshed/pandas/core/arrays/__init__.pyi": "from .base import ExtensionArray, ExtensionOpsMixin\n",
    "/typeshed/pandas/core/arrays/base.pyi": "from typing import Any, Callable, TypeVar\n\nimport numpy as np\n\n# This is normally where ExtensionArray would be defined,\n# but we can't do conditional TYPE_CHECKING imports like pandas does.\n# So this will work for now.\nfrom ..dtypes.base import _ArrayLike\nfrom ..dtypes.base import _ExtensionArray as ExtensionArray\n\nclass ExtensionOpsMixin:\n    @classmethod\n    def _create_arithmetic_method(\n        cls, op: Callable[..., Any]\n    ) -> Callable[[Any, Any], ExtensionArray]: ...\n    @classmethod\n    def _add_arithmetic_ops(cls) -> None: ...\n    @classmethod\n    def _create_comparison_method(cls, op: Callable[..., Any]) -> Callable[..., bool]: ...\n    @classmethod\n    def _add_comparison_ops(cls) -> None: ...\n    @classmethod\n    def _create_logical_method(cls, op: Callable[..., Any]) -> Callable[..., bool]: ...\n    @classmethod\n    def _add_logical_ops(cls) -> None: ...\n",
    "/typeshed/pandas/core/arrays/integer.pyi": "from typing import Any, Callable, List, Optional, Sequence, Type, Union, Tuple\nfrom typing_extensions import Literal\nimport numpy as np\nfrom numpy import _ScalarLike\n\nfrom ..dtypes.base import _ArrayLike, _DtypeObj\nfrom .masked import BaseMaskedArray, BaseMaskedDtype\n\nclass _IntegerDtype(BaseMaskedDtype):\n    def __repr__(self) -> str: ...\n    def is_signed_integer(self) -> bool: ...\n    def is_unsigned_integer(self) -> bool: ...\n    @property\n    def _is_numeric(self) -> bool: ...\n    def numpy_dtype(self) -> np.dtype: ...\n    def kind(self) -> str: ...\n    def itemsize(self) -> int: ...\n    @classmethod\n    def construct_array_type(cls) -> Type[IntegerArray]: ...\n    def _get_common_dtype(self, dtypes: List[_DtypeObj]) -> Optional[_DtypeObj]: ...\n    def __from_arrow__(\n        self,\n        array: Any,  # Union[pyarrow.Array, pyarrow.ChunkedArray]\n    ) -> IntegerArray: ...\n\nclass IntegerArray(BaseMaskedArray):\n    def dtype(self) -> _IntegerDtype: ...\n    def __init__(self, values: np.ndarray, mask: np.ndarray, copy: bool = ...) -> None: ...\n    @classmethod\n    def _from_sequence(\n        cls, scalars: Sequence[_ScalarLike], dtype: Optional[_DtypeObj] = ..., copy: bool = ...\n    ) -> IntegerArray: ...\n    @classmethod\n    def _from_sequence_of_strings(\n        cls, strings: Sequence[str], dtype: Optional[_DtypeObj] = ..., copy: bool = ...\n    ) -> IntegerArray: ...\n    def __array_ufunc__(\n        self,\n        ufunc: Callable[..., Any],\n        method: Literal[\"reduce\", \"accumulate\", \"reduceat\", \"outer\", \"at\", \"__call__\"],\n        *inputs: Any,\n        **kwargs: Any,\n    ) -> Any: ...\n    def _coerce_to_array(self, value: Any) -> Tuple[np.ndarray, np.ndarray]: ...\n    def astype(self, dtype: Union[str, _DtypeObj], copy: bool = ...) -> _ArrayLike: ...\n    def _values_for_argsort(self) -> np.ndarray: ...\n    @classmethod\n    def _create_comparison_method(cls, op: Callable[..., Any]) -> Callable[..., bool]: ...\n    def sum(self, skipna: bool = ..., min_count: int = ..., **kwargs: Any) -> _IntegerDtype: ...\n    def _maybe_mask_result(\n        self,\n        result: _ArrayLike,\n        mask: _ArrayLike,\n        other: Union[_ScalarLike, _ArrayLike],\n        op_name: str,\n    ) -> Callable[[Any, Any], IntegerArray]: ...\n    @classmethod\n    def _create_arithmetic_method(\n        cls, op: Callable[..., Any]\n    ) -> Callable[[Any, Any], IntegerArray]: ...\n\nclass Int8Dtype(_IntegerDtype): ...\nclass Int16Dtype(_IntegerDtype): ...\nclass Int32Dtype(_IntegerDtype): ...\nclass Int64Dtype(_IntegerDtype): ...\nclass UInt8Dtype(_IntegerDtype): ...\nclass UInt16Dtype(_IntegerDtype): ...\nclass UInt32Dtype(_IntegerDtype): ...\nclass UInt64Dtype(_IntegerDtype): ...\n",
    "/typeshed/pandas/core/arrays/masked.pyi": "from typing import Any, Generator, Iterable, Optional, Sequence, Tuple, Type, TypeVar, Union\n\nimport numpy as np\nfrom numpy import _ScalarLike\n\nfrom ..arrays.base import ExtensionArray, ExtensionOpsMixin\nfrom ..dtypes.base import ExtensionDtype, _ArrayLike, _DtypeObj\nfrom ..series import Series\n\n_BaseMaskedArrayT = TypeVar(\"_BaseMaskedArrayT\", bound=BaseMaskedArray)\n\nclass BaseMaskedDtype(ExtensionDtype):\n    @property\n    def numpy_dtype(self) -> np.dtype: ...\n    @classmethod\n    def construct_array_type(cls) -> Type[BaseMaskedArray]: ...\n\nclass BaseMaskedArray(ExtensionArray, ExtensionOpsMixin):\n    def __init__(self, values: np.ndarray, mask: np.ndarray, copy: bool = ...) -> None: ...\n    @property\n    def dtype(self) -> BaseMaskedDtype: ...\n    def _coerce_to_array(self, values: Any) -> Tuple[np.ndarray, np.ndarray]: ...\n    def __setitem__(self, key: Union[int, slice, np.ndarray], value: Any) -> None: ...\n    def __iter__(self) -> Generator[Any, None, None]: ...\n    def __len__(self) -> int: ...\n    def __invert__(self: _BaseMaskedArrayT) -> _BaseMaskedArrayT: ...\n    def to_numpy(\n        self, dtype: Optional[_DtypeObj] = ..., copy: bool = ..., na_value: _ScalarLike = ...\n    ) -> np.ndarray: ...\n    def __array__(self, dtype: _DtypeObj = ...) -> np.ndarray: ...\n    def __arrow_array__(self, type: Optional[Any] = ...) -> Any: ...  # pyarrow.array: ...\n    @property\n    def _hasna(self) -> bool: ...\n    def isna(self) -> _ArrayLike: ...\n    @property\n    def _na_value(self) -> Any: ...\n    @property\n    def nbytes(self) -> int: ...\n    @classmethod\n    def _concat_same_type(\n        cls: Type[_BaseMaskedArrayT], to_concat: Iterable\n    ) -> _BaseMaskedArrayT: ...\n    def take(\n        self: _BaseMaskedArrayT,\n        indexer: Sequence,\n        allow_fill: bool = ...,\n        fill_value: Optional[_ScalarLike] = ...,\n    ) -> _BaseMaskedArrayT: ...\n    def copy(self: _BaseMaskedArrayT) -> _BaseMaskedArrayT: ...\n    def factorize(self, na_sentinel: int = ...) -> Tuple[np.ndarray, ExtensionArray]: ...\n    def value_counts(self, dropna: bool = ...) -> Series: ...\n    def _reduce(self, name: str, skipna: bool = ..., **kwargs: Any) -> _ScalarLike: ...\n",
    "/typeshed/pandas/core/indexes/__init__.pyi": "from .base import Index as Index\nfrom .frozen import FrozenList as FrozenList\nfrom .multi import MultiIndex as MultiIndex\n",
    "/typeshed/pandas/core/indexes/base.pyi": "from typing import (\n    Callable,\n    Generic,\n    Iterator,\n    List,\n    Optional,\n    Set,\n    Tuple,\n    Type,\n    TypeVar,\n    Union,\n    overload,\n)\n\nimport numpy as _np\n\nfrom ..frame import DataFrame\nfrom ..series import Series\nfrom ..strings import StringMethods\nfrom .frozen import FrozenList\n\n_str = str  # needed because Index has a property called \"str\"...\n\n_T = TypeVar(\"_T\", _str, int)\n_U = TypeVar(\"_U\", _str, int)\n\n_ArrayLike = Union[List[_T], Series[_T], _np.ndarray, range]\n\nclass Index(Generic[_T]):\n    # magic methods\n    def __init__(\n        self,\n        data: _ArrayLike[_T],\n        dtype: Optional[_np.dtype] = ...,\n        copy: Optional[bool] = ...,\n        name: Optional[_str] = ...,\n        tupleize_cols: Optional[bool] = ...,\n    ): ...\n    def __eq__(self, other: object) -> Series: ...  # type: ignore\n    @overload\n    def __getitem__(self, idx: int) -> _T: ...\n    @overload\n    def __getitem__(self, idx: Index[_T]) -> Index[_T]: ...\n    @overload\n    def __getitem__(self, idx: Series[bool]) -> _T: ...\n    @overload\n    def __getitem__(self, idx: Tuple[_np.ndarray[_np.int64], ...]) -> _T: ...\n    @overload\n    def __getitem__(self, idx: _np.ndarray[_np.int64]) -> _T: ...\n    def __iter__(self) -> Iterator: ...\n    def __len__(self) -> int: ...\n    def __ne__(self, other: _str) -> Index[_T]: ...  # type: ignore\n    #\n    # properties\n    @property\n    def names(self) -> FrozenList[_str]: ...\n    @property\n    def shape(self) -> Tuple[int, ...]: ...\n    @property\n    def str(self) -> StringMethods: ...\n    @overload\n    def values(self: Index[_str]) -> _np.ndarray[_np.str_]: ...\n    @overload\n    def values(self: Index[int]) -> _np.ndarray[_np.int64]: ...\n    #\n    # methods\n    def astype(self, dtype: Type[_U]) -> Index[_U]: ...\n    def difference(self, other: Union[List[_T], Index[_T]]) -> Index[_T]: ...\n    def get_level_values(self, level: _str) -> Index: ...\n    def isin(\n        self, values: Union[Set, _ArrayLike], level: Union[_str, int] = ...\n    ) -> _np.ndarray[_np.bool_]: ...\n    def map(self, fn: Callable) -> Index: ...\n    def min(self) -> _T: ...\n    def max(self) -> _T: ...\n    def to_frame(self) -> DataFrame: ...\n    def tolist(self) -> List[_T]: ...\n    @overload\n    def to_numpy(self: Index[_str]) -> _np.ndarray[_np.str_]: ...\n    @overload\n    def to_numpy(self: Index[int]) -> _np.ndarray[_np.int64]: ...\n    def unique(self) -> List[_T]: ...\n    def duplicated(self) -> _np.ndarray[_np.bool_]: ...\n    def isna(self) -> _np.ndarray[_np.bool_]: ...\n    def isnull(self) -> _np.ndarray[_np.bool_]: ...\n",
    "/typeshed/pandas/core/indexes/frozen.pyi": "from typing import Generic, Iterator, List, overload, TypeVar, Tuple, Union\n\n_T = TypeVar(\"_T\")\n\nclass FrozenList(Generic[_T]):\n    @overload\n    def __getitem__(self, idx: int) -> _T: ...\n    @overload\n    def __getitem__(self, idx: slice) -> FrozenList[_T]: ...\n    def __iter__(self) -> Iterator[_T]: ...\n    def __len__(self) -> int: ...\n    def __contains__(self, key: object) -> bool: ...\n    def __reversed__(self) -> FrozenList[_T]: ...\n    def __radd__(\n        self, other: Union[FrozenList[_T], List[_T], Tuple[_T, ...]]\n    ) -> FrozenList[_T]: ...\n",
    "/typeshed/pandas/core/indexes/multi.pyi": "from typing import Iterable, List, Optional, Sequence, Tuple, TypeVar, Union\n\nimport numpy as _np\n\nfrom ..frame import DataFrame\nfrom ..series import Series\nfrom .base import Index\nfrom .frozen import FrozenList\n\n_str = str\n_T = TypeVar(\"_T\", _str, int)\n_ArrayLike = Union[List[_T], Series[_T], _np.ndarray]\n\nclass MultiIndex(Index):\n    @property\n    def names(self) -> FrozenList[str]: ...\n    @property\n    def levels(self) -> FrozenList[Index[_T]]: ...\n    @property\n    def codes(self) -> FrozenList[_np.ndarray[_np.int8]]: ...\n    @property\n    def nlevels(self) -> int: ...\n    @property\n    def levshape(self) -> Tuple[int, ...]: ...\n    @classmethod\n    def from_arrays(\n        cls,\n        arrays: Sequence[_ArrayLike],\n        sort_order: Optional[bool] = ...,\n        names: Optional[Union[List[str], Tuple[str, ...]]] = ...,\n    ) -> MultiIndex: ...\n    @classmethod\n    def from_product(\n        cls,\n        iterables: Sequence[Iterable[_T]],\n        sort_order: Optional[bool] = ...,\n        names: Optional[Union[List[str], Tuple[str, ...]]] = ...,\n    ) -> MultiIndex: ...\n    @classmethod\n    def from_tuples(\n        cls,\n        tuples: Sequence[Tuple[_T, ...]],\n        sort_order: Optional[bool] = ...,\n        names: Optional[Union[List[str], Tuple[str, ...]]] = ...,\n    ) -> MultiIndex: ...\n    @classmethod\n    def from_frame(\n        cls,\n        df: DataFrame,\n        sort_order: Optional[bool] = ...,\n        names: Optional[Union[List[str], Tuple[str, ...]]] = ...,\n    ) -> MultiIndex: ...\n"
  }
}